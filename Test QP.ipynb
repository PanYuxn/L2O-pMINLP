{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2cf0b81c90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "num_data = 5000   # number of data\n",
    "num_vars = 5      # number of decision variables\n",
    "num_ints = 5      # number of integer decision variables\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_train = np.random.uniform(1, 11, (train_size, num_vars)).astype(np.float32)\n",
    "p_test = np.random.uniform(1, 11, (test_size, num_vars)).astype(np.float32)\n",
    "p_dev = np.random.uniform(1, 11, (val_size, num_vars)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7678b7-f3c9-4066-816b-a13131bcd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev}, name=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91eaf9b-55bd-417f-a544-84fde74c6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "loader_train = DataLoader(data_train, batch_size=32, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size=32, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size=32, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f16db-28e1-4c9e-bdd3-b747f670c04d",
   "metadata": {},
   "source": [
    "## NM Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c1c5a4-038b-4776-8a44-8ebb5a351e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuromancer as nm\n",
    "from problem.neural import probQuadratic\n",
    "\n",
    "def getNMProb(round_module):\n",
    "    # parameters\n",
    "    p = nm.constraint.variable(\"p\")\n",
    "    # variables\n",
    "    x_bar = nm.constraint.variable(\"x_bar\")\n",
    "    x_rnd = nm.constraint.variable(\"x_rnd\")\n",
    "\n",
    "    # model\n",
    "    obj_bar, constrs_bar = probQuadratic(x_bar, p, num_vars=num_vars, alpha=100)\n",
    "    obj_rnd, constrs_rnd = probQuadratic(x_rnd, p, num_vars=num_vars, alpha=100)\n",
    "\n",
    "    # define neural architecture for the solution mapping\n",
    "    func = nm.modules.blocks.MLP(insize=num_vars, outsize=num_vars, bias=True,\n",
    "                                 linear_map=nm.slim.maps[\"linear\"], nonlin=nn.ReLU, hsizes=[80]*4)\n",
    "    # solution map from model parameters: sol_map(p) -> x\n",
    "    sol_map = nm.system.Node(func, [\"p\"], [\"x_bar\"], name=\"smap\")\n",
    "\n",
    "    # trainable components\n",
    "    components = [sol_map, round_module]\n",
    "\n",
    "    # penalty loss\n",
    "    loss = nm.loss.PenaltyLoss(obj_rnd, constrs_rnd)\n",
    "    problem = nm.problem.Problem(components, loss)\n",
    "\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.solver import exactQuadratic\n",
    "model = exactQuadratic(n_vars=num_vars, n_integers=num_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e326fa-de2f-415e-a4d4-1f28eef6511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    200.432000          3.839661      0.027225\n",
      "std      78.224654          5.579124      0.013338\n",
      "min      36.000000          0.000000      0.016814\n",
      "25%     149.000000          0.000000      0.023348\n",
      "50%     190.000000          0.000000      0.026231\n",
      "75%     247.000000          8.148394      0.029312\n",
      "max     511.000000         25.352531      0.416190\n"
     ]
    }
   ],
   "source": [
    "objvals, conviols, elapseds = [], [], []\n",
    "for p in tqdm(p_test):\n",
    "    model.setParamValue(*p)\n",
    "    tick = time.time()\n",
    "    xval, objval = model.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e1f73-eaa5-40d9-97fb-3b70009df41b",
   "metadata": {},
   "source": [
    "## Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987f3b11-c41c-4012-b2ef-935f62099616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristic import naive_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161556c9-67af-4686-bfec-d0fdea488bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relaxed model\n",
    "model_rel = model.relax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a6d751-9afa-4b4c-abbb-1b2c9ba6ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:49<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.00000       1000.000000   1000.000000\n",
      "mean    179.96800         28.608444      0.048707\n",
      "std      76.37923          7.851483      0.020005\n",
      "min      26.00000         10.634741      0.017738\n",
      "25%     130.00000         21.912093      0.031502\n",
      "50%     170.00000         27.912093      0.049273\n",
      "75%     222.00000         33.912093      0.059908\n",
      "max     471.00000         53.912093      0.154011\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p in tqdm(p_test):\n",
    "    model_rel.setParamValue(*p)\n",
    "    tick = time.time()\n",
    "    xval_init, _ = model_rel.solve(\"scip\", max_iter=100)\n",
    "    naive_round(xval_init, model)\n",
    "    tock = time.time()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d961673a-7420-4260-838a-1ef2fb765ceb",
   "metadata": {},
   "source": [
    "## Learning to Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec0072d-675a-4430-ac06-07936115a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.round import roundModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundModel(layers=layers_rnd, param_keys=[\"p\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                        int_ind={\"x_bar\":model.intInd}, name=\"round\")\n",
    "problem = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea14d3a4-62f7-409b-874e-c9c58e0322a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 935.581787109375\n",
      "epoch: 1  train_loss: 401.3537292480469\n",
      "epoch: 2  train_loss: 377.9687805175781\n",
      "epoch: 3  train_loss: 372.4937744140625\n",
      "epoch: 4  train_loss: 373.88250732421875\n",
      "epoch: 5  train_loss: 377.8916931152344\n",
      "epoch: 6  train_loss: 377.7049865722656\n",
      "epoch: 7  train_loss: 375.1439514160156\n",
      "epoch: 8  train_loss: 373.6103210449219\n",
      "epoch: 9  train_loss: 378.47021484375\n",
      "epoch: 10  train_loss: 365.5278015136719\n",
      "epoch: 11  train_loss: 364.9478454589844\n",
      "epoch: 12  train_loss: 363.7472839355469\n",
      "epoch: 13  train_loss: 361.2356262207031\n",
      "epoch: 14  train_loss: 361.4027099609375\n",
      "epoch: 15  train_loss: 359.34246826171875\n",
      "epoch: 16  train_loss: 362.633056640625\n",
      "epoch: 17  train_loss: 361.0362243652344\n",
      "epoch: 18  train_loss: 355.6873779296875\n",
      "epoch: 19  train_loss: 358.42816162109375\n",
      "epoch: 20  train_loss: 359.5583801269531\n",
      "epoch: 21  train_loss: 357.5403137207031\n",
      "epoch: 22  train_loss: 349.9636535644531\n",
      "epoch: 23  train_loss: 348.8908386230469\n",
      "epoch: 24  train_loss: 347.56402587890625\n",
      "epoch: 25  train_loss: 347.4646911621094\n",
      "epoch: 26  train_loss: 352.0910949707031\n",
      "epoch: 27  train_loss: 350.1334228515625\n",
      "epoch: 28  train_loss: 343.3562927246094\n",
      "epoch: 29  train_loss: 349.0900573730469\n",
      "epoch: 30  train_loss: 347.3518981933594\n",
      "epoch: 31  train_loss: 349.0502014160156\n",
      "epoch: 32  train_loss: 344.830078125\n",
      "epoch: 33  train_loss: 346.5711975097656\n",
      "epoch: 34  train_loss: 346.48980712890625\n",
      "epoch: 35  train_loss: 344.4396057128906\n",
      "epoch: 36  train_loss: 345.16680908203125\n",
      "epoch: 37  train_loss: 344.4063415527344\n",
      "epoch: 38  train_loss: 342.138671875\n",
      "epoch: 39  train_loss: 344.1478271484375\n",
      "epoch: 40  train_loss: 351.90374755859375\n",
      "epoch: 41  train_loss: 345.8853759765625\n",
      "epoch: 42  train_loss: 342.7994689941406\n",
      "epoch: 43  train_loss: 342.71832275390625\n",
      "epoch: 44  train_loss: 341.3356018066406\n",
      "epoch: 45  train_loss: 339.4376220703125\n",
      "epoch: 46  train_loss: 343.4450988769531\n",
      "epoch: 47  train_loss: 341.5877685546875\n",
      "epoch: 48  train_loss: 347.0487060546875\n",
      "epoch: 49  train_loss: 346.57000732421875\n",
      "epoch: 50  train_loss: 342.8973693847656\n",
      "epoch: 51  train_loss: 340.3858947753906\n",
      "epoch: 52  train_loss: 341.66729736328125\n",
      "epoch: 53  train_loss: 341.096435546875\n",
      "epoch: 54  train_loss: 339.44097900390625\n",
      "epoch: 55  train_loss: 343.6848449707031\n",
      "epoch: 56  train_loss: 340.8739929199219\n",
      "epoch: 57  train_loss: 343.8223876953125\n",
      "epoch: 58  train_loss: 342.8704833984375\n",
      "epoch: 59  train_loss: 341.93121337890625\n",
      "epoch: 60  train_loss: 339.19488525390625\n",
      "epoch: 61  train_loss: 341.9784851074219\n",
      "epoch: 62  train_loss: 339.6905212402344\n",
      "epoch: 63  train_loss: 339.4764404296875\n",
      "epoch: 64  train_loss: 339.5360107421875\n",
      "epoch: 65  train_loss: 341.36639404296875\n",
      "epoch: 66  train_loss: 341.3432922363281\n",
      "epoch: 67  train_loss: 339.8009948730469\n",
      "epoch: 68  train_loss: 339.6594543457031\n",
      "epoch: 69  train_loss: 341.1465759277344\n",
      "epoch: 70  train_loss: 340.1202087402344\n",
      "epoch: 71  train_loss: 341.90399169921875\n",
      "epoch: 72  train_loss: 340.96343994140625\n",
      "epoch: 73  train_loss: 342.0453796386719\n",
      "epoch: 74  train_loss: 344.10211181640625\n",
      "epoch: 75  train_loss: 342.1217956542969\n",
      "epoch: 76  train_loss: 342.96942138671875\n",
      "epoch: 77  train_loss: 341.5256042480469\n",
      "epoch: 78  train_loss: 342.3397216796875\n",
      "epoch: 79  train_loss: 339.19195556640625\n",
      "epoch: 80  train_loss: 339.86383056640625\n",
      "epoch: 81  train_loss: 341.48944091796875\n",
      "epoch: 82  train_loss: 337.8290100097656\n",
      "epoch: 83  train_loss: 341.1373291015625\n",
      "epoch: 84  train_loss: 341.935302734375\n",
      "epoch: 85  train_loss: 340.90093994140625\n",
      "epoch: 86  train_loss: 342.0830383300781\n",
      "epoch: 87  train_loss: 343.14239501953125\n",
      "epoch: 88  train_loss: 338.81890869140625\n",
      "epoch: 89  train_loss: 341.02789306640625\n",
      "epoch: 90  train_loss: 342.1627197265625\n",
      "epoch: 91  train_loss: 338.6997985839844\n",
      "epoch: 92  train_loss: 341.7252502441406\n",
      "epoch: 93  train_loss: 340.4540100097656\n",
      "epoch: 94  train_loss: 341.95172119140625\n",
      "epoch: 95  train_loss: 342.2869567871094\n",
      "epoch: 96  train_loss: 342.5058898925781\n",
      "epoch: 97  train_loss: 339.1883850097656\n",
      "epoch: 98  train_loss: 337.6955261230469\n",
      "epoch: 99  train_loss: 341.29119873046875\n",
      "epoch: 100  train_loss: 341.8701477050781\n",
      "epoch: 101  train_loss: 341.1553649902344\n",
      "epoch: 102  train_loss: 341.4239196777344\n",
      "epoch: 103  train_loss: 340.6117248535156\n",
      "epoch: 104  train_loss: 341.5046691894531\n",
      "epoch: 105  train_loss: 337.21380615234375\n",
      "epoch: 106  train_loss: 338.08538818359375\n",
      "epoch: 107  train_loss: 340.0108947753906\n",
      "epoch: 108  train_loss: 339.5794982910156\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b034b7-d404-4e6d-aa6f-11ae008ef1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 387.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    194.814000          8.442956      0.002324\n",
      "std      65.672233          2.812250      0.000417\n",
      "min      46.000000          2.650724      0.002031\n",
      "25%     147.000000          6.302247      0.002119\n",
      "50%     186.000000          8.211475      0.002192\n",
      "75%     237.000000         10.302247      0.002362\n",
      "max     442.000000         18.542614      0.006761\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p in tqdm(p_test):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae6e5c-983f-4689-88e2-4ef26fe8e910",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545cae68-65b7-4d0d-b87d-f021dfb0a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.threshold import roundThresholdModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                                 int_ind={\"x_bar\":model.intInd}, name=\"round\")\n",
    "problem = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18744735-a740-489c-bd05-49988544dfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 964.7532958984375\n",
      "epoch: 1  train_loss: 389.64617919921875\n",
      "epoch: 2  train_loss: 352.8912353515625\n",
      "epoch: 3  train_loss: 348.14794921875\n",
      "epoch: 4  train_loss: 344.8109436035156\n",
      "epoch: 5  train_loss: 343.06121826171875\n",
      "epoch: 6  train_loss: 344.32269287109375\n",
      "epoch: 7  train_loss: 341.03192138671875\n",
      "epoch: 8  train_loss: 339.51239013671875\n",
      "epoch: 9  train_loss: 340.4180603027344\n",
      "epoch: 10  train_loss: 338.1318664550781\n",
      "epoch: 11  train_loss: 339.6825256347656\n",
      "epoch: 12  train_loss: 338.2113037109375\n",
      "epoch: 13  train_loss: 338.3124694824219\n",
      "epoch: 14  train_loss: 337.4046325683594\n",
      "epoch: 15  train_loss: 338.1555480957031\n",
      "epoch: 16  train_loss: 336.8291931152344\n",
      "epoch: 17  train_loss: 337.4896545410156\n",
      "epoch: 18  train_loss: 336.86688232421875\n",
      "epoch: 19  train_loss: 338.0745544433594\n",
      "epoch: 20  train_loss: 336.8587646484375\n",
      "epoch: 21  train_loss: 335.4654541015625\n",
      "epoch: 22  train_loss: 336.9027099609375\n",
      "epoch: 23  train_loss: 336.3321838378906\n",
      "epoch: 24  train_loss: 334.7947998046875\n",
      "epoch: 25  train_loss: 336.62176513671875\n",
      "epoch: 26  train_loss: 335.92120361328125\n",
      "epoch: 27  train_loss: 338.14666748046875\n",
      "epoch: 28  train_loss: 336.0420837402344\n",
      "epoch: 29  train_loss: 335.3155822753906\n",
      "epoch: 30  train_loss: 335.1312561035156\n",
      "epoch: 31  train_loss: 335.85882568359375\n",
      "epoch: 32  train_loss: 334.9044494628906\n",
      "epoch: 33  train_loss: 337.3675842285156\n",
      "epoch: 34  train_loss: 335.1722717285156\n",
      "epoch: 35  train_loss: 333.57281494140625\n",
      "epoch: 36  train_loss: 334.5837097167969\n",
      "epoch: 37  train_loss: 333.2995300292969\n",
      "epoch: 38  train_loss: 334.9867858886719\n",
      "epoch: 39  train_loss: 334.8080749511719\n",
      "epoch: 40  train_loss: 336.4569396972656\n",
      "epoch: 41  train_loss: 335.4389953613281\n",
      "epoch: 42  train_loss: 335.50616455078125\n",
      "epoch: 43  train_loss: 335.3683166503906\n",
      "epoch: 44  train_loss: 335.7657165527344\n",
      "epoch: 45  train_loss: 333.41339111328125\n",
      "epoch: 46  train_loss: 334.9801025390625\n",
      "epoch: 47  train_loss: 334.3040771484375\n",
      "epoch: 48  train_loss: 334.39398193359375\n",
      "epoch: 49  train_loss: 334.02386474609375\n",
      "epoch: 50  train_loss: 333.6698913574219\n",
      "epoch: 51  train_loss: 334.9115295410156\n",
      "epoch: 52  train_loss: 334.22613525390625\n",
      "epoch: 53  train_loss: 332.8502502441406\n",
      "epoch: 54  train_loss: 335.7306823730469\n",
      "epoch: 55  train_loss: 333.1338806152344\n",
      "epoch: 56  train_loss: 333.5560607910156\n",
      "epoch: 57  train_loss: 334.44287109375\n",
      "epoch: 58  train_loss: 333.7837829589844\n",
      "epoch: 59  train_loss: 333.17547607421875\n",
      "epoch: 60  train_loss: 334.0364685058594\n",
      "epoch: 61  train_loss: 333.756591796875\n",
      "epoch: 62  train_loss: 334.1019287109375\n",
      "epoch: 63  train_loss: 332.6269226074219\n",
      "epoch: 64  train_loss: 333.5177917480469\n",
      "epoch: 65  train_loss: 333.5545959472656\n",
      "epoch: 66  train_loss: 333.18524169921875\n",
      "epoch: 67  train_loss: 333.6539306640625\n",
      "epoch: 68  train_loss: 333.57861328125\n",
      "epoch: 69  train_loss: 332.0518493652344\n",
      "epoch: 70  train_loss: 333.3130798339844\n",
      "epoch: 71  train_loss: 334.06396484375\n",
      "epoch: 72  train_loss: 335.06280517578125\n",
      "epoch: 73  train_loss: 333.24365234375\n",
      "epoch: 74  train_loss: 333.06158447265625\n",
      "epoch: 75  train_loss: 332.6316833496094\n",
      "epoch: 76  train_loss: 331.4353942871094\n",
      "epoch: 77  train_loss: 334.1605224609375\n",
      "epoch: 78  train_loss: 332.55230712890625\n",
      "epoch: 79  train_loss: 333.0469665527344\n",
      "epoch: 80  train_loss: 333.7593994140625\n",
      "epoch: 81  train_loss: 332.55633544921875\n",
      "epoch: 82  train_loss: 332.8863830566406\n",
      "epoch: 83  train_loss: 332.0580749511719\n",
      "epoch: 84  train_loss: 332.9342041015625\n",
      "epoch: 85  train_loss: 332.4766540527344\n",
      "epoch: 86  train_loss: 332.9103088378906\n",
      "epoch: 87  train_loss: 334.3027648925781\n",
      "epoch: 88  train_loss: 331.4331359863281\n",
      "epoch: 89  train_loss: 333.0118408203125\n",
      "epoch: 90  train_loss: 333.8485412597656\n",
      "epoch: 91  train_loss: 333.09344482421875\n",
      "epoch: 92  train_loss: 334.1141052246094\n",
      "epoch: 93  train_loss: 332.4566650390625\n",
      "epoch: 94  train_loss: 334.1792907714844\n",
      "epoch: 95  train_loss: 333.43353271484375\n",
      "epoch: 96  train_loss: 332.6309509277344\n",
      "epoch: 97  train_loss: 332.0974426269531\n",
      "epoch: 98  train_loss: 331.76007080078125\n",
      "epoch: 99  train_loss: 333.4418029785156\n",
      "epoch: 100  train_loss: 332.2237548828125\n",
      "epoch: 101  train_loss: 332.63916015625\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "234958b5-a9bd-4a1a-b56a-edd8f2cbd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 404.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    212.501000          9.036044      0.002218\n",
      "std      74.800756          3.197487      0.000274\n",
      "min      46.000000          2.687708      0.001952\n",
      "25%     158.000000          6.733402      0.002059\n",
      "50%     204.500000          8.494876      0.002131\n",
      "75%     260.000000         11.273997      0.002267\n",
      "max     502.000000         20.109414      0.004355\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p in tqdm(p_test):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64737e09-1735-4893-a0d6-c8ca73a91fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
