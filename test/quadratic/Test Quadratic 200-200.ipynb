{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "num_var = 200     # number of variables\n",
    "num_ineq = 200    # number of constraints\n",
    "num_data = 10000  # number of data\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sample from uniform distribution\n",
    "b_samples = torch.from_numpy(np.random.uniform(-1, 1, size=(num_data, num_ineq))).float()\n",
    "data = {\"b\":b_samples}\n",
    "# data split\n",
    "from src.utlis import data_split\n",
    "data_train, data_test, data_dev = data_split(data, test_size=test_size, val_size=val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec0a67-54ea-4a9d-b037-0c7c9390e3f9",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50aaabd7-90ed-4628-a1da-c98777868d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msQuadratic\n",
    "model = msQuadratic(num_var, num_ineq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad38e16-1a87-4f11-92b4-b608f7f3ea11",
   "metadata": {},
   "source": [
    "## Heuristic - Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03328361-3f39-461d-ac81-40c8c14717bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heuristic import naive_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e57b62f-dfb4-4c87-b42e-e43b202ef96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▌                                                                           | 57/1000 [01:07<23:23,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▍                                                                     | 120/1000 [02:25<17:56,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▏                                                                 | 167/1000 [03:24<14:52,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▍                                                         | 271/1000 [05:28<13:08,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▌                                                    | 337/1000 [06:42<12:26,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▎                                                   | 345/1000 [06:53<14:15,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'obj' contains an\n",
      "uncopyable field '_init_sense' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▏                                                 | 369/1000 [07:25<13:30,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████▎                                | 586/1000 [12:00<08:18,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████▋                        | 693/1000 [14:10<05:48,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'OrderedScalarSet'\n",
      "contains an uncopyable field '_init_dimen' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████                        | 697/1000 [14:15<05:49,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to clone Pyomo component attribute. Component 'obj' contains an\n",
      "uncopyable field '_init_sense' (<class\n",
      "'pyomo.core.base.initializer.ConstantInitializer'>).  Setting field to `None`\n",
      "on new object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [20:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    -46.730136         16.508989      0.332651\n",
      "std       0.444228          2.188989      0.079426\n",
      "min     -47.932033          9.702206      0.272455\n",
      "25%     -47.025423         14.941754      0.293414\n",
      "50%     -46.752522         16.485873      0.307633\n",
      "75%     -46.441484         18.010361      0.346934\n",
      "max     -45.188960         24.531775      1.151797\n",
      "Number of infeasible solution: 1000\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # set params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # relax\n",
    "    model_rel = model.relax()\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval_rel, _ = model_rel.solve(\"gurobi\")\n",
    "    xval, objval = naive_round(xval_rel, model)\n",
    "    tock = time.time()\n",
    "    # eval\n",
    "    params.append(list(b))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_heur_rnd_200-200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eafc739-e145-4553-97cc-243934a569aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean   -46.726894         16.542221      0.328783\n",
      "std      0.469392          1.976129      0.063962\n",
      "min    -47.811411         11.747271      0.272783\n",
      "25%    -47.081983         15.132501      0.286565\n",
      "50%    -46.754793         16.507955      0.296470\n",
      "75%    -46.360496         17.777287      0.369865\n",
      "max    -45.698447         21.269113      0.697577\n",
      "Number of infeasible solution: 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_heur_rnd_200-200.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4fb3e2-9c47-4c10-8116-e94be18ea59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 512           # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=num_ineq+num_var, hidden_dims=[hsize]*hlayers_rnd, output_dim=num_var)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"b\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x_rnd\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 9256.08\n",
      "Epoch 1, Validation Loss: 5.83\n",
      "Epoch 2, Validation Loss: -6.76\n",
      "Epoch 3, Validation Loss: -10.87\n",
      "Epoch 4, Validation Loss: -14.71\n",
      "Epoch 5, Validation Loss: -16.20\n",
      "Epoch 6, Validation Loss: -19.37\n",
      "Epoch 7, Validation Loss: -19.62\n",
      "Epoch 8, Validation Loss: -21.89\n",
      "Epoch 9, Validation Loss: -21.39\n",
      "Epoch 10, Validation Loss: -22.98\n",
      "Epoch 11, Validation Loss: -23.98\n",
      "Epoch 12, Validation Loss: -23.43\n",
      "Epoch 13, Validation Loss: -24.29\n",
      "Epoch 14, Validation Loss: -25.07\n",
      "Epoch 15, Validation Loss: -23.75\n",
      "Epoch 16, Validation Loss: -24.17\n",
      "Epoch 17, Validation Loss: -21.96\n",
      "Epoch 18, Validation Loss: -26.21\n",
      "Epoch 19, Validation Loss: -27.79\n",
      "Epoch 20, Validation Loss: -26.54\n",
      "Epoch 21, Validation Loss: -26.27\n",
      "Epoch 22, Validation Loss: -26.40\n",
      "Epoch 23, Validation Loss: -27.66\n",
      "Epoch 24, Validation Loss: -22.84\n",
      "Epoch 25, Validation Loss: -29.50\n",
      "Epoch 26, Validation Loss: -26.94\n",
      "Epoch 27, Validation Loss: -27.53\n",
      "Epoch 28, Validation Loss: -28.32\n",
      "Epoch 29, Validation Loss: -28.92\n",
      "Epoch 30, Validation Loss: -18.01\n",
      "Epoch 31, Validation Loss: -28.56\n",
      "Epoch 32, Validation Loss: -28.38\n",
      "Epoch 33, Validation Loss: -27.75\n",
      "Epoch 34, Validation Loss: -29.18\n",
      "Epoch 35, Validation Loss: -27.20\n",
      "Epoch 36, Validation Loss: -28.60\n",
      "Epoch 37, Validation Loss: -26.64\n",
      "Epoch 38, Validation Loss: -27.37\n",
      "Epoch 39, Validation Loss: -25.79\n",
      "Epoch 40, Validation Loss: -29.70\n",
      "Epoch 41, Validation Loss: -27.94\n",
      "Epoch 42, Validation Loss: -27.08\n",
      "Epoch 43, Validation Loss: 53.28\n",
      "Epoch 44, Validation Loss: -27.99\n",
      "Epoch 45, Validation Loss: -28.80\n",
      "Epoch 46, Validation Loss: -29.76\n",
      "Epoch 47, Validation Loss: -27.27\n",
      "Epoch 48, Validation Loss: -28.80\n",
      "Epoch 49, Validation Loss: -22.04\n",
      "Epoch 50, Validation Loss: -25.17\n",
      "Epoch 51, Validation Loss: -25.83\n",
      "Epoch 52, Validation Loss: -27.77\n",
      "Epoch 53, Validation Loss: -28.49\n",
      "Epoch 54, Validation Loss: -29.33\n",
      "Epoch 55, Validation Loss: -30.00\n",
      "Epoch 56, Validation Loss: 70.49\n",
      "Epoch 57, Validation Loss: -29.82\n",
      "Epoch 58, Validation Loss: -25.66\n",
      "Epoch 59, Validation Loss: -28.89\n",
      "Epoch 60, Validation Loss: -27.99\n",
      "Epoch 61, Validation Loss: -28.61\n",
      "Epoch 62, Validation Loss: -28.13\n",
      "Epoch 63, Validation Loss: -30.66\n",
      "Epoch 64, Validation Loss: -30.64\n",
      "Epoch 65, Validation Loss: 18.07\n",
      "Epoch 66, Validation Loss: -30.47\n",
      "Epoch 67, Validation Loss: -30.37\n",
      "Epoch 68, Validation Loss: 118.04\n",
      "Epoch 69, Validation Loss: -29.21\n",
      "Epoch 70, Validation Loss: -29.26\n",
      "Epoch 71, Validation Loss: -29.24\n",
      "Epoch 72, Validation Loss: -29.30\n",
      "Epoch 73, Validation Loss: -24.55\n",
      "Epoch 74, Validation Loss: -26.21\n",
      "Epoch 75, Validation Loss: -24.89\n",
      "Epoch 76, Validation Loss: -26.68\n",
      "Epoch 77, Validation Loss: -29.67\n",
      "Epoch 78, Validation Loss: -27.45\n",
      "Epoch 79, Validation Loss: -30.97\n",
      "Epoch 80, Validation Loss: -30.68\n",
      "Epoch 81, Validation Loss: -29.97\n",
      "Epoch 82, Validation Loss: -29.24\n",
      "Epoch 83, Validation Loss: -30.22\n",
      "Epoch 84, Validation Loss: -29.28\n",
      "Epoch 85, Validation Loss: -29.87\n",
      "Epoch 86, Validation Loss: -30.51\n",
      "Epoch 87, Validation Loss: -18.24\n",
      "Epoch 88, Validation Loss: -30.17\n",
      "Epoch 89, Validation Loss: -29.57\n",
      "Epoch 90, Validation Loss: -15.01\n",
      "Epoch 91, Validation Loss: -28.43\n",
      "Epoch 92, Validation Loss: -30.11\n",
      "Epoch 93, Validation Loss: -30.42\n",
      "Epoch 94, Validation Loss: -29.20\n",
      "Epoch 95, Validation Loss: -30.71\n",
      "Epoch 96, Validation Loss: -25.90\n",
      "Epoch 97, Validation Loss: -29.65\n",
      "Epoch 98, Validation Loss: -30.06\n",
      "Early stopping at epoch 98\n",
      "Best model loaded.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:01<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    -31.209237          0.002694      0.004614\n",
      "std       0.196035          0.017749      0.002903\n",
      "min     -31.604665          0.000000      0.001510\n",
      "25%     -31.380844          0.000000      0.003013\n",
      "50%     -31.245468          0.000000      0.003568\n",
      "75%     -31.058942          0.000000      0.005091\n",
      "max     -30.328813          0.216221      0.022337\n",
      "Number of infeasible solution: 34\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_lr_200-200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "668a2a48-38e8-4ba7-a149-d7e4c23d8dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean   -31.205519          0.003159      0.004386\n",
      "std      0.182342          0.016189      0.002362\n",
      "min    -31.543232          0.000000      0.001999\n",
      "25%    -31.360568          0.000000      0.003041\n",
      "50%    -31.247028          0.000000      0.003819\n",
      "75%    -31.061275          0.000000      0.004726\n",
      "max    -30.772018          0.104523      0.018421\n",
      "Number of infeasible solution: 5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_lr_200-200.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c57dbb-8dee-4976-8922-82a155fe0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 512           # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=num_ineq+num_var, hidden_dims=[hsize]*hlayers_rnd, output_dim=num_var)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"b\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x_rnd\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 5004.20\n",
      "Epoch 1, Validation Loss: -3.16\n",
      "Epoch 2, Validation Loss: -11.43\n",
      "Epoch 3, Validation Loss: -17.06\n",
      "Epoch 4, Validation Loss: -16.42\n",
      "Epoch 5, Validation Loss: -20.27\n",
      "Epoch 6, Validation Loss: -20.50\n",
      "Epoch 7, Validation Loss: -22.01\n",
      "Epoch 8, Validation Loss: -22.74\n",
      "Epoch 9, Validation Loss: -22.62\n",
      "Epoch 10, Validation Loss: -20.28\n",
      "Epoch 11, Validation Loss: -24.87\n",
      "Epoch 12, Validation Loss: -23.98\n",
      "Epoch 13, Validation Loss: -25.92\n",
      "Epoch 14, Validation Loss: -22.53\n",
      "Epoch 15, Validation Loss: -26.84\n",
      "Epoch 16, Validation Loss: -24.07\n",
      "Epoch 17, Validation Loss: -25.55\n",
      "Epoch 18, Validation Loss: -23.60\n",
      "Epoch 19, Validation Loss: -27.41\n",
      "Epoch 20, Validation Loss: -27.43\n",
      "Epoch 21, Validation Loss: -27.05\n",
      "Epoch 22, Validation Loss: -26.44\n",
      "Epoch 23, Validation Loss: -28.29\n",
      "Epoch 24, Validation Loss: -18.29\n",
      "Epoch 25, Validation Loss: -28.14\n",
      "Epoch 26, Validation Loss: -26.29\n",
      "Epoch 27, Validation Loss: -27.45\n",
      "Epoch 28, Validation Loss: -25.93\n",
      "Epoch 29, Validation Loss: -27.47\n",
      "Epoch 30, Validation Loss: -27.30\n",
      "Epoch 31, Validation Loss: -27.29\n",
      "Epoch 32, Validation Loss: -27.33\n",
      "Epoch 33, Validation Loss: -27.58\n",
      "Epoch 34, Validation Loss: -28.05\n",
      "Epoch 35, Validation Loss: -28.16\n",
      "Epoch 36, Validation Loss: -25.81\n",
      "Epoch 37, Validation Loss: -24.68\n",
      "Epoch 38, Validation Loss: -29.11\n",
      "Epoch 39, Validation Loss: -29.58\n",
      "Epoch 40, Validation Loss: -23.81\n",
      "Epoch 41, Validation Loss: -25.83\n",
      "Epoch 42, Validation Loss: -27.90\n",
      "Epoch 43, Validation Loss: -29.75\n",
      "Epoch 44, Validation Loss: -28.97\n",
      "Epoch 45, Validation Loss: -27.95\n",
      "Epoch 46, Validation Loss: -29.77\n",
      "Epoch 47, Validation Loss: -27.40\n",
      "Epoch 48, Validation Loss: -27.78\n",
      "Epoch 49, Validation Loss: -25.24\n",
      "Epoch 50, Validation Loss: -30.14\n",
      "Epoch 51, Validation Loss: -28.60\n",
      "Epoch 52, Validation Loss: -27.53\n",
      "Epoch 53, Validation Loss: -28.45\n",
      "Epoch 54, Validation Loss: -29.18\n",
      "Epoch 55, Validation Loss: -25.64\n",
      "Epoch 56, Validation Loss: -29.26\n",
      "Epoch 57, Validation Loss: -27.76\n",
      "Epoch 58, Validation Loss: -27.86\n",
      "Epoch 59, Validation Loss: -25.31\n",
      "Epoch 60, Validation Loss: -29.38\n",
      "Epoch 61, Validation Loss: -29.86\n",
      "Epoch 62, Validation Loss: -8.03\n",
      "Epoch 63, Validation Loss: -21.79\n",
      "Epoch 64, Validation Loss: -8.83\n",
      "Epoch 65, Validation Loss: -29.11\n",
      "Epoch 66, Validation Loss: -27.57\n",
      "Epoch 67, Validation Loss: -27.55\n",
      "Epoch 68, Validation Loss: -30.34\n",
      "Epoch 69, Validation Loss: -30.96\n",
      "Epoch 70, Validation Loss: -30.38\n",
      "Epoch 71, Validation Loss: -28.46\n",
      "Epoch 72, Validation Loss: -28.82\n",
      "Epoch 73, Validation Loss: -27.98\n",
      "Epoch 74, Validation Loss: -26.25\n",
      "Epoch 75, Validation Loss: -30.22\n",
      "Epoch 76, Validation Loss: -29.49\n",
      "Epoch 77, Validation Loss: -30.32\n",
      "Epoch 78, Validation Loss: -30.33\n",
      "Epoch 79, Validation Loss: -25.85\n",
      "Epoch 80, Validation Loss: -25.02\n",
      "Epoch 81, Validation Loss: -27.02\n",
      "Epoch 82, Validation Loss: -29.59\n",
      "Epoch 83, Validation Loss: -30.46\n",
      "Epoch 84, Validation Loss: -15.64\n",
      "Epoch 85, Validation Loss: -8.98\n",
      "Epoch 86, Validation Loss: -27.37\n",
      "Epoch 87, Validation Loss: -30.56\n",
      "Epoch 88, Validation Loss: -28.09\n",
      "Early stopping at epoch 88\n",
      "Best model loaded.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:06<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    -31.254160          0.006354      0.004673\n",
      "std       0.338234          0.043944      0.003048\n",
      "min     -31.775507          0.000000      0.001505\n",
      "25%     -31.506309          0.000000      0.003040\n",
      "50%     -31.313588          0.000000      0.003758\n",
      "75%     -31.041621          0.000000      0.005000\n",
      "max     -28.240721          0.584146      0.033856\n",
      "Number of infeasible solution: 38\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_lt_200-200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d16e65ff-2224-4428-8868-d625db48e519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean   -31.260533          0.003983      0.004528\n",
      "std      0.319193          0.039827      0.002572\n",
      "min    -31.760595          0.000000      0.002011\n",
      "25%    -31.516941          0.000000      0.003405\n",
      "50%    -31.319818          0.000000      0.004036\n",
      "75%    -31.048672          0.000000      0.004585\n",
      "max    -30.137631          0.398268      0.020412\n",
      "Number of infeasible solution: 1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_lt_200-200.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75bca80-07e7-43d7-908a-0a049dc231fc",
   "metadata": {},
   "source": [
    "### Parametric Learning Then Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382a0a8a-d846-4182-ab69-7d618edea9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5921542-01cb-4a95-9280-d09427f1870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hsize = 512           # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f743840a-d9d0-472f-b74a-7a026fff1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94010bd1-5d1b-485b-86c7-b90641cbfe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 5051.07\n",
      "Epoch 1, Validation Loss: -7.04\n",
      "Epoch 2, Validation Loss: -14.87\n",
      "Epoch 3, Validation Loss: -21.93\n",
      "Epoch 4, Validation Loss: -25.11\n",
      "Epoch 5, Validation Loss: -26.60\n",
      "Epoch 6, Validation Loss: -29.16\n",
      "Epoch 7, Validation Loss: -29.11\n",
      "Epoch 8, Validation Loss: -29.42\n",
      "Epoch 9, Validation Loss: -30.08\n",
      "Epoch 10, Validation Loss: -29.61\n",
      "Epoch 11, Validation Loss: -30.43\n",
      "Epoch 12, Validation Loss: -31.61\n",
      "Epoch 13, Validation Loss: -31.18\n",
      "Epoch 14, Validation Loss: -31.79\n",
      "Epoch 15, Validation Loss: -32.95\n",
      "Epoch 16, Validation Loss: -32.41\n",
      "Epoch 17, Validation Loss: -32.69\n",
      "Epoch 18, Validation Loss: -32.00\n",
      "Epoch 19, Validation Loss: -32.62\n",
      "Epoch 20, Validation Loss: -33.67\n",
      "Epoch 21, Validation Loss: -33.64\n",
      "Epoch 22, Validation Loss: -33.68\n",
      "Epoch 23, Validation Loss: -33.38\n",
      "Epoch 24, Validation Loss: -34.01\n",
      "Epoch 25, Validation Loss: -33.54\n",
      "Epoch 26, Validation Loss: -33.87\n",
      "Epoch 27, Validation Loss: -33.60\n",
      "Epoch 28, Validation Loss: -33.47\n",
      "Epoch 29, Validation Loss: -33.61\n",
      "Epoch 30, Validation Loss: -34.54\n",
      "Epoch 31, Validation Loss: -35.05\n",
      "Epoch 32, Validation Loss: -34.28\n",
      "Epoch 33, Validation Loss: -33.46\n",
      "Epoch 34, Validation Loss: -34.86\n",
      "Epoch 35, Validation Loss: -34.89\n",
      "Epoch 36, Validation Loss: -34.45\n",
      "Epoch 37, Validation Loss: -35.66\n",
      "Epoch 38, Validation Loss: -34.49\n",
      "Epoch 39, Validation Loss: -33.79\n",
      "Epoch 40, Validation Loss: -33.74\n",
      "Epoch 41, Validation Loss: -35.06\n",
      "Epoch 42, Validation Loss: -35.69\n",
      "Epoch 43, Validation Loss: -35.81\n",
      "Epoch 44, Validation Loss: -35.82\n",
      "Epoch 45, Validation Loss: -35.58\n",
      "Epoch 46, Validation Loss: -34.86\n",
      "Epoch 47, Validation Loss: -35.57\n",
      "Epoch 48, Validation Loss: -35.94\n",
      "Epoch 49, Validation Loss: -35.90\n",
      "Epoch 50, Validation Loss: -35.62\n",
      "Epoch 51, Validation Loss: -36.10\n",
      "Epoch 52, Validation Loss: -34.87\n",
      "Epoch 53, Validation Loss: -36.08\n",
      "Epoch 54, Validation Loss: -36.38\n",
      "Epoch 55, Validation Loss: -35.29\n",
      "Epoch 56, Validation Loss: -36.54\n",
      "Epoch 57, Validation Loss: -35.11\n",
      "Epoch 58, Validation Loss: -36.42\n",
      "Epoch 59, Validation Loss: -36.48\n",
      "Epoch 60, Validation Loss: -36.23\n",
      "Epoch 61, Validation Loss: -35.66\n",
      "Epoch 62, Validation Loss: -36.10\n",
      "Epoch 63, Validation Loss: -36.19\n",
      "Epoch 64, Validation Loss: -36.11\n",
      "Epoch 65, Validation Loss: -36.51\n",
      "Epoch 66, Validation Loss: -36.40\n",
      "Epoch 67, Validation Loss: -36.06\n",
      "Epoch 68, Validation Loss: -36.56\n",
      "Epoch 69, Validation Loss: -35.90\n",
      "Epoch 70, Validation Loss: -36.52\n",
      "Epoch 71, Validation Loss: -36.72\n",
      "Epoch 72, Validation Loss: -36.46\n",
      "Epoch 73, Validation Loss: -36.39\n",
      "Epoch 74, Validation Loss: -36.26\n",
      "Epoch 75, Validation Loss: -36.59\n",
      "Epoch 76, Validation Loss: -36.30\n",
      "Epoch 77, Validation Loss: -36.53\n",
      "Epoch 78, Validation Loss: -37.07\n",
      "Epoch 79, Validation Loss: -37.09\n",
      "Epoch 80, Validation Loss: -36.30\n",
      "Epoch 81, Validation Loss: -36.94\n",
      "Epoch 82, Validation Loss: -36.67\n",
      "Epoch 83, Validation Loss: -36.22\n",
      "Epoch 84, Validation Loss: -36.62\n",
      "Epoch 85, Validation Loss: -37.14\n",
      "Epoch 86, Validation Loss: -36.88\n",
      "Epoch 87, Validation Loss: -36.71\n",
      "Epoch 88, Validation Loss: -36.88\n",
      "Epoch 89, Validation Loss: -37.52\n",
      "Epoch 90, Validation Loss: -36.93\n",
      "Epoch 91, Validation Loss: -36.77\n",
      "Epoch 92, Validation Loss: -36.64\n",
      "Epoch 93, Validation Loss: -37.41\n",
      "Epoch 94, Validation Loss: -36.83\n",
      "Epoch 95, Validation Loss: -36.57\n",
      "Epoch 96, Validation Loss: -37.65\n",
      "Epoch 97, Validation Loss: -37.24\n",
      "Epoch 98, Validation Loss: -37.50\n",
      "Epoch 99, Validation Loss: -37.05\n",
      "Epoch 100, Validation Loss: -36.77\n",
      "Epoch 101, Validation Loss: -37.61\n",
      "Epoch 102, Validation Loss: -37.33\n",
      "Epoch 103, Validation Loss: -36.24\n",
      "Epoch 104, Validation Loss: -37.03\n",
      "Epoch 105, Validation Loss: -37.22\n",
      "Epoch 106, Validation Loss: -37.41\n",
      "Epoch 107, Validation Loss: -37.32\n",
      "Epoch 108, Validation Loss: -37.51\n",
      "Epoch 109, Validation Loss: -37.17\n",
      "Epoch 110, Validation Loss: -37.38\n",
      "Epoch 111, Validation Loss: -37.38\n",
      "Epoch 112, Validation Loss: -37.53\n",
      "Epoch 113, Validation Loss: -37.53\n",
      "Epoch 114, Validation Loss: -37.41\n",
      "Epoch 115, Validation Loss: -37.76\n",
      "Epoch 116, Validation Loss: -37.43\n",
      "Epoch 117, Validation Loss: -37.56\n",
      "Epoch 118, Validation Loss: -37.32\n",
      "Epoch 119, Validation Loss: -37.67\n",
      "Epoch 120, Validation Loss: -37.26\n",
      "Epoch 121, Validation Loss: -37.42\n",
      "Epoch 122, Validation Loss: -37.33\n",
      "Epoch 123, Validation Loss: -36.69\n",
      "Epoch 124, Validation Loss: -37.16\n",
      "Epoch 125, Validation Loss: -37.52\n",
      "Epoch 126, Validation Loss: -37.29\n",
      "Epoch 127, Validation Loss: -37.39\n",
      "Epoch 128, Validation Loss: -37.06\n",
      "Epoch 129, Validation Loss: -37.36\n",
      "Epoch 130, Validation Loss: -37.71\n",
      "Epoch 131, Validation Loss: -37.73\n",
      "Epoch 132, Validation Loss: -37.51\n",
      "Epoch 133, Validation Loss: -37.37\n",
      "Epoch 134, Validation Loss: -37.07\n",
      "Early stopping at epoch 134\n",
      "Best model loaded.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345cb316-9f5d-494a-9d41-a01711e8d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:01<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+03       1000.000000   1000.000000\n",
      "mean  -3.776084e+01          0.535398      0.000840\n",
      "std    6.753534e-13          0.356764      0.000506\n",
      "min   -3.776084e+01          0.000000      0.000000\n",
      "25%   -3.776084e+01          0.256559      0.000513\n",
      "50%   -3.776084e+01          0.489904      0.001001\n",
      "75%   -3.776084e+01          0.777848      0.001010\n",
      "max   -3.776084e+01          1.723091      0.002929\n",
      "Number of infeasible solution: 975\n"
     ]
    }
   ],
   "source": [
    "from src.heuristic import naive_round\n",
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval_rel, _ = model.get_val()\n",
    "    xval, objval = naive_round(xval_rel, model)\n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_pr_200-200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8b5acf-f3c0-4bea-bb66-83c8a7751b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+02        100.000000    100.000000\n",
      "mean  -3.776084e+01          0.531382      0.000896\n",
      "std    4.284734e-14          0.338466      0.000495\n",
      "min   -3.776084e+01          0.000000      0.000000\n",
      "25%   -3.776084e+01          0.321623      0.000998\n",
      "50%   -3.776084e+01          0.488768      0.001002\n",
      "75%   -3.776084e+01          0.699078      0.001010\n",
      "max   -3.776084e+01          1.399221      0.002000\n",
      "Number of infeasible solution: 95\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_pr_200-200.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef73c6-6097-47e8-9a38-aeff1a97d014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
