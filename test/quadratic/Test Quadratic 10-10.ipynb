{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "num_var = 10      # number of variables\n",
    "num_ineq = 10     # number of constraints\n",
    "num_data = 10000  # number of data\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sample from uniform distribution\n",
    "b_samples = torch.from_numpy(np.random.uniform(-1, 1, size=(num_data, num_ineq))).float()\n",
    "data = {\"b\":b_samples}\n",
    "# data split\n",
    "from src.utlis import data_split\n",
    "data_train, data_test, data_dev = data_split(data, test_size=test_size, val_size=val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec0a67-54ea-4a9d-b037-0c7c9390e3f9",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50aaabd7-90ed-4628-a1da-c98777868d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msQuadratic\n",
    "model = msQuadratic(num_var, num_ineq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8d0f11-7ad1-4886-a76d-430189d06c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [03:27<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000            1000.0   1000.000000\n",
      "mean     -2.752972               0.0      0.206351\n",
      "std       1.233259               0.0      0.020654\n",
      "min      -5.254417               0.0      0.153796\n",
      "25%      -3.663621               0.0      0.198585\n",
      "50%      -2.827983               0.0      0.201521\n",
      "75%      -1.934024               0.0      0.216266\n",
      "max       1.447501               0.0      0.324365\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # set params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval, objval = model.solve(\"gurobi\")\n",
    "    tock = time.time()\n",
    "    # eval\n",
    "    params.append(list(b))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_exact_10-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c9bf5a-439a-408e-97f0-0b07c58bea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000             100.0    100.000000\n",
      "mean    -2.778616               0.0      0.199638\n",
      "std      1.399711               0.0      0.013954\n",
      "min     -5.245462               0.0      0.167444\n",
      "25%     -3.973540               0.0      0.198235\n",
      "50%     -2.990693               0.0      0.200515\n",
      "75%     -1.839966               0.0      0.202987\n",
      "max      1.447501               0.0      0.263747\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_exact_10-10.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad38e16-1a87-4f11-92b4-b608f7f3ea11",
   "metadata": {},
   "source": [
    "## Heuristic - Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03328361-3f39-461d-ac81-40c8c14717bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heuristic import naive_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e57b62f-dfb4-4c87-b42e-e43b202ef96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:25<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean     -2.831070          0.177637      0.137060\n",
      "std       1.211896          0.087335      0.018610\n",
      "min      -5.315227          0.000000      0.115648\n",
      "25%      -3.743787          0.113057      0.131130\n",
      "50%      -2.897332          0.165136      0.132988\n",
      "75%      -2.035999          0.227713      0.135511\n",
      "max       1.287201          0.487457      0.347112\n",
      "Number of infeasible solution: 999\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # set params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # relax\n",
    "    model_rel = model.relax()\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval_rel, _ = model_rel.solve(\"gurobi\")\n",
    "    xval, objval = naive_round(xval_rel, model)\n",
    "    tock = time.time()\n",
    "    # eval\n",
    "    params.append(list(b))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_heur_rnd_10-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c956d49c-2d19-4589-b3e4-a45e903a852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean    -2.857766          0.184249      0.139806\n",
      "std      1.380641          0.095250      0.015732\n",
      "min     -5.295697          0.016281      0.118579\n",
      "25%     -4.053361          0.114362      0.132154\n",
      "50%     -3.033066          0.162895      0.133319\n",
      "75%     -1.992545          0.255210      0.143576\n",
      "max      1.287201          0.403525      0.201784\n",
      "Number of infeasible solution: 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_heur_rnd_10-10.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96304fbd-08f5-4be7-a81e-83c85332029c",
   "metadata": {},
   "source": [
    "## Heuristic - N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "356187af-e02d-4478-bf78-ada6a2e1b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_heur = model.first_solution_heuristic(nodes_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c7fc52-cbbc-4414-bf1d-316d65c8db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:19<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+03            1000.0   1000.000000\n",
      "mean   1.289597e+15               0.0      0.138138\n",
      "std    5.794443e+15               0.0      0.043513\n",
      "min   -5.159240e+00               0.0      0.119536\n",
      "25%   -3.066814e+00               0.0      0.123953\n",
      "50%   -2.032727e+00               0.0      0.137413\n",
      "75%    2.832876e+00               0.0      0.139122\n",
      "max    4.525135e+16               0.0      0.901425\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"]):\n",
    "    # set params\n",
    "    model_heur.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval, objval = model_heur.solve(\"gurobi\")\n",
    "    tock = time.time()\n",
    "    # eval\n",
    "    params.append(list(b))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model_heur.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_heur_n1_10-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee15718-e299-4111-a775-a0ab9b5e3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+02             100.0    100.000000\n",
      "mean   1.219108e+15               0.0      0.132198\n",
      "std    5.757495e+15               0.0      0.009339\n",
      "min   -4.765557e+00               0.0      0.120835\n",
      "25%   -3.147985e+00               0.0      0.123503\n",
      "50%   -1.900374e+00               0.0      0.136191\n",
      "75%    5.268976e+00               0.0      0.138600\n",
      "max    3.688209e+16               0.0      0.168422\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/cq_heur_n1_10-10.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4fb3e2-9c47-4c10-8116-e94be18ea59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 32            # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=num_ineq+num_var, hidden_dims=[hsize]*hlayers_rnd, output_dim=num_var)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"b\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x_rnd\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 248.32\n",
      "Epoch 1, Validation Loss: 83.96\n",
      "Epoch 2, Validation Loss: 11.49\n",
      "Epoch 3, Validation Loss: 5.05\n",
      "Epoch 4, Validation Loss: 4.89\n",
      "Epoch 5, Validation Loss: 3.85\n",
      "Epoch 6, Validation Loss: 3.27\n",
      "Epoch 7, Validation Loss: 4.43\n",
      "Epoch 8, Validation Loss: 3.47\n",
      "Epoch 9, Validation Loss: 1.81\n",
      "Epoch 10, Validation Loss: 1.56\n",
      "Epoch 11, Validation Loss: 1.02\n",
      "Epoch 12, Validation Loss: 1.08\n",
      "Epoch 13, Validation Loss: 0.71\n",
      "Epoch 14, Validation Loss: 1.40\n",
      "Epoch 15, Validation Loss: 1.11\n",
      "Epoch 16, Validation Loss: 0.40\n",
      "Epoch 17, Validation Loss: 0.40\n",
      "Epoch 18, Validation Loss: 0.41\n",
      "Epoch 19, Validation Loss: 1.19\n",
      "Epoch 20, Validation Loss: 0.74\n",
      "Epoch 21, Validation Loss: 0.75\n",
      "Epoch 22, Validation Loss: 0.37\n",
      "Epoch 23, Validation Loss: -0.17\n",
      "Epoch 24, Validation Loss: -0.30\n",
      "Epoch 25, Validation Loss: -0.20\n",
      "Epoch 26, Validation Loss: -0.52\n",
      "Epoch 27, Validation Loss: -0.38\n",
      "Epoch 28, Validation Loss: -0.32\n",
      "Epoch 29, Validation Loss: -0.56\n",
      "Epoch 30, Validation Loss: -0.59\n",
      "Epoch 31, Validation Loss: -0.36\n",
      "Epoch 32, Validation Loss: -0.37\n",
      "Epoch 33, Validation Loss: -0.66\n",
      "Epoch 34, Validation Loss: -0.58\n",
      "Epoch 35, Validation Loss: -0.11\n",
      "Epoch 36, Validation Loss: -0.76\n",
      "Epoch 37, Validation Loss: -0.46\n",
      "Epoch 38, Validation Loss: -0.67\n",
      "Epoch 39, Validation Loss: -0.74\n",
      "Epoch 40, Validation Loss: -0.63\n",
      "Epoch 41, Validation Loss: -0.81\n",
      "Epoch 42, Validation Loss: -0.79\n",
      "Epoch 43, Validation Loss: -0.85\n",
      "Epoch 44, Validation Loss: -0.83\n",
      "Epoch 45, Validation Loss: -0.98\n",
      "Epoch 46, Validation Loss: -0.78\n",
      "Epoch 47, Validation Loss: -0.68\n",
      "Epoch 48, Validation Loss: -0.78\n",
      "Epoch 49, Validation Loss: -0.93\n",
      "Epoch 50, Validation Loss: -0.92\n",
      "Epoch 51, Validation Loss: -0.77\n",
      "Epoch 52, Validation Loss: -0.90\n",
      "Epoch 53, Validation Loss: -0.97\n",
      "Epoch 54, Validation Loss: -0.88\n",
      "Epoch 55, Validation Loss: -0.95\n",
      "Epoch 56, Validation Loss: -1.07\n",
      "Epoch 57, Validation Loss: -1.05\n",
      "Epoch 58, Validation Loss: -1.05\n",
      "Epoch 59, Validation Loss: -1.05\n",
      "Epoch 60, Validation Loss: -1.09\n",
      "Epoch 61, Validation Loss: -1.04\n",
      "Epoch 62, Validation Loss: -0.87\n",
      "Epoch 63, Validation Loss: -0.62\n",
      "Epoch 64, Validation Loss: -1.01\n",
      "Epoch 65, Validation Loss: -1.03\n",
      "Epoch 66, Validation Loss: -1.16\n",
      "Epoch 67, Validation Loss: -1.04\n",
      "Epoch 68, Validation Loss: -1.09\n",
      "Epoch 69, Validation Loss: -1.05\n",
      "Epoch 70, Validation Loss: -1.22\n",
      "Epoch 71, Validation Loss: -1.13\n",
      "Epoch 72, Validation Loss: -1.29\n",
      "Epoch 73, Validation Loss: -1.30\n",
      "Epoch 74, Validation Loss: -0.97\n",
      "Epoch 75, Validation Loss: -1.18\n",
      "Epoch 76, Validation Loss: -1.32\n",
      "Epoch 77, Validation Loss: -1.24\n",
      "Epoch 78, Validation Loss: -1.17\n",
      "Epoch 79, Validation Loss: -0.83\n",
      "Epoch 80, Validation Loss: -1.02\n",
      "Epoch 81, Validation Loss: -1.31\n",
      "Epoch 82, Validation Loss: -1.25\n",
      "Epoch 83, Validation Loss: -1.29\n",
      "Epoch 84, Validation Loss: -1.27\n",
      "Epoch 85, Validation Loss: -1.30\n",
      "Epoch 86, Validation Loss: -0.91\n",
      "Epoch 87, Validation Loss: -1.32\n",
      "Epoch 88, Validation Loss: -1.41\n",
      "Epoch 89, Validation Loss: -1.35\n",
      "Epoch 90, Validation Loss: -1.33\n",
      "Epoch 91, Validation Loss: -1.24\n",
      "Epoch 92, Validation Loss: -1.46\n",
      "Epoch 93, Validation Loss: -1.35\n",
      "Epoch 94, Validation Loss: -0.96\n",
      "Epoch 95, Validation Loss: -1.39\n",
      "Epoch 96, Validation Loss: -1.00\n",
      "Epoch 97, Validation Loss: -1.46\n",
      "Epoch 98, Validation Loss: -1.47\n",
      "Epoch 99, Validation Loss: -1.47\n",
      "Epoch 100, Validation Loss: -1.43\n",
      "Epoch 101, Validation Loss: -1.49\n",
      "Epoch 102, Validation Loss: -1.37\n",
      "Epoch 103, Validation Loss: -1.43\n",
      "Epoch 104, Validation Loss: -1.10\n",
      "Epoch 105, Validation Loss: -1.41\n",
      "Epoch 106, Validation Loss: -1.52\n",
      "Epoch 107, Validation Loss: -1.27\n",
      "Epoch 108, Validation Loss: -1.27\n",
      "Epoch 109, Validation Loss: -1.35\n",
      "Epoch 110, Validation Loss: -1.29\n",
      "Epoch 111, Validation Loss: -1.33\n",
      "Epoch 112, Validation Loss: -1.38\n",
      "Epoch 113, Validation Loss: -1.51\n",
      "Epoch 114, Validation Loss: -1.45\n",
      "Epoch 115, Validation Loss: -1.48\n",
      "Epoch 116, Validation Loss: -1.18\n",
      "Epoch 117, Validation Loss: -1.41\n",
      "Epoch 118, Validation Loss: -1.48\n",
      "Epoch 119, Validation Loss: -1.49\n",
      "Epoch 120, Validation Loss: -1.57\n",
      "Epoch 121, Validation Loss: -1.24\n",
      "Epoch 122, Validation Loss: -1.48\n",
      "Epoch 123, Validation Loss: -1.40\n",
      "Epoch 124, Validation Loss: -1.49\n",
      "Epoch 125, Validation Loss: -1.49\n",
      "Epoch 126, Validation Loss: -1.54\n",
      "Epoch 127, Validation Loss: -1.46\n",
      "Epoch 128, Validation Loss: -1.58\n",
      "Epoch 129, Validation Loss: -1.23\n",
      "Epoch 130, Validation Loss: -1.52\n",
      "Epoch 131, Validation Loss: -1.31\n",
      "Epoch 132, Validation Loss: -1.33\n",
      "Epoch 133, Validation Loss: -1.40\n",
      "Epoch 134, Validation Loss: -1.39\n",
      "Epoch 135, Validation Loss: -1.46\n",
      "Epoch 136, Validation Loss: -1.55\n",
      "Epoch 137, Validation Loss: -1.47\n",
      "Epoch 138, Validation Loss: -0.95\n",
      "Epoch 139, Validation Loss: -1.50\n",
      "Epoch 140, Validation Loss: -1.57\n",
      "Epoch 141, Validation Loss: -1.47\n",
      "Epoch 142, Validation Loss: -1.53\n",
      "Epoch 143, Validation Loss: -1.50\n",
      "Epoch 144, Validation Loss: -1.36\n",
      "Epoch 145, Validation Loss: -1.51\n",
      "Epoch 146, Validation Loss: -1.49\n",
      "Epoch 147, Validation Loss: -1.36\n",
      "Early stopping at epoch 147\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 213.53 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 203.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean    -1.602293          0.000358      0.003116\n",
      "std      1.672147          0.002678      0.001334\n",
      "min     -4.187225          0.000000      0.001228\n",
      "25%     -2.992502          0.000000      0.002016\n",
      "50%     -1.999704          0.000000      0.002888\n",
      "75%     -0.622180          0.000000      0.003527\n",
      "max      3.252418          0.024279      0.008123\n",
      "Number of infeasible solution: 2\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"][:100]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_lr_10-10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c57dbb-8dee-4976-8922-82a155fe0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 32            # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=num_ineq+num_var, hidden_dims=[hsize]*hlayers_rnd, output_dim=num_var)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"b\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x_rnd\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 253.56\n",
      "Epoch 1, Validation Loss: 89.36\n",
      "Epoch 2, Validation Loss: 5.90\n",
      "Epoch 3, Validation Loss: 3.70\n",
      "Epoch 4, Validation Loss: 3.06\n",
      "Epoch 5, Validation Loss: 3.05\n",
      "Epoch 6, Validation Loss: 2.70\n",
      "Epoch 7, Validation Loss: 1.97\n",
      "Epoch 8, Validation Loss: 1.86\n",
      "Epoch 9, Validation Loss: 2.75\n",
      "Epoch 10, Validation Loss: 1.65\n",
      "Epoch 11, Validation Loss: 2.01\n",
      "Epoch 12, Validation Loss: 2.18\n",
      "Epoch 13, Validation Loss: 1.67\n",
      "Epoch 14, Validation Loss: 1.23\n",
      "Epoch 15, Validation Loss: 1.69\n",
      "Epoch 16, Validation Loss: 1.98\n",
      "Epoch 17, Validation Loss: 1.31\n",
      "Epoch 18, Validation Loss: 0.96\n",
      "Epoch 19, Validation Loss: 0.88\n",
      "Epoch 20, Validation Loss: 0.56\n",
      "Epoch 21, Validation Loss: 0.37\n",
      "Epoch 22, Validation Loss: 0.70\n",
      "Epoch 23, Validation Loss: -0.06\n",
      "Epoch 24, Validation Loss: 0.32\n",
      "Epoch 25, Validation Loss: 0.33\n",
      "Epoch 26, Validation Loss: -0.16\n",
      "Epoch 27, Validation Loss: -0.37\n",
      "Epoch 28, Validation Loss: -0.51\n",
      "Epoch 29, Validation Loss: -0.51\n",
      "Epoch 30, Validation Loss: -0.20\n",
      "Epoch 31, Validation Loss: -0.44\n",
      "Epoch 32, Validation Loss: -0.49\n",
      "Epoch 33, Validation Loss: -0.47\n",
      "Epoch 34, Validation Loss: -0.70\n",
      "Epoch 35, Validation Loss: -0.78\n",
      "Epoch 36, Validation Loss: -0.68\n",
      "Epoch 37, Validation Loss: -0.62\n",
      "Epoch 38, Validation Loss: -0.58\n",
      "Epoch 39, Validation Loss: -0.21\n",
      "Epoch 40, Validation Loss: -0.94\n",
      "Epoch 41, Validation Loss: -0.82\n",
      "Epoch 42, Validation Loss: -0.86\n",
      "Epoch 43, Validation Loss: -0.92\n",
      "Epoch 44, Validation Loss: -0.94\n",
      "Epoch 45, Validation Loss: -0.82\n",
      "Epoch 46, Validation Loss: -0.91\n",
      "Epoch 47, Validation Loss: -0.87\n",
      "Epoch 48, Validation Loss: -1.05\n",
      "Epoch 49, Validation Loss: -1.16\n",
      "Epoch 50, Validation Loss: -1.18\n",
      "Epoch 51, Validation Loss: -0.78\n",
      "Epoch 52, Validation Loss: -1.14\n",
      "Epoch 53, Validation Loss: -1.24\n",
      "Epoch 54, Validation Loss: -1.15\n",
      "Epoch 55, Validation Loss: -1.32\n",
      "Epoch 56, Validation Loss: -1.22\n",
      "Epoch 57, Validation Loss: -1.19\n",
      "Epoch 58, Validation Loss: -1.38\n",
      "Epoch 59, Validation Loss: -1.46\n",
      "Epoch 60, Validation Loss: -1.18\n",
      "Epoch 61, Validation Loss: -1.40\n",
      "Epoch 62, Validation Loss: -1.42\n",
      "Epoch 63, Validation Loss: -1.43\n",
      "Epoch 64, Validation Loss: -1.38\n",
      "Epoch 65, Validation Loss: -1.32\n",
      "Epoch 66, Validation Loss: -1.53\n",
      "Epoch 67, Validation Loss: -1.51\n",
      "Epoch 68, Validation Loss: -1.34\n",
      "Epoch 69, Validation Loss: -1.48\n",
      "Epoch 70, Validation Loss: -1.41\n",
      "Epoch 71, Validation Loss: -1.48\n",
      "Epoch 72, Validation Loss: -1.42\n",
      "Epoch 73, Validation Loss: -1.42\n",
      "Epoch 74, Validation Loss: -1.45\n",
      "Epoch 75, Validation Loss: -1.45\n",
      "Epoch 76, Validation Loss: -1.43\n",
      "Epoch 77, Validation Loss: -1.54\n",
      "Epoch 78, Validation Loss: -1.42\n",
      "Epoch 79, Validation Loss: -1.44\n",
      "Epoch 80, Validation Loss: -1.45\n",
      "Epoch 81, Validation Loss: -1.40\n",
      "Epoch 82, Validation Loss: -1.49\n",
      "Epoch 83, Validation Loss: -1.41\n",
      "Epoch 84, Validation Loss: -1.48\n",
      "Epoch 85, Validation Loss: -1.35\n",
      "Epoch 86, Validation Loss: -1.51\n",
      "Epoch 87, Validation Loss: -1.31\n",
      "Epoch 88, Validation Loss: -1.51\n",
      "Epoch 89, Validation Loss: -1.31\n",
      "Epoch 90, Validation Loss: -1.49\n",
      "Epoch 91, Validation Loss: -1.47\n",
      "Epoch 92, Validation Loss: -1.46\n",
      "Epoch 93, Validation Loss: -1.43\n",
      "Epoch 94, Validation Loss: -1.38\n",
      "Epoch 95, Validation Loss: -1.60\n",
      "Epoch 96, Validation Loss: -1.47\n",
      "Epoch 97, Validation Loss: -1.39\n",
      "Epoch 98, Validation Loss: -1.54\n",
      "Epoch 99, Validation Loss: -1.52\n",
      "Epoch 100, Validation Loss: -1.60\n",
      "Epoch 101, Validation Loss: -1.25\n",
      "Epoch 102, Validation Loss: -1.46\n",
      "Epoch 103, Validation Loss: -1.50\n",
      "Epoch 104, Validation Loss: -1.57\n",
      "Epoch 105, Validation Loss: -1.42\n",
      "Epoch 106, Validation Loss: -1.53\n",
      "Epoch 107, Validation Loss: -1.35\n",
      "Epoch 108, Validation Loss: -1.59\n",
      "Epoch 109, Validation Loss: -1.66\n",
      "Epoch 110, Validation Loss: -1.47\n",
      "Epoch 111, Validation Loss: -1.57\n",
      "Epoch 112, Validation Loss: -1.51\n",
      "Epoch 113, Validation Loss: -1.47\n",
      "Epoch 114, Validation Loss: -1.43\n",
      "Epoch 115, Validation Loss: -1.43\n",
      "Epoch 116, Validation Loss: -1.50\n",
      "Epoch 117, Validation Loss: -1.50\n",
      "Epoch 118, Validation Loss: -1.54\n",
      "Epoch 119, Validation Loss: -1.34\n",
      "Epoch 120, Validation Loss: -1.64\n",
      "Epoch 121, Validation Loss: -1.54\n",
      "Epoch 122, Validation Loss: -1.48\n",
      "Epoch 123, Validation Loss: -1.35\n",
      "Epoch 124, Validation Loss: -1.60\n",
      "Epoch 125, Validation Loss: -1.58\n",
      "Epoch 126, Validation Loss: -1.56\n",
      "Epoch 127, Validation Loss: -1.29\n",
      "Epoch 128, Validation Loss: -1.67\n",
      "Epoch 129, Validation Loss: -1.61\n",
      "Epoch 130, Validation Loss: -1.65\n",
      "Epoch 131, Validation Loss: -1.53\n",
      "Epoch 132, Validation Loss: -1.59\n",
      "Epoch 133, Validation Loss: -1.43\n",
      "Epoch 134, Validation Loss: -1.59\n",
      "Epoch 135, Validation Loss: -1.60\n",
      "Epoch 136, Validation Loss: -1.46\n",
      "Epoch 137, Validation Loss: -1.50\n",
      "Epoch 138, Validation Loss: -1.58\n",
      "Epoch 139, Validation Loss: -1.54\n",
      "Epoch 140, Validation Loss: -1.66\n",
      "Epoch 141, Validation Loss: -1.58\n",
      "Epoch 142, Validation Loss: -0.93\n",
      "Epoch 143, Validation Loss: -1.53\n",
      "Epoch 144, Validation Loss: -1.58\n",
      "Epoch 145, Validation Loss: -1.28\n",
      "Epoch 146, Validation Loss: -1.59\n",
      "Epoch 147, Validation Loss: -1.52\n",
      "Early stopping at epoch 147\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 225.38 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 210.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean    -1.817698          0.001271      0.003038\n",
      "std      1.652370          0.005377      0.001021\n",
      "min     -4.591527          0.000000      0.001505\n",
      "25%     -3.265236          0.000000      0.002008\n",
      "50%     -2.078343          0.000000      0.003000\n",
      "75%     -0.703937          0.000000      0.003513\n",
      "max      3.096604          0.031964      0.006009\n",
      "Number of infeasible solution: 7\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"][:100]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_lt_10-10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941a76c-0ea0-4fb9-a23e-51c85a433463",
   "metadata": {},
   "source": [
    "## Parametric Learning Then Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "382a0a8a-d846-4182-ab69-7d618edea9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdf56b3-5d23-4042-b4c8-a4eb3dbb756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hsize = 32            # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0910211-a95e-4c60-acb5-c764cfffe155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "302fa35d-7b70-4cd8-a56b-5e450223d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 258.35\n",
      "Epoch 1, Validation Loss: 96.46\n",
      "Epoch 2, Validation Loss: 6.20\n",
      "Epoch 3, Validation Loss: 4.04\n",
      "Epoch 4, Validation Loss: 3.37\n",
      "Epoch 5, Validation Loss: 2.73\n",
      "Epoch 6, Validation Loss: 2.24\n",
      "Epoch 7, Validation Loss: 2.03\n",
      "Epoch 8, Validation Loss: 2.04\n",
      "Epoch 9, Validation Loss: 1.84\n",
      "Epoch 10, Validation Loss: 1.65\n",
      "Epoch 11, Validation Loss: 1.38\n",
      "Epoch 12, Validation Loss: 0.74\n",
      "Epoch 13, Validation Loss: 0.58\n",
      "Epoch 14, Validation Loss: 0.53\n",
      "Epoch 15, Validation Loss: 0.13\n",
      "Epoch 16, Validation Loss: 0.13\n",
      "Epoch 17, Validation Loss: -0.00\n",
      "Epoch 18, Validation Loss: -0.03\n",
      "Epoch 19, Validation Loss: -0.08\n",
      "Epoch 20, Validation Loss: -0.14\n",
      "Epoch 21, Validation Loss: 0.40\n",
      "Epoch 22, Validation Loss: -0.42\n",
      "Epoch 23, Validation Loss: -0.68\n",
      "Epoch 24, Validation Loss: -0.52\n",
      "Epoch 25, Validation Loss: -0.42\n",
      "Epoch 26, Validation Loss: -0.34\n",
      "Epoch 27, Validation Loss: -0.88\n",
      "Epoch 28, Validation Loss: -1.06\n",
      "Epoch 29, Validation Loss: -1.13\n",
      "Epoch 30, Validation Loss: -1.14\n",
      "Epoch 31, Validation Loss: -1.20\n",
      "Epoch 32, Validation Loss: -1.25\n",
      "Epoch 33, Validation Loss: -1.44\n",
      "Epoch 34, Validation Loss: -1.48\n",
      "Epoch 35, Validation Loss: -1.49\n",
      "Epoch 36, Validation Loss: -1.60\n",
      "Epoch 37, Validation Loss: -1.61\n",
      "Epoch 38, Validation Loss: -1.79\n",
      "Epoch 39, Validation Loss: -1.76\n",
      "Epoch 40, Validation Loss: -1.91\n",
      "Epoch 41, Validation Loss: -1.83\n",
      "Epoch 42, Validation Loss: -1.92\n",
      "Epoch 43, Validation Loss: -1.90\n",
      "Epoch 44, Validation Loss: -1.94\n",
      "Epoch 45, Validation Loss: -2.01\n",
      "Epoch 46, Validation Loss: -2.15\n",
      "Epoch 47, Validation Loss: -2.18\n",
      "Epoch 48, Validation Loss: -1.76\n",
      "Epoch 49, Validation Loss: -2.06\n",
      "Epoch 50, Validation Loss: -2.03\n",
      "Epoch 51, Validation Loss: -2.06\n",
      "Epoch 52, Validation Loss: -2.05\n",
      "Epoch 53, Validation Loss: -2.18\n",
      "Epoch 54, Validation Loss: -2.20\n",
      "Epoch 55, Validation Loss: -2.07\n",
      "Epoch 56, Validation Loss: -2.19\n",
      "Epoch 57, Validation Loss: -2.16\n",
      "Epoch 58, Validation Loss: -2.24\n",
      "Epoch 59, Validation Loss: -2.27\n",
      "Epoch 60, Validation Loss: -2.07\n",
      "Epoch 61, Validation Loss: -2.25\n",
      "Epoch 62, Validation Loss: -0.73\n",
      "Epoch 63, Validation Loss: -2.20\n",
      "Epoch 64, Validation Loss: -1.93\n",
      "Epoch 65, Validation Loss: -2.16\n",
      "Epoch 66, Validation Loss: -2.31\n",
      "Epoch 67, Validation Loss: -1.99\n",
      "Epoch 68, Validation Loss: -2.28\n",
      "Epoch 69, Validation Loss: -1.80\n",
      "Epoch 70, Validation Loss: -2.09\n",
      "Epoch 71, Validation Loss: -1.20\n",
      "Epoch 72, Validation Loss: -2.12\n",
      "Epoch 73, Validation Loss: -2.24\n",
      "Epoch 74, Validation Loss: -2.18\n",
      "Epoch 75, Validation Loss: -2.17\n",
      "Epoch 76, Validation Loss: -2.14\n",
      "Epoch 77, Validation Loss: -2.32\n",
      "Epoch 78, Validation Loss: -2.15\n",
      "Epoch 79, Validation Loss: -2.32\n",
      "Epoch 80, Validation Loss: -2.29\n",
      "Epoch 81, Validation Loss: -1.74\n",
      "Epoch 82, Validation Loss: -2.04\n",
      "Epoch 83, Validation Loss: -2.33\n",
      "Epoch 84, Validation Loss: -2.28\n",
      "Epoch 85, Validation Loss: -2.11\n",
      "Epoch 86, Validation Loss: -2.28\n",
      "Epoch 87, Validation Loss: -1.94\n",
      "Epoch 88, Validation Loss: -1.96\n",
      "Epoch 89, Validation Loss: -2.07\n",
      "Epoch 90, Validation Loss: -2.30\n",
      "Epoch 91, Validation Loss: -2.21\n",
      "Epoch 92, Validation Loss: -1.89\n",
      "Epoch 93, Validation Loss: -2.36\n",
      "Epoch 94, Validation Loss: -2.28\n",
      "Epoch 95, Validation Loss: -2.37\n",
      "Epoch 96, Validation Loss: -2.26\n",
      "Epoch 97, Validation Loss: -2.42\n",
      "Epoch 98, Validation Loss: -2.34\n",
      "Epoch 99, Validation Loss: -1.58\n",
      "Epoch 100, Validation Loss: -1.13\n",
      "Epoch 101, Validation Loss: -2.38\n",
      "Epoch 102, Validation Loss: -2.38\n",
      "Epoch 103, Validation Loss: -2.33\n",
      "Epoch 104, Validation Loss: -2.18\n",
      "Epoch 105, Validation Loss: -2.21\n",
      "Epoch 106, Validation Loss: -2.32\n",
      "Epoch 107, Validation Loss: -2.31\n",
      "Epoch 108, Validation Loss: -2.06\n",
      "Epoch 109, Validation Loss: -2.24\n",
      "Epoch 110, Validation Loss: -2.23\n",
      "Epoch 111, Validation Loss: -2.25\n",
      "Epoch 112, Validation Loss: -2.18\n",
      "Epoch 113, Validation Loss: -2.24\n",
      "Epoch 114, Validation Loss: -2.16\n",
      "Epoch 115, Validation Loss: -2.30\n",
      "Epoch 116, Validation Loss: -2.07\n",
      "Early stopping at epoch 116\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 63.96 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75f4de2-7ebf-43b8-ac0b-d1a82a300eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 370.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000        100.000000    100.000000\n",
      "mean    -2.481321          0.078485      0.000698\n",
      "std      1.548409          0.057827      0.000486\n",
      "min     -4.868193          0.000000      0.000000\n",
      "25%     -3.808517          0.032311      0.000000\n",
      "50%     -2.755608          0.069870      0.001000\n",
      "75%     -1.583942          0.111662      0.001006\n",
      "max      2.281136          0.262004      0.001507\n",
      "Number of infeasible solution: 93\n"
     ]
    }
   ],
   "source": [
    "from src.heuristic import naive_round\n",
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"][:100]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval_rel, _ = model.get_val()\n",
    "    xval, objval = naive_round(xval_rel, model)\n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_pr_10-10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524149ef-1159-45e9-84a2-ac84300173dc",
   "metadata": {},
   "source": [
    "### STE Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a0ce16-a370-449f-b9d0-718a4b734640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477bb7eb-b08b-438d-91e5-4f34398ea30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hsize = 16            # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc8a5b9-f6f6-437d-8605-fbfdaa0a5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmQuadratic\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundSTEModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_ineq, outsize=num_var, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "rnd = roundSTEModel(param_keys=[\"b\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], int_ind=model.int_ind, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmQuadratic([\"b\", \"x_rnd\"], num_var, num_ineq, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32cd01d3-38ff-489e-ae13-08f460715b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 253.56\n",
      "Epoch 1, Validation Loss: 108.38\n",
      "Epoch 2, Validation Loss: 20.31\n",
      "Epoch 3, Validation Loss: 5.15\n",
      "Epoch 4, Validation Loss: 4.24\n",
      "Epoch 5, Validation Loss: 4.20\n",
      "Epoch 6, Validation Loss: 3.94\n",
      "Epoch 7, Validation Loss: 3.94\n",
      "Epoch 8, Validation Loss: 3.90\n",
      "Epoch 9, Validation Loss: 3.96\n",
      "Epoch 10, Validation Loss: 3.84\n",
      "Epoch 11, Validation Loss: 3.59\n",
      "Epoch 12, Validation Loss: 3.51\n",
      "Epoch 13, Validation Loss: 3.40\n",
      "Epoch 14, Validation Loss: 3.48\n",
      "Epoch 15, Validation Loss: 2.96\n",
      "Epoch 16, Validation Loss: 2.70\n",
      "Epoch 17, Validation Loss: 2.04\n",
      "Epoch 18, Validation Loss: 2.02\n",
      "Epoch 19, Validation Loss: 1.69\n",
      "Epoch 20, Validation Loss: 1.71\n",
      "Epoch 21, Validation Loss: 1.63\n",
      "Epoch 22, Validation Loss: 1.82\n",
      "Epoch 23, Validation Loss: 1.46\n",
      "Epoch 24, Validation Loss: 1.62\n",
      "Epoch 25, Validation Loss: 1.50\n",
      "Epoch 26, Validation Loss: 1.57\n",
      "Epoch 27, Validation Loss: 1.49\n",
      "Epoch 28, Validation Loss: 1.42\n",
      "Epoch 29, Validation Loss: 1.59\n",
      "Epoch 30, Validation Loss: 1.65\n",
      "Epoch 31, Validation Loss: 1.63\n",
      "Epoch 32, Validation Loss: 1.36\n",
      "Epoch 33, Validation Loss: 1.58\n",
      "Epoch 34, Validation Loss: 1.62\n",
      "Epoch 35, Validation Loss: 1.28\n",
      "Epoch 36, Validation Loss: 1.42\n",
      "Epoch 37, Validation Loss: 1.46\n",
      "Epoch 38, Validation Loss: 1.36\n",
      "Epoch 39, Validation Loss: 1.38\n",
      "Epoch 40, Validation Loss: 1.48\n",
      "Epoch 41, Validation Loss: 1.32\n",
      "Epoch 42, Validation Loss: 1.35\n",
      "Epoch 43, Validation Loss: 1.34\n",
      "Epoch 44, Validation Loss: 1.46\n",
      "Epoch 45, Validation Loss: 1.27\n",
      "Epoch 46, Validation Loss: 1.36\n",
      "Epoch 47, Validation Loss: 1.45\n",
      "Epoch 48, Validation Loss: 1.30\n",
      "Epoch 49, Validation Loss: 1.31\n",
      "Epoch 50, Validation Loss: 1.36\n",
      "Epoch 51, Validation Loss: 1.37\n",
      "Epoch 52, Validation Loss: 1.25\n",
      "Epoch 53, Validation Loss: 1.27\n",
      "Epoch 54, Validation Loss: 1.11\n",
      "Epoch 55, Validation Loss: 1.36\n",
      "Epoch 56, Validation Loss: 1.03\n",
      "Epoch 57, Validation Loss: 1.35\n",
      "Epoch 58, Validation Loss: 1.28\n",
      "Epoch 59, Validation Loss: 1.18\n",
      "Epoch 60, Validation Loss: 1.05\n",
      "Epoch 61, Validation Loss: 0.97\n",
      "Epoch 62, Validation Loss: 0.82\n",
      "Epoch 63, Validation Loss: 0.58\n",
      "Epoch 64, Validation Loss: 0.55\n",
      "Epoch 65, Validation Loss: 0.23\n",
      "Epoch 66, Validation Loss: 0.19\n",
      "Epoch 67, Validation Loss: 0.08\n",
      "Epoch 68, Validation Loss: 0.09\n",
      "Epoch 69, Validation Loss: 0.13\n",
      "Epoch 70, Validation Loss: 0.04\n",
      "Epoch 71, Validation Loss: -0.03\n",
      "Epoch 72, Validation Loss: -0.11\n",
      "Epoch 73, Validation Loss: -0.07\n",
      "Epoch 74, Validation Loss: -0.06\n",
      "Epoch 75, Validation Loss: 0.00\n",
      "Epoch 76, Validation Loss: -0.02\n",
      "Epoch 77, Validation Loss: -0.25\n",
      "Epoch 78, Validation Loss: -0.18\n",
      "Epoch 79, Validation Loss: -0.35\n",
      "Epoch 80, Validation Loss: -0.30\n",
      "Epoch 81, Validation Loss: -0.29\n",
      "Epoch 82, Validation Loss: -0.21\n",
      "Epoch 83, Validation Loss: -0.35\n",
      "Epoch 84, Validation Loss: -0.17\n",
      "Epoch 85, Validation Loss: -0.23\n",
      "Epoch 86, Validation Loss: -0.35\n",
      "Epoch 87, Validation Loss: -0.26\n",
      "Epoch 88, Validation Loss: -0.23\n",
      "Epoch 89, Validation Loss: -0.31\n",
      "Epoch 90, Validation Loss: -0.13\n",
      "Epoch 91, Validation Loss: -0.32\n",
      "Epoch 92, Validation Loss: -0.17\n",
      "Epoch 93, Validation Loss: -0.37\n",
      "Epoch 94, Validation Loss: -0.33\n",
      "Epoch 95, Validation Loss: -0.30\n",
      "Epoch 96, Validation Loss: -0.31\n",
      "Epoch 97, Validation Loss: -0.37\n",
      "Epoch 98, Validation Loss: -0.19\n",
      "Epoch 99, Validation Loss: -0.40\n",
      "Epoch 100, Validation Loss: -0.47\n",
      "Epoch 101, Validation Loss: -0.43\n",
      "Epoch 102, Validation Loss: -0.41\n",
      "Epoch 103, Validation Loss: -0.28\n",
      "Epoch 104, Validation Loss: -0.44\n",
      "Epoch 105, Validation Loss: -0.50\n",
      "Epoch 106, Validation Loss: -0.44\n",
      "Epoch 107, Validation Loss: -0.50\n",
      "Epoch 108, Validation Loss: -0.49\n",
      "Epoch 109, Validation Loss: -0.37\n",
      "Epoch 110, Validation Loss: -0.19\n",
      "Epoch 111, Validation Loss: -0.33\n",
      "Epoch 112, Validation Loss: -0.56\n",
      "Epoch 113, Validation Loss: -0.60\n",
      "Epoch 114, Validation Loss: -0.39\n",
      "Epoch 115, Validation Loss: -0.43\n",
      "Epoch 116, Validation Loss: -0.42\n",
      "Epoch 117, Validation Loss: -0.35\n",
      "Epoch 118, Validation Loss: -0.60\n",
      "Epoch 119, Validation Loss: -0.47\n",
      "Epoch 120, Validation Loss: -0.36\n",
      "Epoch 121, Validation Loss: -0.42\n",
      "Epoch 122, Validation Loss: -0.54\n",
      "Epoch 123, Validation Loss: -0.44\n",
      "Epoch 124, Validation Loss: -0.47\n",
      "Epoch 125, Validation Loss: -0.48\n",
      "Epoch 126, Validation Loss: -0.47\n",
      "Epoch 127, Validation Loss: -0.46\n",
      "Epoch 128, Validation Loss: -0.44\n",
      "Epoch 129, Validation Loss: -0.40\n",
      "Epoch 130, Validation Loss: -0.32\n",
      "Epoch 131, Validation Loss: -0.55\n",
      "Epoch 132, Validation Loss: -0.46\n",
      "Epoch 133, Validation Loss: -0.60\n",
      "Epoch 134, Validation Loss: -0.42\n",
      "Epoch 135, Validation Loss: -0.52\n",
      "Epoch 136, Validation Loss: -0.47\n",
      "Epoch 137, Validation Loss: -0.52\n",
      "Epoch 138, Validation Loss: -0.40\n",
      "Epoch 139, Validation Loss: -0.54\n",
      "Epoch 140, Validation Loss: -0.51\n",
      "Epoch 141, Validation Loss: -0.53\n",
      "Epoch 142, Validation Loss: -0.43\n",
      "Epoch 143, Validation Loss: -0.47\n",
      "Epoch 144, Validation Loss: -0.47\n",
      "Epoch 145, Validation Loss: -0.48\n",
      "Epoch 146, Validation Loss: -0.44\n",
      "Epoch 147, Validation Loss: -0.39\n",
      "Epoch 148, Validation Loss: -0.27\n",
      "Epoch 149, Validation Loss: -0.42\n",
      "Epoch 150, Validation Loss: -0.53\n",
      "Epoch 151, Validation Loss: -0.54\n",
      "Epoch 152, Validation Loss: -0.56\n",
      "Epoch 153, Validation Loss: -0.65\n",
      "Epoch 154, Validation Loss: -0.59\n",
      "Epoch 155, Validation Loss: -0.67\n",
      "Epoch 156, Validation Loss: -0.64\n",
      "Epoch 157, Validation Loss: -0.64\n",
      "Epoch 158, Validation Loss: -0.64\n",
      "Epoch 159, Validation Loss: -0.67\n",
      "Epoch 160, Validation Loss: -0.71\n",
      "Epoch 161, Validation Loss: -0.56\n",
      "Epoch 162, Validation Loss: -0.56\n",
      "Epoch 163, Validation Loss: -0.45\n",
      "Epoch 164, Validation Loss: -0.51\n",
      "Epoch 165, Validation Loss: -0.56\n",
      "Epoch 166, Validation Loss: -0.56\n",
      "Epoch 167, Validation Loss: -0.63\n",
      "Epoch 168, Validation Loss: -0.44\n",
      "Epoch 169, Validation Loss: -0.61\n",
      "Epoch 170, Validation Loss: -0.58\n",
      "Epoch 171, Validation Loss: -0.66\n",
      "Epoch 172, Validation Loss: -0.65\n",
      "Epoch 173, Validation Loss: -0.67\n",
      "Epoch 174, Validation Loss: -0.65\n",
      "Epoch 175, Validation Loss: -0.70\n",
      "Epoch 176, Validation Loss: -0.58\n",
      "Epoch 177, Validation Loss: -0.54\n",
      "Epoch 178, Validation Loss: -0.69\n",
      "Epoch 179, Validation Loss: -0.73\n",
      "Epoch 180, Validation Loss: -0.77\n",
      "Epoch 181, Validation Loss: -0.60\n",
      "Epoch 182, Validation Loss: -0.74\n",
      "Epoch 183, Validation Loss: -0.65\n",
      "Epoch 184, Validation Loss: -0.86\n",
      "Epoch 185, Validation Loss: -0.67\n",
      "Epoch 186, Validation Loss: -0.61\n",
      "Epoch 187, Validation Loss: -0.75\n",
      "Epoch 188, Validation Loss: -0.70\n",
      "Epoch 189, Validation Loss: -0.75\n",
      "Epoch 190, Validation Loss: -0.75\n",
      "Epoch 191, Validation Loss: -0.73\n",
      "Epoch 192, Validation Loss: -0.90\n",
      "Epoch 193, Validation Loss: -0.83\n",
      "Epoch 194, Validation Loss: -0.64\n",
      "Epoch 195, Validation Loss: -0.78\n",
      "Epoch 196, Validation Loss: -0.77\n",
      "Epoch 197, Validation Loss: -0.76\n",
      "Epoch 198, Validation Loss: -0.65\n",
      "Epoch 199, Validation Loss: -0.80\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 204.69 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be702950-8853-4844-a913-430ee8a2695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 262.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Obj Val  Constraints Viol  Elapsed Time\n",
      "count  100.000000             100.0    100.000000\n",
      "mean    -0.942166               0.0      0.001851\n",
      "std      1.880038               0.0      0.000653\n",
      "min     -3.665615               0.0      0.000000\n",
      "25%     -2.462619               0.0      0.001128\n",
      "50%     -1.319264               0.0      0.002008\n",
      "75%      0.266201               0.0      0.002292\n",
      "max      4.683797               0.0      0.003017\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for b in tqdm(data_test.datadict[\"b\"][:100]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(b, 0).to(\"cuda\"), \n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"b\":b.cpu().numpy()})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(num_var):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(b.cpu().numpy()))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/cq_st_10-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdb429-d08f-4b28-bcac-e6a5cf53f109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
