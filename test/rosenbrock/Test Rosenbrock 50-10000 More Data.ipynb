{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50     # steepness factor\n",
    "num_blocks = 10000 # number of expression blocks\n",
    "num_data = 81100    # number of data\n",
    "test_size = 100    # number of test size\n",
    "val_size = 1000    # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2bdd74-a0d1-4afa-b610-4f29559a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 2576558.44\n",
      "Epoch 0, Iters 125, Validation Loss: 11011623.81\n",
      "Epoch 0, Iters 250, Validation Loss: 1376246.12\n",
      "Epoch 0, Iters 375, Validation Loss: 705293.87\n",
      "Epoch 0, Iters 500, Validation Loss: 567785.90\n",
      "Epoch 0, Iters 625, Validation Loss: 1040880.62\n",
      "Epoch 0, Iters 750, Validation Loss: 66952333.50\n",
      "Epoch 0, Iters 875, Validation Loss: 382868309.59\n",
      "Epoch 0, Iters 1000, Validation Loss: 11365694.48\n",
      "Epoch 0, Iters 1125, Validation Loss: 3237054981.83\n",
      "Epoch 0, Iters 1250, Validation Loss: 1347419101629863952384.00\n",
      "Epoch 1, Iters 1375, Validation Loss: 551715748641268563968.00\n",
      "Epoch 1, Iters 1500, Validation Loss: 3876376581752.97\n",
      "Epoch 1, Iters 1625, Validation Loss: 347415.50\n",
      "Epoch 1, Iters 1750, Validation Loss: 266013027590651.94\n",
      "Epoch 1, Iters 1875, Validation Loss: 1777489580002377728.00\n",
      "Epoch 1, Iters 2000, Validation Loss: 455526440201915.06\n",
      "Epoch 1, Iters 2125, Validation Loss: 12527389056179.08\n",
      "Epoch 1, Iters 2250, Validation Loss: 344685.99\n",
      "Epoch 1, Iters 2375, Validation Loss: 255178.60\n",
      "Epoch 1, Iters 2500, Validation Loss: 899604.59\n",
      "Epoch 2, Iters 2625, Validation Loss: 197023.22\n",
      "Epoch 2, Iters 2750, Validation Loss: 189444.52\n",
      "Epoch 2, Iters 2875, Validation Loss: 141255.17\n",
      "Epoch 2, Iters 3000, Validation Loss: 115798.69\n",
      "Epoch 2, Iters 3125, Validation Loss: 157471.72\n",
      "Epoch 2, Iters 3250, Validation Loss: 200063.83\n",
      "Epoch 2, Iters 3375, Validation Loss: 216558.37\n",
      "Epoch 2, Iters 3500, Validation Loss: 116116.30\n",
      "Epoch 2, Iters 3625, Validation Loss: 133820.03\n",
      "Epoch 2, Iters 3750, Validation Loss: 202435.90\n",
      "Epoch 3, Iters 3875, Validation Loss: 142733.51\n",
      "Epoch 3, Iters 4000, Validation Loss: 533204.40\n",
      "Epoch 3, Iters 4125, Validation Loss: 149564.92\n",
      "Epoch 3, Iters 4250, Validation Loss: 123605.95\n",
      "Epoch 3, Iters 4375, Validation Loss: 226298.56\n",
      "Epoch 3, Iters 4500, Validation Loss: 585382.69\n",
      "Epoch 3, Iters 4625, Validation Loss: 110976.44\n",
      "Epoch 3, Iters 4750, Validation Loss: 193460.40\n",
      "Epoch 3, Iters 4875, Validation Loss: 270659.90\n",
      "Epoch 3, Iters 5000, Validation Loss: 126578.29\n",
      "Epoch 4, Iters 5125, Validation Loss: 463392836498084593664.00\n",
      "Epoch 4, Iters 5250, Validation Loss: 2491326289412194784247808.00\n",
      "Epoch 4, Iters 5375, Validation Loss: 3039686010762494.00\n",
      "Epoch 4, Iters 5500, Validation Loss: 30134757854.69\n",
      "Epoch 4, Iters 5625, Validation Loss: 100586.25\n",
      "Epoch 4, Iters 5750, Validation Loss: 680015.93\n",
      "Epoch 4, Iters 5875, Validation Loss: 310321.54\n",
      "Epoch 4, Iters 6000, Validation Loss: 176272.10\n",
      "Epoch 4, Iters 6125, Validation Loss: 89519.40\n",
      "Epoch 4, Iters 6250, Validation Loss: 141998820.90\n",
      "Epoch 5, Iters 6375, Validation Loss: 1476626.37\n",
      "Epoch 5, Iters 6500, Validation Loss: 541976163673267776.00\n",
      "Epoch 5, Iters 6625, Validation Loss: 498836772073106309120.00\n",
      "Epoch 5, Iters 6750, Validation Loss: 8150426794137583616.00\n",
      "Epoch 5, Iters 6875, Validation Loss: 364272.44\n",
      "Epoch 5, Iters 7000, Validation Loss: 511627.50\n",
      "Epoch 5, Iters 7125, Validation Loss: 560447.66\n",
      "Epoch 5, Iters 7250, Validation Loss: 2743511.58\n",
      "Epoch 5, Iters 7375, Validation Loss: 24659625167716089856.00\n",
      "Epoch 5, Iters 7500, Validation Loss: 27044761506488799371198464.00\n",
      "Epoch 6, Iters 7625, Validation Loss: 307581281030.53\n",
      "Epoch 6, Iters 7750, Validation Loss: 6386008270502363136.00\n",
      "Epoch 6, Iters 7875, Validation Loss: 64154625479621936108384813056.00\n",
      "Epoch 6, Iters 8000, Validation Loss: 300613874378081056883625426944.00\n",
      "Epoch 6, Iters 8125, Validation Loss: 166447920325251.97\n",
      "Epoch 6, Iters 8250, Validation Loss: 1150503008928343785472.00\n",
      "Epoch 6, Iters 8375, Validation Loss: 1039466701801935061307050950656.00\n",
      "Epoch 6, Iters 8500, Validation Loss: 11509278693367674.00\n",
      "Epoch 6, Iters 8625, Validation Loss: 289599042817049536.00\n",
      "Early stopping at iters 8626\n",
      "Early stopping at iters 8627\n",
      "Early stopping at iters 8628\n",
      "Early stopping at iters 8629\n",
      "Early stopping at iters 8630\n",
      "Early stopping at iters 8631\n",
      "Early stopping at iters 8632\n",
      "Early stopping at iters 8633\n",
      "Early stopping at iters 8634\n",
      "Early stopping at iters 8635\n",
      "Early stopping at iters 8636\n",
      "Early stopping at iters 8637\n",
      "Early stopping at iters 8638\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 736.00 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 20                     # number of training epochs\n",
    "warmup = 20                     # number of steps to wait before enacting early stopping policy\n",
    "patience = 20                   # number of steps with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:07<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Obj Val  Constraints Viol  Elapsed Time\n",
      "count     100.000000        100.000000    100.000000\n",
      "mean    93201.643254          5.937882      0.044229\n",
      "std     35598.842358         59.378825      0.005001\n",
      "min     52855.305370          0.000000      0.012624\n",
      "25%     68361.402574          0.000000      0.043846\n",
      "50%     75160.501619          0.000000      0.044348\n",
      "75%    113978.720713          0.000000      0.045244\n",
      "max    180846.332872        593.788249      0.050292\n",
      "Number of infeasible solution: 1\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lr_50-10000_l.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7912a689-22cd-4d7b-a50f-d136dbdf5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                          int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 2328965.64\n",
      "Epoch 0, Iters 125, Validation Loss: 10015729.44\n",
      "Epoch 0, Iters 250, Validation Loss: 8090307680.00\n",
      "Epoch 0, Iters 375, Validation Loss: 1131913.62\n",
      "Epoch 0, Iters 500, Validation Loss: 124707385.38\n",
      "Epoch 0, Iters 625, Validation Loss: 11801074925568.00\n",
      "Epoch 0, Iters 750, Validation Loss: 8926565329010688.00\n",
      "Epoch 0, Iters 875, Validation Loss: 162258480914432.00\n",
      "Epoch 0, Iters 1000, Validation Loss: 649409132222218240.00\n",
      "Epoch 0, Iters 1125, Validation Loss: 1028460576768.00\n",
      "Epoch 0, Iters 1250, Validation Loss: 670135.68\n",
      "Epoch 1, Iters 1375, Validation Loss: 741309.20\n",
      "Epoch 1, Iters 1500, Validation Loss: 533692.67\n",
      "Epoch 1, Iters 1625, Validation Loss: 1181530152158.00\n",
      "Epoch 1, Iters 1750, Validation Loss: 9058761383936.00\n",
      "Epoch 1, Iters 1875, Validation Loss: 1061128063878432817152.00\n",
      "Epoch 1, Iters 2000, Validation Loss: 64452370181.43\n",
      "Epoch 1, Iters 2125, Validation Loss: 3774534997057.81\n",
      "Epoch 1, Iters 2250, Validation Loss: 365346.74\n",
      "Epoch 1, Iters 2375, Validation Loss: 1114766.27\n",
      "Epoch 1, Iters 2500, Validation Loss: 278548152615022511521792.00\n",
      "Epoch 2, Iters 2625, Validation Loss: 1047900.02\n",
      "Epoch 2, Iters 2750, Validation Loss: 175307.27\n",
      "Epoch 2, Iters 2875, Validation Loss: 251380.10\n",
      "Epoch 2, Iters 3000, Validation Loss: 371653592815.46\n",
      "Epoch 2, Iters 3125, Validation Loss: 200191.25\n",
      "Epoch 2, Iters 3250, Validation Loss: 356167.68\n",
      "Epoch 2, Iters 3375, Validation Loss: 133171.57\n",
      "Epoch 2, Iters 3500, Validation Loss: 472684.57\n",
      "Epoch 2, Iters 3625, Validation Loss: 107749.46\n",
      "Epoch 2, Iters 3750, Validation Loss: 6134001936675950821376.00\n",
      "Epoch 3, Iters 3875, Validation Loss: 178624.69\n",
      "Epoch 3, Iters 4000, Validation Loss: 2077894575082231960698880.00\n",
      "Epoch 3, Iters 4125, Validation Loss: 647581309388482209120256.00\n",
      "Epoch 3, Iters 4250, Validation Loss: inf\n",
      "Epoch 3, Iters 4375, Validation Loss: 6950580981335150945107968.00\n",
      "Epoch 3, Iters 4500, Validation Loss: 474307.84\n",
      "Epoch 3, Iters 4625, Validation Loss: 3573382532004.43\n",
      "Epoch 3, Iters 4750, Validation Loss: 1985740377024104759296.00\n",
      "Epoch 3, Iters 4875, Validation Loss: 1494570481061883912650752.00\n",
      "Epoch 3, Iters 5000, Validation Loss: 85651.75\n",
      "Epoch 4, Iters 5125, Validation Loss: 135436.94\n",
      "Epoch 4, Iters 5250, Validation Loss: 103049.83\n",
      "Epoch 4, Iters 5375, Validation Loss: 205589.81\n",
      "Epoch 4, Iters 5500, Validation Loss: 123332.45\n",
      "Epoch 4, Iters 5625, Validation Loss: 90586.71\n",
      "Epoch 4, Iters 5750, Validation Loss: 347648.78\n",
      "Epoch 4, Iters 5875, Validation Loss: 74787.43\n",
      "Epoch 4, Iters 6000, Validation Loss: 82917.40\n",
      "Epoch 4, Iters 6125, Validation Loss: 60072.03\n",
      "Epoch 4, Iters 6250, Validation Loss: 63832.14\n",
      "Epoch 5, Iters 6375, Validation Loss: 73651.90\n",
      "Epoch 5, Iters 6500, Validation Loss: 162395.48\n",
      "Epoch 5, Iters 6625, Validation Loss: 88350.79\n",
      "Epoch 5, Iters 6750, Validation Loss: 110176.70\n",
      "Epoch 5, Iters 6875, Validation Loss: 91081.47\n",
      "Epoch 5, Iters 7000, Validation Loss: 129838.07\n",
      "Epoch 5, Iters 7125, Validation Loss: 63237.41\n",
      "Epoch 5, Iters 7250, Validation Loss: 561984.68\n",
      "Epoch 5, Iters 7375, Validation Loss: 444579.25\n",
      "Epoch 5, Iters 7500, Validation Loss: 75781.28\n",
      "Epoch 6, Iters 7625, Validation Loss: 117523.06\n",
      "Epoch 6, Iters 7750, Validation Loss: 221985.76\n",
      "Epoch 6, Iters 7875, Validation Loss: 62710.32\n",
      "Epoch 6, Iters 8000, Validation Loss: 100289.27\n",
      "Epoch 6, Iters 8125, Validation Loss: 170736.53\n",
      "Epoch 6, Iters 8250, Validation Loss: 113071.26\n",
      "Epoch 6, Iters 8375, Validation Loss: 73122.26\n",
      "Epoch 6, Iters 8500, Validation Loss: 164709.14\n",
      "Epoch 6, Iters 8625, Validation Loss: 69121.35\n",
      "Early stopping at iters 8626\n",
      "Early stopping at iters 8627\n",
      "Early stopping at iters 8628\n",
      "Early stopping at iters 8629\n",
      "Early stopping at iters 8630\n",
      "Early stopping at iters 8631\n",
      "Early stopping at iters 8632\n",
      "Early stopping at iters 8633\n",
      "Early stopping at iters 8634\n",
      "Early stopping at iters 8635\n",
      "Early stopping at iters 8636\n",
      "Early stopping at iters 8637\n",
      "Early stopping at iters 8638\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 756.69 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 20                     # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:07<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count    100.000000             100.0    100.000000\n",
      "mean   60497.329874               0.0      0.043434\n",
      "std    12504.687773               0.0      0.007029\n",
      "min    39604.485020               0.0      0.010867\n",
      "25%    49361.541732               0.0      0.043601\n",
      "50%    57232.160451               0.0      0.044234\n",
      "75%    68858.006611               0.0      0.045418\n",
      "max    94449.314669               0.0      0.050184\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lt_50-10000_l.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f038b4a-7343-4662-88db-78ef4c99a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
