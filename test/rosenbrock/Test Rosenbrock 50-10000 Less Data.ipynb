{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50     # steepness factor\n",
    "num_blocks = 10000 # number of expression blocks\n",
    "num_data = 1900    # number of data\n",
    "test_size = 100    # number of test size\n",
    "val_size = 1000    # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2bdd74-a0d1-4afa-b610-4f29559a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 2593960.00\n",
      "Epoch 1, Validation Loss: 573909356.00\n",
      "Epoch 2, Validation Loss: 3488881868800.00\n",
      "Epoch 3, Validation Loss: 126014059520.00\n",
      "Epoch 4, Validation Loss: 123627577.50\n",
      "Epoch 5, Validation Loss: 5490150.59\n",
      "Epoch 6, Validation Loss: 3705841.02\n",
      "Epoch 7, Validation Loss: 2012055.21\n",
      "Epoch 8, Validation Loss: 1554858.25\n",
      "Epoch 9, Validation Loss: 1706727.34\n",
      "Epoch 10, Validation Loss: 1734503.23\n",
      "Epoch 11, Validation Loss: 2040054.13\n",
      "Epoch 12, Validation Loss: 1453294.98\n",
      "Epoch 13, Validation Loss: 1293839.89\n",
      "Epoch 14, Validation Loss: 1321966.72\n",
      "Epoch 15, Validation Loss: 1050613.75\n",
      "Epoch 16, Validation Loss: 873178.72\n",
      "Epoch 17, Validation Loss: 1652335.52\n",
      "Epoch 18, Validation Loss: 1588407.82\n",
      "Epoch 19, Validation Loss: 1129695.05\n",
      "Epoch 20, Validation Loss: 1730939.39\n",
      "Epoch 21, Validation Loss: 1810683.86\n",
      "Epoch 22, Validation Loss: 884861.55\n",
      "Epoch 23, Validation Loss: 1596195.88\n",
      "Epoch 24, Validation Loss: 1387324.20\n",
      "Epoch 25, Validation Loss: 919176.92\n",
      "Epoch 26, Validation Loss: 539183.16\n",
      "Epoch 27, Validation Loss: 921813.81\n",
      "Epoch 28, Validation Loss: 1135274.57\n",
      "Epoch 29, Validation Loss: 1716738.70\n",
      "Epoch 30, Validation Loss: 697185.81\n",
      "Epoch 31, Validation Loss: 945495.88\n",
      "Epoch 32, Validation Loss: 2034826.25\n",
      "Epoch 33, Validation Loss: 1782304.26\n",
      "Epoch 34, Validation Loss: 568299.16\n",
      "Epoch 35, Validation Loss: 1601996.23\n",
      "Epoch 36, Validation Loss: 837813.89\n",
      "Epoch 37, Validation Loss: 933362.19\n",
      "Epoch 38, Validation Loss: 819904.34\n",
      "Epoch 39, Validation Loss: 768416.46\n",
      "Epoch 40, Validation Loss: 540321.08\n",
      "Epoch 41, Validation Loss: 541445.39\n",
      "Epoch 42, Validation Loss: 691335.31\n",
      "Epoch 43, Validation Loss: 898942.82\n",
      "Epoch 44, Validation Loss: 816892.91\n",
      "Epoch 45, Validation Loss: 1426364.58\n",
      "Epoch 46, Validation Loss: 669060.59\n",
      "Epoch 47, Validation Loss: 2728997.08\n",
      "Epoch 48, Validation Loss: 1379425.95\n",
      "Epoch 49, Validation Loss: 1267796.50\n",
      "Epoch 50, Validation Loss: 522882.11\n",
      "Epoch 51, Validation Loss: 692709.29\n",
      "Epoch 52, Validation Loss: 979031.51\n",
      "Epoch 53, Validation Loss: 819738.88\n",
      "Epoch 54, Validation Loss: 728239.55\n",
      "Epoch 55, Validation Loss: 590287.02\n",
      "Epoch 56, Validation Loss: 549497.14\n",
      "Epoch 57, Validation Loss: 626532.03\n",
      "Epoch 58, Validation Loss: 634025.14\n",
      "Epoch 59, Validation Loss: 833826.01\n",
      "Epoch 60, Validation Loss: 673483.14\n",
      "Epoch 61, Validation Loss: 912750.23\n",
      "Epoch 62, Validation Loss: 1172424.41\n",
      "Epoch 63, Validation Loss: 1078925.70\n",
      "Epoch 64, Validation Loss: 599713.42\n",
      "Epoch 65, Validation Loss: 540464.99\n",
      "Epoch 66, Validation Loss: 794007.14\n",
      "Epoch 67, Validation Loss: 766422.27\n",
      "Epoch 68, Validation Loss: 585753.58\n",
      "Epoch 69, Validation Loss: 1221273.46\n",
      "Epoch 70, Validation Loss: 40873863296.00\n",
      "Epoch 71, Validation Loss: 657564.10\n",
      "Epoch 72, Validation Loss: 639948.06\n",
      "Epoch 73, Validation Loss: 692814.66\n",
      "Epoch 74, Validation Loss: 897716.64\n",
      "Epoch 75, Validation Loss: 556527.96\n",
      "Epoch 76, Validation Loss: 990069.67\n",
      "Epoch 77, Validation Loss: 595129.00\n",
      "Epoch 78, Validation Loss: 624733.36\n",
      "Epoch 79, Validation Loss: 525064.28\n",
      "Epoch 80, Validation Loss: 534300.26\n",
      "Epoch 81, Validation Loss: 539632.17\n",
      "Epoch 82, Validation Loss: 845287.98\n",
      "Epoch 83, Validation Loss: 483566.65\n",
      "Epoch 84, Validation Loss: 548329.32\n",
      "Epoch 85, Validation Loss: 663298.45\n",
      "Epoch 86, Validation Loss: 509320.14\n",
      "Epoch 87, Validation Loss: 475283.00\n",
      "Epoch 88, Validation Loss: 573976.29\n",
      "Epoch 89, Validation Loss: 477851.79\n",
      "Epoch 90, Validation Loss: 497696.99\n",
      "Epoch 91, Validation Loss: 585752.04\n",
      "Epoch 92, Validation Loss: 678204.70\n",
      "Epoch 93, Validation Loss: 556583.50\n",
      "Epoch 94, Validation Loss: 652614.69\n",
      "Epoch 95, Validation Loss: 578152.82\n",
      "Epoch 96, Validation Loss: 53594003.27\n",
      "Epoch 97, Validation Loss: 495003.55\n",
      "Epoch 98, Validation Loss: 5431194177.59\n",
      "Epoch 99, Validation Loss: 733195.74\n",
      "Epoch 100, Validation Loss: 705951.87\n",
      "Epoch 101, Validation Loss: 720629.62\n",
      "Epoch 102, Validation Loss: 471671.79\n",
      "Epoch 103, Validation Loss: 140989916.00\n",
      "Epoch 104, Validation Loss: 739939.47\n",
      "Epoch 105, Validation Loss: 1043428.80\n",
      "Epoch 106, Validation Loss: 507581.22\n",
      "Epoch 107, Validation Loss: 544639.56\n",
      "Epoch 108, Validation Loss: 848954.98\n",
      "Epoch 109, Validation Loss: 564742.15\n",
      "Epoch 110, Validation Loss: 643405.57\n",
      "Epoch 111, Validation Loss: 855866.32\n",
      "Epoch 112, Validation Loss: 60724629.63\n",
      "Epoch 113, Validation Loss: 99739777.72\n",
      "Epoch 114, Validation Loss: 121125183866.68\n",
      "Epoch 115, Validation Loss: 495235.68\n",
      "Epoch 116, Validation Loss: 1088226.15\n",
      "Epoch 117, Validation Loss: 661380.09\n",
      "Epoch 118, Validation Loss: 183406833496.52\n",
      "Epoch 119, Validation Loss: 338289687090.00\n",
      "Epoch 120, Validation Loss: 2860285286.95\n",
      "Epoch 121, Validation Loss: 13583325.27\n",
      "Epoch 122, Validation Loss: 772963.04\n",
      "Epoch 123, Validation Loss: 1290624.15\n",
      "Epoch 124, Validation Loss: 475883.96\n",
      "Epoch 125, Validation Loss: 48826069684.34\n",
      "Epoch 126, Validation Loss: 238029990565977.00\n",
      "Epoch 127, Validation Loss: 772273.70\n",
      "Epoch 128, Validation Loss: 526708.38\n",
      "Epoch 129, Validation Loss: 8775937.90\n",
      "Epoch 130, Validation Loss: 609017.98\n",
      "Epoch 131, Validation Loss: 1897262478260819.25\n",
      "Epoch 132, Validation Loss: 524422.99\n",
      "Epoch 133, Validation Loss: 161597643395.25\n",
      "Epoch 134, Validation Loss: 1002599.30\n",
      "Epoch 135, Validation Loss: 633491.36\n",
      "Epoch 136, Validation Loss: 825074.75\n",
      "Epoch 137, Validation Loss: 481288.67\n",
      "Epoch 138, Validation Loss: 552983.12\n",
      "Epoch 139, Validation Loss: 497810.09\n",
      "Epoch 140, Validation Loss: 778783.65\n",
      "Epoch 141, Validation Loss: 653428.05\n",
      "Epoch 142, Validation Loss: 545573.69\n",
      "Epoch 143, Validation Loss: 440836737.00\n",
      "Epoch 144, Validation Loss: 649149.66\n",
      "Epoch 145, Validation Loss: 569430.34\n",
      "Epoch 146, Validation Loss: 481302.06\n",
      "Epoch 147, Validation Loss: 466065.81\n",
      "Epoch 148, Validation Loss: 657398.31\n",
      "Epoch 149, Validation Loss: 651064.34\n",
      "Epoch 150, Validation Loss: 563474.07\n",
      "Epoch 151, Validation Loss: 632171.86\n",
      "Epoch 152, Validation Loss: 601685.11\n",
      "Epoch 153, Validation Loss: 481353.25\n",
      "Epoch 154, Validation Loss: 561974.75\n",
      "Epoch 155, Validation Loss: 525257.39\n",
      "Epoch 156, Validation Loss: 476933.04\n",
      "Epoch 157, Validation Loss: 548461.75\n",
      "Epoch 158, Validation Loss: 543645.48\n",
      "Epoch 159, Validation Loss: 522780.09\n",
      "Epoch 160, Validation Loss: 477428.08\n",
      "Epoch 161, Validation Loss: 481305.06\n",
      "Epoch 162, Validation Loss: 528394.69\n",
      "Epoch 163, Validation Loss: 945506.84\n",
      "Epoch 164, Validation Loss: 495921.50\n",
      "Epoch 165, Validation Loss: 500388.58\n",
      "Epoch 166, Validation Loss: 863217.04\n",
      "Epoch 167, Validation Loss: 682190.68\n",
      "Epoch 168, Validation Loss: 4890697.95\n",
      "Epoch 169, Validation Loss: 38468985.29\n",
      "Epoch 170, Validation Loss: 8402268.64\n",
      "Epoch 171, Validation Loss: 1022148.36\n",
      "Epoch 172, Validation Loss: 17182009.70\n",
      "Epoch 173, Validation Loss: 57634482.42\n",
      "Epoch 174, Validation Loss: 1171558.71\n",
      "Epoch 175, Validation Loss: 21338348.53\n",
      "Epoch 176, Validation Loss: 295256711.03\n",
      "Epoch 177, Validation Loss: 34260039.56\n",
      "Epoch 178, Validation Loss: 195550954.84\n",
      "Epoch 179, Validation Loss: 36104407695.93\n",
      "Epoch 180, Validation Loss: 261062503045.45\n",
      "Epoch 181, Validation Loss: 186127560339949442717003546624.00\n",
      "Epoch 182, Validation Loss: 721396.68\n",
      "Epoch 183, Validation Loss: 600650.56\n",
      "Epoch 184, Validation Loss: 470268.05\n",
      "Epoch 185, Validation Loss: 629479.16\n",
      "Epoch 186, Validation Loss: 547747.20\n",
      "Epoch 187, Validation Loss: 473924.95\n",
      "Epoch 188, Validation Loss: 642668.82\n",
      "Epoch 189, Validation Loss: 742221.88\n",
      "Epoch 190, Validation Loss: 581540.82\n",
      "Epoch 191, Validation Loss: 2116972.91\n",
      "Epoch 192, Validation Loss: 775974.57\n",
      "Epoch 193, Validation Loss: 601803.10\n",
      "Epoch 194, Validation Loss: 590857.29\n",
      "Epoch 195, Validation Loss: 730794.02\n",
      "Epoch 196, Validation Loss: 489080.37\n",
      "Epoch 197, Validation Loss: 589153.86\n",
      "Epoch 198, Validation Loss: 4373744.91\n",
      "Epoch 199, Validation Loss: 480501.14\n",
      "Epoch 200, Validation Loss: 498746.34\n",
      "Epoch 201, Validation Loss: 567604.47\n",
      "Epoch 202, Validation Loss: 460154.85\n",
      "Epoch 203, Validation Loss: 465152.56\n",
      "Epoch 204, Validation Loss: 775784.09\n",
      "Epoch 205, Validation Loss: 518758800617402.50\n",
      "Epoch 206, Validation Loss: 587406.15\n",
      "Epoch 207, Validation Loss: 507820.76\n",
      "Epoch 208, Validation Loss: 484120.22\n",
      "Epoch 209, Validation Loss: 503190.15\n",
      "Epoch 210, Validation Loss: 19523531435815.95\n",
      "Epoch 211, Validation Loss: 622002.94\n",
      "Epoch 212, Validation Loss: 506060.12\n",
      "Epoch 213, Validation Loss: 479371.82\n",
      "Epoch 214, Validation Loss: 640847.91\n",
      "Epoch 215, Validation Loss: 583994.29\n",
      "Epoch 216, Validation Loss: 785893.01\n",
      "Epoch 217, Validation Loss: 929116.54\n",
      "Epoch 218, Validation Loss: 599900.02\n",
      "Epoch 219, Validation Loss: 578511.54\n",
      "Epoch 220, Validation Loss: 723635.55\n",
      "Epoch 221, Validation Loss: 3166617.85\n",
      "Epoch 222, Validation Loss: 490359.66\n",
      "Epoch 223, Validation Loss: 623458.35\n",
      "Epoch 224, Validation Loss: 59293794.75\n",
      "Epoch 225, Validation Loss: 816728.02\n",
      "Epoch 226, Validation Loss: 786979.58\n",
      "Epoch 227, Validation Loss: 806451.83\n",
      "Epoch 228, Validation Loss: 904891.51\n",
      "Epoch 229, Validation Loss: 534683.06\n",
      "Epoch 230, Validation Loss: 732291.46\n",
      "Epoch 231, Validation Loss: 505443.70\n",
      "Epoch 232, Validation Loss: 515086.85\n",
      "Epoch 233, Validation Loss: 612084.38\n",
      "Epoch 234, Validation Loss: 495890.87\n",
      "Epoch 235, Validation Loss: 465540.84\n",
      "Epoch 236, Validation Loss: 554904.76\n",
      "Epoch 237, Validation Loss: 629655.40\n",
      "Epoch 238, Validation Loss: 582634.98\n",
      "Epoch 239, Validation Loss: 762877.75\n",
      "Epoch 240, Validation Loss: 704304.57\n",
      "Epoch 241, Validation Loss: 581265.49\n",
      "Epoch 242, Validation Loss: 745403.24\n",
      "Epoch 243, Validation Loss: 548443.57\n",
      "Epoch 244, Validation Loss: 574825.76\n",
      "Epoch 245, Validation Loss: 835383.65\n",
      "Epoch 246, Validation Loss: 464106.60\n",
      "Epoch 247, Validation Loss: 539921.29\n",
      "Epoch 248, Validation Loss: 573869.35\n",
      "Epoch 249, Validation Loss: 831423.79\n",
      "Epoch 250, Validation Loss: 520846.19\n",
      "Epoch 251, Validation Loss: 475331.25\n",
      "Epoch 252, Validation Loss: 671001.95\n",
      "Epoch 253, Validation Loss: 760544.14\n",
      "Epoch 254, Validation Loss: 446153.86\n",
      "Epoch 255, Validation Loss: 524292.45\n",
      "Epoch 256, Validation Loss: 658893.65\n",
      "Epoch 257, Validation Loss: 2418688761856.00\n",
      "Epoch 258, Validation Loss: 428692.63\n",
      "Epoch 259, Validation Loss: 30199638272.00\n",
      "Epoch 260, Validation Loss: 641806.42\n",
      "Epoch 261, Validation Loss: 758837.43\n",
      "Epoch 262, Validation Loss: 544063.05\n",
      "Epoch 263, Validation Loss: 929053.90\n",
      "Epoch 264, Validation Loss: 913507.32\n",
      "Epoch 265, Validation Loss: 443678.60\n",
      "Epoch 266, Validation Loss: 517055.17\n",
      "Epoch 267, Validation Loss: 657679.59\n",
      "Epoch 268, Validation Loss: 706697.22\n",
      "Epoch 269, Validation Loss: 477518.36\n",
      "Epoch 270, Validation Loss: 668850.93\n",
      "Epoch 271, Validation Loss: 528819.16\n",
      "Epoch 272, Validation Loss: 435649.88\n",
      "Epoch 273, Validation Loss: 450145.22\n",
      "Epoch 274, Validation Loss: 514593.57\n",
      "Epoch 275, Validation Loss: 515870.38\n",
      "Epoch 276, Validation Loss: 634878.14\n",
      "Epoch 277, Validation Loss: 753697.26\n",
      "Epoch 278, Validation Loss: 448519.58\n",
      "Epoch 279, Validation Loss: 476183.54\n",
      "Epoch 280, Validation Loss: 623097.57\n",
      "Epoch 281, Validation Loss: 650816.27\n",
      "Epoch 282, Validation Loss: 759579.90\n",
      "Epoch 283, Validation Loss: 891849.79\n",
      "Epoch 284, Validation Loss: 812102.09\n",
      "Epoch 285, Validation Loss: 762449.91\n",
      "Epoch 286, Validation Loss: 555322.43\n",
      "Epoch 287, Validation Loss: 635767.14\n",
      "Epoch 288, Validation Loss: 534745.99\n",
      "Epoch 289, Validation Loss: 460662.82\n",
      "Epoch 290, Validation Loss: 458943.03\n",
      "Epoch 291, Validation Loss: 1048717.12\n",
      "Epoch 292, Validation Loss: 977692.89\n",
      "Epoch 293, Validation Loss: 534362.13\n",
      "Epoch 294, Validation Loss: 567548.07\n",
      "Epoch 295, Validation Loss: 843131.42\n",
      "Epoch 296, Validation Loss: 788618.66\n",
      "Epoch 297, Validation Loss: 495979.16\n",
      "Epoch 298, Validation Loss: 459115.94\n",
      "Epoch 299, Validation Loss: 666657.07\n",
      "Epoch 300, Validation Loss: 668780.72\n",
      "Epoch 301, Validation Loss: 751740.07\n",
      "Epoch 302, Validation Loss: 623660.68\n",
      "Epoch 303, Validation Loss: 591365.17\n",
      "Epoch 304, Validation Loss: 782814.27\n",
      "Epoch 305, Validation Loss: 452307.82\n",
      "Epoch 306, Validation Loss: 649716.75\n",
      "Epoch 307, Validation Loss: 558603.47\n",
      "Epoch 308, Validation Loss: 481556.24\n",
      "Epoch 309, Validation Loss: 577338.07\n",
      "Epoch 310, Validation Loss: 716883.12\n",
      "Epoch 311, Validation Loss: 457718.02\n",
      "Epoch 312, Validation Loss: 658140.83\n",
      "Epoch 313, Validation Loss: 742532.84\n",
      "Epoch 314, Validation Loss: 461336.30\n",
      "Epoch 315, Validation Loss: 632963.82\n",
      "Epoch 316, Validation Loss: 618775.66\n",
      "Epoch 317, Validation Loss: 569943.18\n",
      "Epoch 318, Validation Loss: 551332.82\n",
      "Epoch 319, Validation Loss: 521241.49\n",
      "Epoch 320, Validation Loss: 546562.01\n",
      "Epoch 321, Validation Loss: 457385.60\n",
      "Epoch 322, Validation Loss: 545498.10\n",
      "Epoch 323, Validation Loss: 528567.06\n",
      "Epoch 324, Validation Loss: 51733206.46\n",
      "Epoch 325, Validation Loss: 437133.57\n",
      "Epoch 326, Validation Loss: 524156.60\n",
      "Epoch 327, Validation Loss: 479924.61\n",
      "Epoch 328, Validation Loss: 640794.68\n",
      "Epoch 329, Validation Loss: 587099.08\n",
      "Epoch 330, Validation Loss: 725245.80\n",
      "Epoch 331, Validation Loss: 474021.51\n",
      "Epoch 332, Validation Loss: 482861.92\n",
      "Epoch 333, Validation Loss: 569348.36\n",
      "Epoch 334, Validation Loss: 538413.62\n",
      "Epoch 335, Validation Loss: 509289.95\n",
      "Epoch 336, Validation Loss: 456366.90\n",
      "Epoch 337, Validation Loss: 572728.99\n",
      "Epoch 338, Validation Loss: 458206.15\n",
      "Epoch 339, Validation Loss: 462641.49\n",
      "Epoch 340, Validation Loss: 546156.16\n",
      "Epoch 341, Validation Loss: 468646.40\n",
      "Epoch 342, Validation Loss: 567690.69\n",
      "Epoch 343, Validation Loss: 592093.09\n",
      "Epoch 344, Validation Loss: 691965.89\n",
      "Epoch 345, Validation Loss: 516198.88\n",
      "Epoch 346, Validation Loss: 594811.35\n",
      "Epoch 347, Validation Loss: 559644.42\n",
      "Epoch 348, Validation Loss: 436603.37\n",
      "Epoch 349, Validation Loss: 692554.48\n",
      "Epoch 350, Validation Loss: 636516.86\n",
      "Epoch 351, Validation Loss: 682226.88\n",
      "Epoch 352, Validation Loss: 534654.24\n",
      "Epoch 353, Validation Loss: 681771.91\n",
      "Epoch 354, Validation Loss: 473113.71\n",
      "Epoch 355, Validation Loss: 4033861.72\n",
      "Epoch 356, Validation Loss: 458513.62\n",
      "Epoch 357, Validation Loss: 482182.12\n",
      "Epoch 358, Validation Loss: 518916.42\n",
      "Epoch 359, Validation Loss: 784804.67\n",
      "Epoch 360, Validation Loss: 490293.49\n",
      "Epoch 361, Validation Loss: 468783.40\n",
      "Epoch 362, Validation Loss: 902555488256.00\n",
      "Epoch 363, Validation Loss: 471996.20\n",
      "Epoch 364, Validation Loss: 457722.36\n",
      "Epoch 365, Validation Loss: 445483.63\n",
      "Epoch 366, Validation Loss: 717582.27\n",
      "Epoch 367, Validation Loss: 488460.84\n",
      "Epoch 368, Validation Loss: 668877.52\n",
      "Epoch 369, Validation Loss: 511265.85\n",
      "Epoch 370, Validation Loss: 691211.62\n",
      "Epoch 371, Validation Loss: 572826.04\n",
      "Epoch 372, Validation Loss: 537517.10\n",
      "Epoch 373, Validation Loss: 797686.70\n",
      "Epoch 374, Validation Loss: 420222.79\n",
      "Epoch 375, Validation Loss: 618144.65\n",
      "Epoch 376, Validation Loss: 656932.97\n",
      "Epoch 377, Validation Loss: 534158.14\n",
      "Epoch 378, Validation Loss: 639080.50\n",
      "Epoch 379, Validation Loss: 604255.41\n",
      "Epoch 380, Validation Loss: 479725.04\n",
      "Epoch 381, Validation Loss: 498471.55\n",
      "Epoch 382, Validation Loss: 637226.48\n",
      "Epoch 383, Validation Loss: 1153209.40\n",
      "Epoch 384, Validation Loss: 669052.28\n",
      "Epoch 385, Validation Loss: 573824.65\n",
      "Epoch 386, Validation Loss: 744780.30\n",
      "Epoch 387, Validation Loss: 506850.63\n",
      "Epoch 388, Validation Loss: 521482.70\n",
      "Epoch 389, Validation Loss: 492408.08\n",
      "Epoch 390, Validation Loss: 680390.99\n",
      "Epoch 391, Validation Loss: 603421.57\n",
      "Epoch 392, Validation Loss: 3383999.75\n",
      "Epoch 393, Validation Loss: 752742.10\n",
      "Epoch 394, Validation Loss: 479928.75\n",
      "Epoch 395, Validation Loss: 544329.49\n",
      "Epoch 396, Validation Loss: 448280.71\n",
      "Epoch 397, Validation Loss: 526586.17\n",
      "Epoch 398, Validation Loss: 628976.32\n",
      "Epoch 399, Validation Loss: 496676.49\n",
      "Epoch 400, Validation Loss: 448217.46\n",
      "Epoch 401, Validation Loss: 538858.33\n",
      "Epoch 402, Validation Loss: 444606.69\n",
      "Epoch 403, Validation Loss: 595495.48\n",
      "Epoch 404, Validation Loss: 478617.29\n",
      "Epoch 405, Validation Loss: 605168.62\n",
      "Epoch 406, Validation Loss: 535816.20\n",
      "Epoch 407, Validation Loss: 495499.94\n",
      "Epoch 408, Validation Loss: 425130.71\n",
      "Epoch 409, Validation Loss: 650730.21\n",
      "Epoch 410, Validation Loss: 720232.81\n",
      "Epoch 411, Validation Loss: 619094.87\n",
      "Epoch 412, Validation Loss: 489995.23\n",
      "Epoch 413, Validation Loss: 543493.47\n",
      "Epoch 414, Validation Loss: 608538.57\n",
      "Epoch 415, Validation Loss: 630651.22\n",
      "Epoch 416, Validation Loss: 530645.20\n",
      "Epoch 417, Validation Loss: 501013.30\n",
      "Epoch 418, Validation Loss: 524555.90\n",
      "Epoch 419, Validation Loss: 940347.20\n",
      "Epoch 420, Validation Loss: 521436.81\n",
      "Epoch 421, Validation Loss: 702123.71\n",
      "Epoch 422, Validation Loss: 423173.29\n",
      "Epoch 423, Validation Loss: 2926582.64\n",
      "Epoch 424, Validation Loss: 445766.32\n",
      "Epoch 425, Validation Loss: 470478.34\n",
      "Epoch 426, Validation Loss: 648157.79\n",
      "Epoch 427, Validation Loss: 523014.42\n",
      "Epoch 428, Validation Loss: 590973.80\n",
      "Epoch 429, Validation Loss: 476869.16\n",
      "Epoch 430, Validation Loss: 711854.17\n",
      "Epoch 431, Validation Loss: 6778209904.00\n",
      "Epoch 432, Validation Loss: 668080.95\n",
      "Epoch 433, Validation Loss: 883411.26\n",
      "Epoch 434, Validation Loss: 508905.15\n",
      "Epoch 435, Validation Loss: 477251.32\n",
      "Epoch 436, Validation Loss: 793261.79\n",
      "Epoch 437, Validation Loss: 249310827688.26\n",
      "Epoch 438, Validation Loss: 499019.56\n",
      "Epoch 439, Validation Loss: 572141.54\n",
      "Epoch 440, Validation Loss: 639883.65\n",
      "Epoch 441, Validation Loss: 445956.63\n",
      "Epoch 442, Validation Loss: 480163.04\n",
      "Epoch 443, Validation Loss: 705421.89\n",
      "Epoch 444, Validation Loss: 489042.47\n",
      "Epoch 445, Validation Loss: 461848.99\n",
      "Epoch 446, Validation Loss: 561434.94\n",
      "Epoch 447, Validation Loss: 631751.98\n",
      "Epoch 448, Validation Loss: 433302.37\n",
      "Epoch 449, Validation Loss: 450726.49\n",
      "Epoch 450, Validation Loss: 567477.40\n",
      "Epoch 451, Validation Loss: 485791.84\n",
      "Epoch 452, Validation Loss: 553108.08\n",
      "Epoch 453, Validation Loss: 543756.94\n",
      "Epoch 454, Validation Loss: 890879.80\n",
      "Epoch 455, Validation Loss: 447517.00\n",
      "Epoch 456, Validation Loss: 686196.80\n",
      "Epoch 457, Validation Loss: 549865.37\n",
      "Epoch 458, Validation Loss: 666070.22\n",
      "Epoch 459, Validation Loss: 485849.97\n",
      "Epoch 460, Validation Loss: 526059.91\n",
      "Epoch 461, Validation Loss: 72622942.59\n",
      "Epoch 462, Validation Loss: 597347.37\n",
      "Epoch 463, Validation Loss: 781673.50\n",
      "Epoch 464, Validation Loss: 773454.91\n",
      "Epoch 465, Validation Loss: 499459.94\n",
      "Epoch 466, Validation Loss: 476462.73\n",
      "Epoch 467, Validation Loss: 612072.27\n",
      "Epoch 468, Validation Loss: 493334.00\n",
      "Epoch 469, Validation Loss: 566934.31\n",
      "Epoch 470, Validation Loss: 464995.53\n",
      "Epoch 471, Validation Loss: 449347.98\n",
      "Epoch 472, Validation Loss: 67812021416140080.00\n",
      "Epoch 473, Validation Loss: 1704332.14\n",
      "Epoch 474, Validation Loss: 530262.38\n",
      "Epoch 475, Validation Loss: 777137.03\n",
      "Epoch 476, Validation Loss: 506658.94\n",
      "Epoch 477, Validation Loss: 648052.64\n",
      "Epoch 478, Validation Loss: 504691.78\n",
      "Epoch 479, Validation Loss: 782223.04\n",
      "Epoch 480, Validation Loss: 742509.77\n",
      "Epoch 481, Validation Loss: 570113.70\n",
      "Epoch 482, Validation Loss: 490606.49\n",
      "Epoch 483, Validation Loss: 552431.81\n",
      "Epoch 484, Validation Loss: 535549.72\n",
      "Epoch 485, Validation Loss: 556405.45\n",
      "Epoch 486, Validation Loss: 653403.57\n",
      "Epoch 487, Validation Loss: 623478.08\n",
      "Epoch 488, Validation Loss: 3799166602.75\n",
      "Epoch 489, Validation Loss: 481536.35\n",
      "Epoch 490, Validation Loss: 585023.93\n",
      "Epoch 491, Validation Loss: 486977.58\n",
      "Epoch 492, Validation Loss: 573506.82\n",
      "Epoch 493, Validation Loss: 499081.40\n",
      "Epoch 494, Validation Loss: 465695.79\n",
      "Epoch 495, Validation Loss: 422298.48\n",
      "Epoch 496, Validation Loss: 457967.05\n",
      "Epoch 497, Validation Loss: 494729.79\n",
      "Epoch 498, Validation Loss: 448545.41\n",
      "Epoch 499, Validation Loss: 708062.02\n",
      "Epoch 500, Validation Loss: 500976.46\n",
      "Epoch 501, Validation Loss: 798859.03\n",
      "Epoch 502, Validation Loss: 791295.79\n",
      "Epoch 503, Validation Loss: 506259.60\n",
      "Epoch 504, Validation Loss: 567094.56\n",
      "Epoch 505, Validation Loss: 689312.16\n",
      "Epoch 506, Validation Loss: 538414.46\n",
      "Epoch 507, Validation Loss: 537598.39\n",
      "Epoch 508, Validation Loss: 465563.83\n",
      "Epoch 509, Validation Loss: 524269.45\n",
      "Epoch 510, Validation Loss: 498115.45\n",
      "Epoch 511, Validation Loss: 149840292625470.31\n",
      "Epoch 512, Validation Loss: 527356.70\n",
      "Epoch 513, Validation Loss: 518959.37\n",
      "Epoch 514, Validation Loss: 590793.17\n",
      "Epoch 515, Validation Loss: 895977.35\n",
      "Epoch 516, Validation Loss: 516216988893184.00\n",
      "Epoch 517, Validation Loss: 588919.71\n",
      "Epoch 518, Validation Loss: 448343.26\n",
      "Epoch 519, Validation Loss: 667549.99\n",
      "Epoch 520, Validation Loss: 472962.52\n",
      "Epoch 521, Validation Loss: 559876.21\n",
      "Epoch 522, Validation Loss: 630642.97\n",
      "Epoch 523, Validation Loss: 505636.73\n",
      "Epoch 524, Validation Loss: 457615.34\n",
      "Epoch 525, Validation Loss: 703850.21\n",
      "Epoch 526, Validation Loss: 463396.36\n",
      "Epoch 527, Validation Loss: 10824064138477568.00\n",
      "Epoch 528, Validation Loss: 541166.12\n",
      "Epoch 529, Validation Loss: 539405.53\n",
      "Epoch 530, Validation Loss: 513063.02\n",
      "Epoch 531, Validation Loss: 477398.01\n",
      "Epoch 532, Validation Loss: 569737.28\n",
      "Epoch 533, Validation Loss: 457850.81\n",
      "Epoch 534, Validation Loss: 541040.23\n",
      "Epoch 535, Validation Loss: 477651.50\n",
      "Epoch 536, Validation Loss: 491995.01\n",
      "Epoch 537, Validation Loss: 679756.24\n",
      "Epoch 538, Validation Loss: 475330.68\n",
      "Epoch 539, Validation Loss: 464032.38\n",
      "Epoch 540, Validation Loss: 451488.20\n",
      "Epoch 541, Validation Loss: 12513329758208.00\n",
      "Epoch 542, Validation Loss: 626354.29\n",
      "Epoch 543, Validation Loss: 499961.86\n",
      "Epoch 544, Validation Loss: 846994.44\n",
      "Epoch 545, Validation Loss: 23509546053248.00\n",
      "Epoch 546, Validation Loss: 519742.34\n",
      "Epoch 547, Validation Loss: 483580.39\n",
      "Epoch 548, Validation Loss: 858045.92\n",
      "Epoch 549, Validation Loss: 479373.99\n",
      "Epoch 550, Validation Loss: 615623.33\n",
      "Epoch 551, Validation Loss: 452085.15\n",
      "Epoch 552, Validation Loss: 458358.47\n",
      "Epoch 553, Validation Loss: 450558.69\n",
      "Epoch 554, Validation Loss: 745167.81\n",
      "Epoch 555, Validation Loss: 318830935801856.00\n",
      "Epoch 556, Validation Loss: 602277.99\n",
      "Epoch 557, Validation Loss: 795056.96\n",
      "Epoch 558, Validation Loss: 612818.93\n",
      "Epoch 559, Validation Loss: 457142.10\n",
      "Epoch 560, Validation Loss: 581856.70\n",
      "Epoch 561, Validation Loss: 551556.92\n",
      "Epoch 562, Validation Loss: 851982.71\n",
      "Epoch 563, Validation Loss: 448583.24\n",
      "Epoch 564, Validation Loss: 475468.27\n",
      "Epoch 565, Validation Loss: 614803.90\n",
      "Epoch 566, Validation Loss: 899273.68\n",
      "Epoch 567, Validation Loss: 492006.07\n",
      "Epoch 568, Validation Loss: 433105.33\n",
      "Epoch 569, Validation Loss: 783242.35\n",
      "Epoch 570, Validation Loss: 628369.46\n",
      "Epoch 571, Validation Loss: 487835.45\n",
      "Epoch 572, Validation Loss: 465814.70\n",
      "Epoch 573, Validation Loss: 1432630659853.64\n",
      "Epoch 574, Validation Loss: 715268.38\n",
      "Epoch 575, Validation Loss: 534115.28\n",
      "Epoch 576, Validation Loss: 1038416.63\n",
      "Epoch 577, Validation Loss: 807015.51\n",
      "Epoch 578, Validation Loss: 505966.97\n",
      "Epoch 579, Validation Loss: 486624.46\n",
      "Epoch 580, Validation Loss: 615569.49\n",
      "Epoch 581, Validation Loss: 617390.80\n",
      "Epoch 582, Validation Loss: 475969.09\n",
      "Epoch 583, Validation Loss: 469622.32\n",
      "Epoch 584, Validation Loss: 519112.83\n",
      "Epoch 585, Validation Loss: 468694.59\n",
      "Epoch 586, Validation Loss: 509960.87\n",
      "Epoch 587, Validation Loss: 562880.02\n",
      "Epoch 588, Validation Loss: 614984461850.98\n",
      "Epoch 589, Validation Loss: 481504.34\n",
      "Epoch 590, Validation Loss: 539755.04\n",
      "Epoch 591, Validation Loss: 778988.31\n",
      "Epoch 592, Validation Loss: 480090.37\n",
      "Epoch 593, Validation Loss: 512400.50\n",
      "Epoch 594, Validation Loss: 472721.65\n",
      "Epoch 595, Validation Loss: 742560.21\n",
      "Epoch 596, Validation Loss: 11007642147225600.00\n",
      "Epoch 597, Validation Loss: 445090.45\n",
      "Epoch 598, Validation Loss: 549364.14\n",
      "Epoch 599, Validation Loss: 567935.66\n",
      "Epoch 600, Validation Loss: 484760.40\n",
      "Epoch 601, Validation Loss: 795331.84\n",
      "Epoch 602, Validation Loss: 471455.29\n",
      "Epoch 603, Validation Loss: 484845.83\n",
      "Epoch 604, Validation Loss: 457673.54\n",
      "Epoch 605, Validation Loss: 650670.72\n",
      "Epoch 606, Validation Loss: 711796.28\n",
      "Epoch 607, Validation Loss: 431246.41\n",
      "Epoch 608, Validation Loss: 465093.50\n",
      "Epoch 609, Validation Loss: 1517524090365275013120.00\n",
      "Epoch 610, Validation Loss: 458133.24\n",
      "Epoch 611, Validation Loss: 611719.97\n",
      "Epoch 612, Validation Loss: 617066.49\n",
      "Epoch 613, Validation Loss: 1376656695484219392.00\n",
      "Epoch 614, Validation Loss: 458337.27\n",
      "Epoch 615, Validation Loss: 418656.34\n",
      "Epoch 616, Validation Loss: 428934.48\n",
      "Epoch 617, Validation Loss: 496037.21\n",
      "Epoch 618, Validation Loss: 517061.17\n",
      "Epoch 619, Validation Loss: 503506.68\n",
      "Epoch 620, Validation Loss: 513006.88\n",
      "Epoch 621, Validation Loss: 529532.10\n",
      "Epoch 622, Validation Loss: 415882.54\n",
      "Epoch 623, Validation Loss: 807590.54\n",
      "Epoch 624, Validation Loss: 493808.56\n",
      "Epoch 625, Validation Loss: 483428.28\n",
      "Epoch 626, Validation Loss: 424808.30\n",
      "Epoch 627, Validation Loss: 568609.28\n",
      "Epoch 628, Validation Loss: 856166.64\n",
      "Epoch 629, Validation Loss: 448126.62\n",
      "Epoch 630, Validation Loss: 491571.59\n",
      "Epoch 631, Validation Loss: 685907.47\n",
      "Epoch 632, Validation Loss: 420203.45\n",
      "Epoch 633, Validation Loss: 69443857.19\n",
      "Epoch 634, Validation Loss: 703270.44\n",
      "Epoch 635, Validation Loss: 629667.52\n",
      "Epoch 636, Validation Loss: 436897.02\n",
      "Epoch 637, Validation Loss: 447094.88\n",
      "Epoch 638, Validation Loss: 962860.55\n",
      "Epoch 639, Validation Loss: 835476.95\n",
      "Epoch 640, Validation Loss: 593591.50\n",
      "Epoch 641, Validation Loss: 590051.77\n",
      "Epoch 642, Validation Loss: 421753.37\n",
      "Epoch 643, Validation Loss: 779117.74\n",
      "Epoch 644, Validation Loss: 647971.61\n",
      "Epoch 645, Validation Loss: 651241.39\n",
      "Epoch 646, Validation Loss: 853299.58\n",
      "Epoch 647, Validation Loss: 432440.43\n",
      "Epoch 648, Validation Loss: 601591.07\n",
      "Epoch 649, Validation Loss: 636611.47\n",
      "Epoch 650, Validation Loss: 716988.76\n",
      "Epoch 651, Validation Loss: 513714.84\n",
      "Epoch 652, Validation Loss: 530860.67\n",
      "Epoch 653, Validation Loss: 529322.01\n",
      "Epoch 654, Validation Loss: 779257.66\n",
      "Epoch 655, Validation Loss: 472269.64\n",
      "Epoch 656, Validation Loss: 599508.05\n",
      "Epoch 657, Validation Loss: 682039.91\n",
      "Epoch 658, Validation Loss: 626747.98\n",
      "Epoch 659, Validation Loss: 434658.48\n",
      "Epoch 660, Validation Loss: 507093.47\n",
      "Epoch 661, Validation Loss: 758513.56\n",
      "Epoch 662, Validation Loss: 507858.06\n",
      "Epoch 663, Validation Loss: 582755.79\n",
      "Epoch 664, Validation Loss: 799430.66\n",
      "Epoch 665, Validation Loss: 464229.08\n",
      "Epoch 666, Validation Loss: 513819.32\n",
      "Epoch 667, Validation Loss: 444718.38\n",
      "Epoch 668, Validation Loss: 638570.99\n",
      "Epoch 669, Validation Loss: 430516.21\n",
      "Epoch 670, Validation Loss: 499924.31\n",
      "Epoch 671, Validation Loss: 783289.72\n",
      "Epoch 672, Validation Loss: 594731.37\n",
      "Epoch 673, Validation Loss: 543946.23\n",
      "Epoch 674, Validation Loss: 472042.47\n",
      "Epoch 675, Validation Loss: 607923.56\n",
      "Epoch 676, Validation Loss: 700889.16\n",
      "Epoch 677, Validation Loss: 455995.45\n",
      "Epoch 678, Validation Loss: 496217.10\n",
      "Epoch 679, Validation Loss: 732796.21\n",
      "Epoch 680, Validation Loss: 805029.32\n",
      "Epoch 681, Validation Loss: 528512.59\n",
      "Epoch 682, Validation Loss: 434977.67\n",
      "Epoch 683, Validation Loss: 418472.15\n",
      "Epoch 684, Validation Loss: 439808.35\n",
      "Epoch 685, Validation Loss: 486777.37\n",
      "Epoch 686, Validation Loss: 523356.30\n",
      "Epoch 687, Validation Loss: 468845.99\n",
      "Epoch 688, Validation Loss: 478929.51\n",
      "Epoch 689, Validation Loss: 459196.10\n",
      "Epoch 690, Validation Loss: 447773.61\n",
      "Epoch 691, Validation Loss: 907466.30\n",
      "Epoch 692, Validation Loss: 588058.51\n",
      "Epoch 693, Validation Loss: 479607.47\n",
      "Epoch 694, Validation Loss: 465166.94\n",
      "Epoch 695, Validation Loss: 745726.64\n",
      "Epoch 696, Validation Loss: 698760.72\n",
      "Epoch 697, Validation Loss: 489446.89\n",
      "Epoch 698, Validation Loss: 564297.03\n",
      "Epoch 699, Validation Loss: 427129.70\n",
      "Epoch 700, Validation Loss: 513785.33\n",
      "Epoch 701, Validation Loss: 687080.62\n",
      "Epoch 702, Validation Loss: 436878.42\n",
      "Epoch 703, Validation Loss: 641027.07\n",
      "Epoch 704, Validation Loss: 806963.74\n",
      "Epoch 705, Validation Loss: 857173.99\n",
      "Epoch 706, Validation Loss: 446761.63\n",
      "Epoch 707, Validation Loss: 555560.91\n",
      "Epoch 708, Validation Loss: 638768.85\n",
      "Epoch 709, Validation Loss: 660778.49\n",
      "Epoch 710, Validation Loss: 533498.90\n",
      "Epoch 711, Validation Loss: 475608.29\n",
      "Epoch 712, Validation Loss: 754665.70\n",
      "Epoch 713, Validation Loss: 436165.19\n",
      "Epoch 714, Validation Loss: 467629.99\n",
      "Epoch 715, Validation Loss: 816940.87\n",
      "Epoch 716, Validation Loss: 533934.71\n",
      "Epoch 717, Validation Loss: 474391.21\n",
      "Epoch 718, Validation Loss: 625653.61\n",
      "Epoch 719, Validation Loss: 487875.02\n",
      "Epoch 720, Validation Loss: 845340.70\n",
      "Epoch 721, Validation Loss: 503338.61\n",
      "Epoch 722, Validation Loss: 601369.10\n",
      "Epoch 723, Validation Loss: 850683.89\n",
      "Epoch 724, Validation Loss: 749624.36\n",
      "Epoch 725, Validation Loss: 528899.61\n",
      "Epoch 726, Validation Loss: 673843.50\n",
      "Epoch 727, Validation Loss: 588307.45\n",
      "Epoch 728, Validation Loss: 431896.64\n",
      "Epoch 729, Validation Loss: 752191.30\n",
      "Epoch 730, Validation Loss: 444844.79\n",
      "Epoch 731, Validation Loss: 522525.77\n",
      "Epoch 732, Validation Loss: 499135.19\n",
      "Epoch 733, Validation Loss: 449333.00\n",
      "Epoch 734, Validation Loss: 473082.42\n",
      "Epoch 735, Validation Loss: 617975.90\n",
      "Epoch 736, Validation Loss: 784177.81\n",
      "Epoch 737, Validation Loss: 547894.87\n",
      "Epoch 738, Validation Loss: 560539.12\n",
      "Epoch 739, Validation Loss: 737100.70\n",
      "Epoch 740, Validation Loss: 718795.54\n",
      "Epoch 741, Validation Loss: 798961.71\n",
      "Epoch 742, Validation Loss: 441974.64\n",
      "Epoch 743, Validation Loss: 440792.35\n",
      "Epoch 744, Validation Loss: 496979.46\n",
      "Epoch 745, Validation Loss: 639538.02\n",
      "Epoch 746, Validation Loss: 585426.19\n",
      "Epoch 747, Validation Loss: 635411.57\n",
      "Epoch 748, Validation Loss: 522365.51\n",
      "Epoch 749, Validation Loss: 493307.77\n",
      "Epoch 750, Validation Loss: 520314.68\n",
      "Epoch 751, Validation Loss: 542956.52\n",
      "Epoch 752, Validation Loss: 485172.26\n",
      "Epoch 753, Validation Loss: 599066.66\n",
      "Epoch 754, Validation Loss: 535421.43\n",
      "Epoch 755, Validation Loss: 479306.78\n",
      "Epoch 756, Validation Loss: 802398.06\n",
      "Epoch 757, Validation Loss: 835022.32\n",
      "Epoch 758, Validation Loss: 441147.06\n",
      "Epoch 759, Validation Loss: 613178.48\n",
      "Epoch 760, Validation Loss: 700096.34\n",
      "Epoch 761, Validation Loss: 702791.53\n",
      "Epoch 762, Validation Loss: 434097.84\n",
      "Epoch 763, Validation Loss: 445669.00\n",
      "Epoch 764, Validation Loss: 681017.80\n",
      "Epoch 765, Validation Loss: 661230.92\n",
      "Epoch 766, Validation Loss: 463315.26\n",
      "Epoch 767, Validation Loss: 477474.42\n",
      "Epoch 768, Validation Loss: 514323.19\n",
      "Epoch 769, Validation Loss: 706052.44\n",
      "Epoch 770, Validation Loss: 554551.05\n",
      "Epoch 771, Validation Loss: 614686.54\n",
      "Epoch 772, Validation Loss: 786525.23\n",
      "Epoch 773, Validation Loss: 557252.71\n",
      "Epoch 774, Validation Loss: 473149.59\n",
      "Epoch 775, Validation Loss: 825306.52\n",
      "Epoch 776, Validation Loss: 1102412219209.71\n",
      "Epoch 777, Validation Loss: 537524.89\n",
      "Epoch 778, Validation Loss: 485310.16\n",
      "Epoch 779, Validation Loss: 725557.68\n",
      "Epoch 780, Validation Loss: 788470.77\n",
      "Epoch 781, Validation Loss: 483644.72\n",
      "Epoch 782, Validation Loss: 453755.30\n",
      "Epoch 783, Validation Loss: 774115.67\n",
      "Epoch 784, Validation Loss: 444152.13\n",
      "Epoch 785, Validation Loss: 602758.13\n",
      "Epoch 786, Validation Loss: 497234.62\n",
      "Epoch 787, Validation Loss: 839182.60\n",
      "Epoch 788, Validation Loss: 519402.98\n",
      "Epoch 789, Validation Loss: 503851.77\n",
      "Epoch 790, Validation Loss: 861381.80\n",
      "Epoch 791, Validation Loss: 620065.21\n",
      "Epoch 792, Validation Loss: 475844.96\n",
      "Epoch 793, Validation Loss: 863046.08\n",
      "Epoch 794, Validation Loss: 1497286.55\n",
      "Epoch 795, Validation Loss: 523532.52\n",
      "Epoch 796, Validation Loss: 529162.24\n",
      "Epoch 797, Validation Loss: 745483.54\n",
      "Epoch 798, Validation Loss: 550035.48\n",
      "Epoch 799, Validation Loss: 427951.09\n",
      "Epoch 800, Validation Loss: 644162.82\n",
      "Epoch 801, Validation Loss: 770662.61\n",
      "Epoch 802, Validation Loss: 628378.94\n",
      "Epoch 803, Validation Loss: 555529.42\n",
      "Epoch 804, Validation Loss: 631898.33\n",
      "Epoch 805, Validation Loss: 717313.43\n",
      "Epoch 806, Validation Loss: 599841.91\n",
      "Epoch 807, Validation Loss: 545149.43\n",
      "Epoch 808, Validation Loss: 579609.33\n",
      "Epoch 809, Validation Loss: 532153.24\n",
      "Epoch 810, Validation Loss: 670913.50\n",
      "Epoch 811, Validation Loss: 515257.27\n",
      "Epoch 812, Validation Loss: 820262.61\n",
      "Epoch 813, Validation Loss: 498898.87\n",
      "Epoch 814, Validation Loss: 476418.83\n",
      "Epoch 815, Validation Loss: 514312.45\n",
      "Epoch 816, Validation Loss: 479215.04\n",
      "Epoch 817, Validation Loss: 439138.26\n",
      "Epoch 818, Validation Loss: 860764.29\n",
      "Epoch 819, Validation Loss: 852549.09\n",
      "Epoch 820, Validation Loss: 449129.56\n",
      "Epoch 821, Validation Loss: 431844.65\n",
      "Early stopping at epoch 821\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 1107.14 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 2000                   # number of training epochs\n",
    "warmup = 400                    # number of epochs to wait before enacting early stopping policy\n",
    "patience = 200                  # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Obj Val  Constraints Viol  Elapsed Time\n",
      "count     100.000000        100.000000    100.000000\n",
      "mean    71153.106690       3494.335871      0.044617\n",
      "std     41521.282294       5338.217303      0.004960\n",
      "min     29406.999489          0.000000      0.010635\n",
      "25%     39667.823104          0.000000      0.044043\n",
      "50%     62969.347254          0.000000      0.044551\n",
      "75%     74510.622683       5494.146586      0.046336\n",
      "max    202908.713203      20595.257874      0.050940\n",
      "Number of infeasible solution: 47\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lr_50-10000_s.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7912a689-22cd-4d7b-a50f-d136dbdf5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                          int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 2346129.37\n",
      "Epoch 1, Validation Loss: 2901645520.00\n",
      "Epoch 2, Validation Loss: 520412239872.00\n",
      "Epoch 3, Validation Loss: 441771270144.00\n",
      "Epoch 4, Validation Loss: 14536662.56\n",
      "Epoch 5, Validation Loss: 3396917.30\n",
      "Epoch 6, Validation Loss: 3139643.17\n",
      "Epoch 7, Validation Loss: 25771237.62\n",
      "Epoch 8, Validation Loss: 1617424.49\n",
      "Epoch 9, Validation Loss: 942228.27\n",
      "Epoch 10, Validation Loss: 925896.19\n",
      "Epoch 11, Validation Loss: 839255.34\n",
      "Epoch 12, Validation Loss: 1338706.82\n",
      "Epoch 13, Validation Loss: 1627481.77\n",
      "Epoch 14, Validation Loss: 833669.55\n",
      "Epoch 15, Validation Loss: 1223276.12\n",
      "Epoch 16, Validation Loss: 570126.07\n",
      "Epoch 17, Validation Loss: 1412495.75\n",
      "Epoch 18, Validation Loss: 1928513.25\n",
      "Epoch 19, Validation Loss: 807339.38\n",
      "Epoch 20, Validation Loss: 698801.66\n",
      "Epoch 21, Validation Loss: 1538501.50\n",
      "Epoch 22, Validation Loss: 939586.76\n",
      "Epoch 23, Validation Loss: 523234.65\n",
      "Epoch 24, Validation Loss: 1209823.64\n",
      "Epoch 25, Validation Loss: 837182.74\n",
      "Epoch 26, Validation Loss: 535733.23\n",
      "Epoch 27, Validation Loss: 734581.72\n",
      "Epoch 28, Validation Loss: 514821.72\n",
      "Epoch 29, Validation Loss: 949654.07\n",
      "Epoch 30, Validation Loss: 2433879.84\n",
      "Epoch 31, Validation Loss: 740765.93\n",
      "Epoch 32, Validation Loss: 805103.39\n",
      "Epoch 33, Validation Loss: 1123236.16\n",
      "Epoch 34, Validation Loss: 886314.67\n",
      "Epoch 35, Validation Loss: 1680305.49\n",
      "Epoch 36, Validation Loss: 1598072.86\n",
      "Epoch 37, Validation Loss: 622755.25\n",
      "Epoch 38, Validation Loss: 1009257.39\n",
      "Epoch 39, Validation Loss: 1023089.49\n",
      "Epoch 40, Validation Loss: 808170.39\n",
      "Epoch 41, Validation Loss: 686894.13\n",
      "Epoch 42, Validation Loss: 684008.27\n",
      "Epoch 43, Validation Loss: 1214628.85\n",
      "Epoch 44, Validation Loss: 593872.06\n",
      "Epoch 45, Validation Loss: 692849.47\n",
      "Epoch 46, Validation Loss: 693727.43\n",
      "Epoch 47, Validation Loss: 827442.43\n",
      "Epoch 48, Validation Loss: 889822.50\n",
      "Epoch 49, Validation Loss: 833012.09\n",
      "Epoch 50, Validation Loss: 930633.88\n",
      "Epoch 51, Validation Loss: 1518843.14\n",
      "Epoch 52, Validation Loss: 498177.00\n",
      "Epoch 53, Validation Loss: 542235.60\n",
      "Epoch 54, Validation Loss: 1431900.31\n",
      "Epoch 55, Validation Loss: 804275.81\n",
      "Epoch 56, Validation Loss: 477452.46\n",
      "Epoch 57, Validation Loss: 629762.02\n",
      "Epoch 58, Validation Loss: 979088.06\n",
      "Epoch 59, Validation Loss: 719532.31\n",
      "Epoch 60, Validation Loss: 1024051.96\n",
      "Epoch 61, Validation Loss: 524672.87\n",
      "Epoch 62, Validation Loss: 534529.89\n",
      "Epoch 63, Validation Loss: 482039.29\n",
      "Epoch 64, Validation Loss: 531409.67\n",
      "Epoch 65, Validation Loss: 550239.83\n",
      "Epoch 66, Validation Loss: 557396.49\n",
      "Epoch 67, Validation Loss: 799940.75\n",
      "Epoch 68, Validation Loss: 522172.48\n",
      "Epoch 69, Validation Loss: 1272501.48\n",
      "Epoch 70, Validation Loss: 725573.48\n",
      "Epoch 71, Validation Loss: 594478.13\n",
      "Epoch 72, Validation Loss: 1541853.08\n",
      "Epoch 73, Validation Loss: 50284187.38\n",
      "Epoch 74, Validation Loss: 654990.86\n",
      "Epoch 75, Validation Loss: 678040.38\n",
      "Epoch 76, Validation Loss: 520323.13\n",
      "Epoch 77, Validation Loss: 850829.39\n",
      "Epoch 78, Validation Loss: 540279.41\n",
      "Epoch 79, Validation Loss: 582493.82\n",
      "Epoch 80, Validation Loss: 634646.89\n",
      "Epoch 81, Validation Loss: 1146479.20\n",
      "Epoch 82, Validation Loss: 553067.49\n",
      "Epoch 83, Validation Loss: 556079.11\n",
      "Epoch 84, Validation Loss: 485771.94\n",
      "Epoch 85, Validation Loss: 915110.75\n",
      "Epoch 86, Validation Loss: 632642.59\n",
      "Epoch 87, Validation Loss: 942066.67\n",
      "Epoch 88, Validation Loss: 800861.55\n",
      "Epoch 89, Validation Loss: 795694.79\n",
      "Epoch 90, Validation Loss: 668222.17\n",
      "Epoch 91, Validation Loss: 909995.86\n",
      "Epoch 92, Validation Loss: 494357.21\n",
      "Epoch 93, Validation Loss: 486458.07\n",
      "Epoch 94, Validation Loss: 532172.55\n",
      "Epoch 95, Validation Loss: 500807.35\n",
      "Epoch 96, Validation Loss: 476579.93\n",
      "Epoch 97, Validation Loss: 663047.20\n",
      "Epoch 98, Validation Loss: 575679.37\n",
      "Epoch 99, Validation Loss: 513742.35\n",
      "Epoch 100, Validation Loss: 528874.32\n",
      "Epoch 101, Validation Loss: 788461.36\n",
      "Epoch 102, Validation Loss: 537048.52\n",
      "Epoch 103, Validation Loss: 689251.52\n",
      "Epoch 104, Validation Loss: 797466.59\n",
      "Epoch 105, Validation Loss: 515345.56\n",
      "Epoch 106, Validation Loss: 467331.10\n",
      "Epoch 107, Validation Loss: 557732.39\n",
      "Epoch 108, Validation Loss: 460650.85\n",
      "Epoch 109, Validation Loss: 718896.14\n",
      "Epoch 110, Validation Loss: 509928.62\n",
      "Epoch 111, Validation Loss: 587159.24\n",
      "Epoch 112, Validation Loss: 492140.23\n",
      "Epoch 113, Validation Loss: 619738.88\n",
      "Epoch 114, Validation Loss: 496768.07\n",
      "Epoch 115, Validation Loss: 596516.67\n",
      "Epoch 116, Validation Loss: 816100.49\n",
      "Epoch 117, Validation Loss: 688988.76\n",
      "Epoch 118, Validation Loss: 458217.08\n",
      "Epoch 119, Validation Loss: 8108451.30\n",
      "Epoch 120, Validation Loss: 807648.71\n",
      "Epoch 121, Validation Loss: 520850.69\n",
      "Epoch 122, Validation Loss: 540053.85\n",
      "Epoch 123, Validation Loss: 528488.26\n",
      "Epoch 124, Validation Loss: 549966.81\n",
      "Epoch 125, Validation Loss: 566823.91\n",
      "Epoch 126, Validation Loss: 503919.64\n",
      "Epoch 127, Validation Loss: 703812.27\n",
      "Epoch 128, Validation Loss: 733509.68\n",
      "Epoch 129, Validation Loss: 575145.70\n",
      "Epoch 130, Validation Loss: 606946.50\n",
      "Epoch 131, Validation Loss: 628578.07\n",
      "Epoch 132, Validation Loss: 598479.13\n",
      "Epoch 133, Validation Loss: 506947.85\n",
      "Epoch 134, Validation Loss: 476598.45\n",
      "Epoch 135, Validation Loss: 685464.82\n",
      "Epoch 136, Validation Loss: 598576.31\n",
      "Epoch 137, Validation Loss: 1629578548518066323456.00\n",
      "Epoch 138, Validation Loss: 603268.25\n",
      "Epoch 139, Validation Loss: 700888.23\n",
      "Epoch 140, Validation Loss: 521458.63\n",
      "Epoch 141, Validation Loss: 672820.84\n",
      "Epoch 142, Validation Loss: 600265.96\n",
      "Epoch 143, Validation Loss: 469175.82\n",
      "Epoch 144, Validation Loss: 504076.57\n",
      "Epoch 145, Validation Loss: 492086.23\n",
      "Epoch 146, Validation Loss: 834576.37\n",
      "Epoch 147, Validation Loss: 547249.09\n",
      "Epoch 148, Validation Loss: 506555.62\n",
      "Epoch 149, Validation Loss: 557906.09\n",
      "Epoch 150, Validation Loss: 592477.79\n",
      "Epoch 151, Validation Loss: 616456.01\n",
      "Epoch 152, Validation Loss: 472145.66\n",
      "Epoch 153, Validation Loss: 636606.23\n",
      "Epoch 154, Validation Loss: 774405.83\n",
      "Epoch 155, Validation Loss: 683110.68\n",
      "Epoch 156, Validation Loss: 489283.59\n",
      "Epoch 157, Validation Loss: 623616.55\n",
      "Epoch 158, Validation Loss: 604936.10\n",
      "Epoch 159, Validation Loss: 491483.07\n",
      "Epoch 160, Validation Loss: 497363.17\n",
      "Epoch 161, Validation Loss: 489907.84\n",
      "Epoch 162, Validation Loss: 489293.92\n",
      "Epoch 163, Validation Loss: 488306.01\n",
      "Epoch 164, Validation Loss: 580855.87\n",
      "Epoch 165, Validation Loss: 517260.41\n",
      "Epoch 166, Validation Loss: 497588.34\n",
      "Epoch 167, Validation Loss: 479550.18\n",
      "Epoch 168, Validation Loss: 480993.70\n",
      "Epoch 169, Validation Loss: 504387.65\n",
      "Epoch 170, Validation Loss: 570262.66\n",
      "Epoch 171, Validation Loss: 539488.35\n",
      "Epoch 172, Validation Loss: 478981.56\n",
      "Epoch 173, Validation Loss: 469726.31\n",
      "Epoch 174, Validation Loss: 592904.50\n",
      "Epoch 175, Validation Loss: 520525.62\n",
      "Epoch 176, Validation Loss: 554176.94\n",
      "Epoch 177, Validation Loss: 497296.95\n",
      "Epoch 178, Validation Loss: 672254.54\n",
      "Epoch 179, Validation Loss: 674268.75\n",
      "Epoch 180, Validation Loss: 572654.04\n",
      "Epoch 181, Validation Loss: 501014.77\n",
      "Epoch 182, Validation Loss: 613157.46\n",
      "Epoch 183, Validation Loss: 617361.82\n",
      "Epoch 184, Validation Loss: 512200.55\n",
      "Epoch 185, Validation Loss: 496198.50\n",
      "Epoch 186, Validation Loss: 516791.83\n",
      "Epoch 187, Validation Loss: 564730.67\n",
      "Epoch 188, Validation Loss: 704349.52\n",
      "Epoch 189, Validation Loss: 478686.77\n",
      "Epoch 190, Validation Loss: 504975.94\n",
      "Epoch 191, Validation Loss: 712276.39\n",
      "Epoch 192, Validation Loss: 542154.65\n",
      "Epoch 193, Validation Loss: 633287.34\n",
      "Epoch 194, Validation Loss: 600799.92\n",
      "Epoch 195, Validation Loss: 468736.67\n",
      "Epoch 196, Validation Loss: 475215.31\n",
      "Epoch 197, Validation Loss: 950632.30\n",
      "Epoch 198, Validation Loss: 566066.88\n",
      "Epoch 199, Validation Loss: 500864.04\n",
      "Epoch 200, Validation Loss: 529552.19\n",
      "Epoch 201, Validation Loss: 845556.36\n",
      "Epoch 202, Validation Loss: 501194.53\n",
      "Epoch 203, Validation Loss: 750993.02\n",
      "Epoch 204, Validation Loss: 524455.92\n",
      "Epoch 205, Validation Loss: 460888.06\n",
      "Epoch 206, Validation Loss: 543341.16\n",
      "Epoch 207, Validation Loss: 508238.28\n",
      "Epoch 208, Validation Loss: 537867.30\n",
      "Epoch 209, Validation Loss: 698131.82\n",
      "Epoch 210, Validation Loss: 540994.58\n",
      "Epoch 211, Validation Loss: 512827.65\n",
      "Epoch 212, Validation Loss: 515970.73\n",
      "Epoch 213, Validation Loss: 597913.73\n",
      "Epoch 214, Validation Loss: 583457.94\n",
      "Epoch 215, Validation Loss: 491518.88\n",
      "Epoch 216, Validation Loss: 565047.15\n",
      "Epoch 217, Validation Loss: 547954.46\n",
      "Epoch 218, Validation Loss: 512314.62\n",
      "Epoch 219, Validation Loss: 460541.28\n",
      "Epoch 220, Validation Loss: 569209.22\n",
      "Epoch 221, Validation Loss: 569128.88\n",
      "Epoch 222, Validation Loss: 570996.93\n",
      "Epoch 223, Validation Loss: 597411.39\n",
      "Epoch 224, Validation Loss: 520347.72\n",
      "Epoch 225, Validation Loss: 700721.08\n",
      "Epoch 226, Validation Loss: 558187.15\n",
      "Epoch 227, Validation Loss: 468457.39\n",
      "Epoch 228, Validation Loss: 482090.89\n",
      "Epoch 229, Validation Loss: 496496.32\n",
      "Epoch 230, Validation Loss: 497109.66\n",
      "Epoch 231, Validation Loss: 686903.62\n",
      "Epoch 232, Validation Loss: 639257.78\n",
      "Epoch 233, Validation Loss: 563338.99\n",
      "Epoch 234, Validation Loss: 666968.59\n",
      "Epoch 235, Validation Loss: 610126.89\n",
      "Epoch 236, Validation Loss: 518230.45\n",
      "Epoch 237, Validation Loss: 573554.64\n",
      "Epoch 238, Validation Loss: 523889.01\n",
      "Epoch 239, Validation Loss: 771310.62\n",
      "Epoch 240, Validation Loss: 522113.72\n",
      "Epoch 241, Validation Loss: 621394.88\n",
      "Epoch 242, Validation Loss: 527074.03\n",
      "Epoch 243, Validation Loss: 548764.40\n",
      "Epoch 244, Validation Loss: 575703.41\n",
      "Epoch 245, Validation Loss: 566109.99\n",
      "Epoch 246, Validation Loss: 481946.36\n",
      "Epoch 247, Validation Loss: 560292.01\n",
      "Epoch 248, Validation Loss: 483596.12\n",
      "Epoch 249, Validation Loss: 742298.81\n",
      "Epoch 250, Validation Loss: 509631.16\n",
      "Epoch 251, Validation Loss: 522433.45\n",
      "Epoch 252, Validation Loss: 463996.18\n",
      "Epoch 253, Validation Loss: 739927.45\n",
      "Epoch 254, Validation Loss: 655751.54\n",
      "Epoch 255, Validation Loss: 486590.75\n",
      "Epoch 256, Validation Loss: 471122.15\n",
      "Epoch 257, Validation Loss: 485395.55\n",
      "Epoch 258, Validation Loss: 557529.59\n",
      "Epoch 259, Validation Loss: 539932.58\n",
      "Epoch 260, Validation Loss: 495828.45\n",
      "Epoch 261, Validation Loss: 653745.76\n",
      "Epoch 262, Validation Loss: 476160.93\n",
      "Epoch 263, Validation Loss: 608578.84\n",
      "Epoch 264, Validation Loss: 461457.77\n",
      "Epoch 265, Validation Loss: 492833.43\n",
      "Epoch 266, Validation Loss: 467345.59\n",
      "Epoch 267, Validation Loss: 539792.27\n",
      "Epoch 268, Validation Loss: 504406.75\n",
      "Epoch 269, Validation Loss: 480934.00\n",
      "Epoch 270, Validation Loss: 606231.82\n",
      "Epoch 271, Validation Loss: 448070.57\n",
      "Epoch 272, Validation Loss: 529314.99\n",
      "Epoch 273, Validation Loss: 524813.04\n",
      "Epoch 274, Validation Loss: 566294.51\n",
      "Epoch 275, Validation Loss: 506215.02\n",
      "Epoch 276, Validation Loss: 474620.80\n",
      "Epoch 277, Validation Loss: 463044.16\n",
      "Epoch 278, Validation Loss: 556871.50\n",
      "Epoch 279, Validation Loss: 511209.09\n",
      "Epoch 280, Validation Loss: 597147.93\n",
      "Epoch 281, Validation Loss: 466177.81\n",
      "Epoch 282, Validation Loss: 589224.55\n",
      "Epoch 283, Validation Loss: 533990.63\n",
      "Epoch 284, Validation Loss: 484233.38\n",
      "Epoch 285, Validation Loss: 611648.59\n",
      "Epoch 286, Validation Loss: 587831.52\n",
      "Epoch 287, Validation Loss: 469782.41\n",
      "Epoch 288, Validation Loss: 693807.19\n",
      "Epoch 289, Validation Loss: 481909.41\n",
      "Epoch 290, Validation Loss: 544178.14\n",
      "Epoch 291, Validation Loss: 509371.64\n",
      "Epoch 292, Validation Loss: 573900.36\n",
      "Epoch 293, Validation Loss: 524632.91\n",
      "Epoch 294, Validation Loss: 477044.00\n",
      "Epoch 295, Validation Loss: 489804.50\n",
      "Epoch 296, Validation Loss: 490384.25\n",
      "Epoch 297, Validation Loss: 494865.70\n",
      "Epoch 298, Validation Loss: 542327.65\n",
      "Epoch 299, Validation Loss: 558890.34\n",
      "Epoch 300, Validation Loss: 552383.34\n",
      "Epoch 301, Validation Loss: 500216.03\n",
      "Epoch 302, Validation Loss: 449561.37\n",
      "Epoch 303, Validation Loss: 466661.21\n",
      "Epoch 304, Validation Loss: 503441.35\n",
      "Epoch 305, Validation Loss: 503025.64\n",
      "Epoch 306, Validation Loss: 475539.09\n",
      "Epoch 307, Validation Loss: 541087.21\n",
      "Epoch 308, Validation Loss: 727077.41\n",
      "Epoch 309, Validation Loss: 567154.73\n",
      "Epoch 310, Validation Loss: 545546.18\n",
      "Epoch 311, Validation Loss: 491756.13\n",
      "Epoch 312, Validation Loss: 709004.00\n",
      "Epoch 313, Validation Loss: 614661.41\n",
      "Epoch 314, Validation Loss: 475674.03\n",
      "Epoch 315, Validation Loss: 483729.31\n",
      "Epoch 316, Validation Loss: 498474.31\n",
      "Epoch 317, Validation Loss: 569451.44\n",
      "Epoch 318, Validation Loss: 563216.04\n",
      "Epoch 319, Validation Loss: 511335.03\n",
      "Epoch 320, Validation Loss: 564829.68\n",
      "Epoch 321, Validation Loss: 511619.58\n",
      "Epoch 322, Validation Loss: 704003.50\n",
      "Epoch 323, Validation Loss: 456401.68\n",
      "Epoch 324, Validation Loss: 481692.72\n",
      "Epoch 325, Validation Loss: 469959.17\n",
      "Epoch 326, Validation Loss: 542674.77\n",
      "Epoch 327, Validation Loss: 562181.17\n",
      "Epoch 328, Validation Loss: 478627.46\n",
      "Epoch 329, Validation Loss: 626075.12\n",
      "Epoch 330, Validation Loss: 533846.33\n",
      "Epoch 331, Validation Loss: 652492.91\n",
      "Epoch 332, Validation Loss: 535064.21\n",
      "Epoch 333, Validation Loss: 690166.87\n",
      "Epoch 334, Validation Loss: 510113.06\n",
      "Epoch 335, Validation Loss: 455545.18\n",
      "Epoch 336, Validation Loss: 551774.45\n",
      "Epoch 337, Validation Loss: 451367.52\n",
      "Epoch 338, Validation Loss: 732130.09\n",
      "Epoch 339, Validation Loss: 593702.56\n",
      "Epoch 340, Validation Loss: 515826.75\n",
      "Epoch 341, Validation Loss: 580277.57\n",
      "Epoch 342, Validation Loss: 734317.69\n",
      "Epoch 343, Validation Loss: 463932.61\n",
      "Epoch 344, Validation Loss: 452822.39\n",
      "Epoch 345, Validation Loss: 620089.60\n",
      "Epoch 346, Validation Loss: 600491.72\n",
      "Epoch 347, Validation Loss: 458866.76\n",
      "Epoch 348, Validation Loss: 552633.21\n",
      "Epoch 349, Validation Loss: 721340.71\n",
      "Epoch 350, Validation Loss: 500692.91\n",
      "Epoch 351, Validation Loss: 421678.45\n",
      "Epoch 352, Validation Loss: 520097.67\n",
      "Epoch 353, Validation Loss: 476065.64\n",
      "Epoch 354, Validation Loss: 486857.94\n",
      "Epoch 355, Validation Loss: 731142.71\n",
      "Epoch 356, Validation Loss: 499974.06\n",
      "Epoch 357, Validation Loss: 518819.80\n",
      "Epoch 358, Validation Loss: 1051224.70\n",
      "Epoch 359, Validation Loss: 504734.16\n",
      "Epoch 360, Validation Loss: 524929.38\n",
      "Epoch 361, Validation Loss: 612586.59\n",
      "Epoch 362, Validation Loss: 487771.13\n",
      "Epoch 363, Validation Loss: 449055.50\n",
      "Epoch 364, Validation Loss: 621310.40\n",
      "Epoch 365, Validation Loss: 593015.32\n",
      "Epoch 366, Validation Loss: 492936.27\n",
      "Epoch 367, Validation Loss: 489456.04\n",
      "Epoch 368, Validation Loss: 441799.39\n",
      "Epoch 369, Validation Loss: 569415.87\n",
      "Epoch 370, Validation Loss: 477578.53\n",
      "Epoch 371, Validation Loss: 488487.93\n",
      "Epoch 372, Validation Loss: 510264.57\n",
      "Epoch 373, Validation Loss: 492329.42\n",
      "Epoch 374, Validation Loss: 464606.84\n",
      "Epoch 375, Validation Loss: 598170.01\n",
      "Epoch 376, Validation Loss: 528711.68\n",
      "Epoch 377, Validation Loss: 816409.83\n",
      "Epoch 378, Validation Loss: 740254.03\n",
      "Epoch 379, Validation Loss: 538560.15\n",
      "Epoch 380, Validation Loss: 509986.21\n",
      "Epoch 381, Validation Loss: 429935.99\n",
      "Epoch 382, Validation Loss: 435948.39\n",
      "Epoch 383, Validation Loss: 560285.70\n",
      "Epoch 384, Validation Loss: 496233.19\n",
      "Epoch 385, Validation Loss: 480992.38\n",
      "Epoch 386, Validation Loss: 447892.05\n",
      "Epoch 387, Validation Loss: 465127.12\n",
      "Epoch 388, Validation Loss: 543526.19\n",
      "Epoch 389, Validation Loss: 765401.68\n",
      "Epoch 390, Validation Loss: 804124.70\n",
      "Epoch 391, Validation Loss: 526349.87\n",
      "Epoch 392, Validation Loss: 597095.35\n",
      "Epoch 393, Validation Loss: 506740.56\n",
      "Epoch 394, Validation Loss: 471494.86\n",
      "Epoch 395, Validation Loss: 512723.17\n",
      "Epoch 396, Validation Loss: 575341.58\n",
      "Epoch 397, Validation Loss: 490971.77\n",
      "Epoch 398, Validation Loss: 660481.13\n",
      "Epoch 399, Validation Loss: 818894.64\n",
      "Epoch 400, Validation Loss: 597258.41\n",
      "Epoch 401, Validation Loss: 624767.37\n",
      "Epoch 402, Validation Loss: 439080.50\n",
      "Epoch 403, Validation Loss: 460376.76\n",
      "Epoch 404, Validation Loss: 442671.42\n",
      "Epoch 405, Validation Loss: 653227.55\n",
      "Epoch 406, Validation Loss: 617717.81\n",
      "Epoch 407, Validation Loss: 451188.66\n",
      "Epoch 408, Validation Loss: 720921.41\n",
      "Epoch 409, Validation Loss: 521278.99\n",
      "Epoch 410, Validation Loss: 493747.61\n",
      "Epoch 411, Validation Loss: 799820.29\n",
      "Epoch 412, Validation Loss: 682978.71\n",
      "Epoch 413, Validation Loss: 418363.12\n",
      "Epoch 414, Validation Loss: 468417.60\n",
      "Epoch 415, Validation Loss: 605967.41\n",
      "Epoch 416, Validation Loss: 558845.75\n",
      "Epoch 417, Validation Loss: 577034.47\n",
      "Epoch 418, Validation Loss: 683124.70\n",
      "Epoch 419, Validation Loss: 721678.63\n",
      "Epoch 420, Validation Loss: 533444.00\n",
      "Epoch 421, Validation Loss: 556684.78\n",
      "Epoch 422, Validation Loss: 541632.06\n",
      "Epoch 423, Validation Loss: 445817.28\n",
      "Epoch 424, Validation Loss: 497579.55\n",
      "Epoch 425, Validation Loss: 435149.88\n",
      "Epoch 426, Validation Loss: 702715.03\n",
      "Epoch 427, Validation Loss: 475514.58\n",
      "Epoch 428, Validation Loss: 428955.61\n",
      "Epoch 429, Validation Loss: 898508.51\n",
      "Epoch 430, Validation Loss: 545719.87\n",
      "Epoch 431, Validation Loss: 622523.08\n",
      "Epoch 432, Validation Loss: 600272.37\n",
      "Epoch 433, Validation Loss: 442459.80\n",
      "Epoch 434, Validation Loss: 593972.11\n",
      "Epoch 435, Validation Loss: 488285.56\n",
      "Epoch 436, Validation Loss: 587437.87\n",
      "Epoch 437, Validation Loss: 532867.09\n",
      "Epoch 438, Validation Loss: 626659.04\n",
      "Epoch 439, Validation Loss: 765753.83\n",
      "Epoch 440, Validation Loss: 425050.72\n",
      "Epoch 441, Validation Loss: 502874.64\n",
      "Epoch 442, Validation Loss: 659269.93\n",
      "Epoch 443, Validation Loss: 446192.33\n",
      "Epoch 444, Validation Loss: 564461.30\n",
      "Epoch 445, Validation Loss: 800302.08\n",
      "Epoch 446, Validation Loss: 617547.61\n",
      "Epoch 447, Validation Loss: 432284.21\n",
      "Epoch 448, Validation Loss: 475355.49\n",
      "Epoch 449, Validation Loss: 626834.81\n",
      "Epoch 450, Validation Loss: 537020.08\n",
      "Epoch 451, Validation Loss: 434650.97\n",
      "Epoch 452, Validation Loss: 653101.56\n",
      "Epoch 453, Validation Loss: 492043.07\n",
      "Epoch 454, Validation Loss: 441954.81\n",
      "Epoch 455, Validation Loss: 664773.62\n",
      "Epoch 456, Validation Loss: 785487.35\n",
      "Epoch 457, Validation Loss: 514215.87\n",
      "Epoch 458, Validation Loss: 513243.49\n",
      "Epoch 459, Validation Loss: 697965.28\n",
      "Epoch 460, Validation Loss: 499268.13\n",
      "Epoch 461, Validation Loss: 766212.12\n",
      "Epoch 462, Validation Loss: 642689.62\n",
      "Epoch 463, Validation Loss: 632522.37\n",
      "Epoch 464, Validation Loss: 475152.57\n",
      "Epoch 465, Validation Loss: 428360.37\n",
      "Epoch 466, Validation Loss: 707163.07\n",
      "Epoch 467, Validation Loss: 474622.86\n",
      "Epoch 468, Validation Loss: 521260.79\n",
      "Epoch 469, Validation Loss: 680193.42\n",
      "Epoch 470, Validation Loss: 455890.90\n",
      "Epoch 471, Validation Loss: 429236.80\n",
      "Epoch 472, Validation Loss: 448493.74\n",
      "Epoch 473, Validation Loss: 542210.53\n",
      "Epoch 474, Validation Loss: 439470.27\n",
      "Epoch 475, Validation Loss: 637763.69\n",
      "Epoch 476, Validation Loss: 437268.64\n",
      "Epoch 477, Validation Loss: 544814.80\n",
      "Epoch 478, Validation Loss: 432317.40\n",
      "Epoch 479, Validation Loss: 449061.07\n",
      "Epoch 480, Validation Loss: 526881.85\n",
      "Epoch 481, Validation Loss: 660829.60\n",
      "Epoch 482, Validation Loss: 423853.12\n",
      "Epoch 483, Validation Loss: 444204.11\n",
      "Epoch 484, Validation Loss: 499879.11\n",
      "Epoch 485, Validation Loss: 470738.32\n",
      "Epoch 486, Validation Loss: 454649.83\n",
      "Epoch 487, Validation Loss: 680595.07\n",
      "Epoch 488, Validation Loss: 429770.46\n",
      "Epoch 489, Validation Loss: 607534.52\n",
      "Epoch 490, Validation Loss: 831199.34\n",
      "Epoch 491, Validation Loss: 525761.03\n",
      "Epoch 492, Validation Loss: 436839.76\n",
      "Epoch 493, Validation Loss: 776928.70\n",
      "Epoch 494, Validation Loss: 554577.72\n",
      "Epoch 495, Validation Loss: 666608.26\n",
      "Epoch 496, Validation Loss: 712916.44\n",
      "Epoch 497, Validation Loss: 436294.87\n",
      "Epoch 498, Validation Loss: 445155.30\n",
      "Epoch 499, Validation Loss: 737829.57\n",
      "Epoch 500, Validation Loss: 440409.17\n",
      "Epoch 501, Validation Loss: 541351.28\n",
      "Epoch 502, Validation Loss: 493493.97\n",
      "Epoch 503, Validation Loss: 667425.38\n",
      "Epoch 504, Validation Loss: 705530.49\n",
      "Epoch 505, Validation Loss: 646664.67\n",
      "Epoch 506, Validation Loss: 511350.48\n",
      "Epoch 507, Validation Loss: 579434.54\n",
      "Epoch 508, Validation Loss: 592978.32\n",
      "Epoch 509, Validation Loss: 12068223133795936256.00\n",
      "Epoch 510, Validation Loss: 455929.19\n",
      "Epoch 511, Validation Loss: 611154.31\n",
      "Epoch 512, Validation Loss: 451289.59\n",
      "Epoch 513, Validation Loss: 704032.75\n",
      "Epoch 514, Validation Loss: 741881.12\n",
      "Epoch 515, Validation Loss: 433397.62\n",
      "Epoch 516, Validation Loss: 506527.67\n",
      "Epoch 517, Validation Loss: 465380.20\n",
      "Epoch 518, Validation Loss: 639415.46\n",
      "Epoch 519, Validation Loss: 471555.28\n",
      "Epoch 520, Validation Loss: 479072.56\n",
      "Epoch 521, Validation Loss: 594315.88\n",
      "Epoch 522, Validation Loss: 450873.92\n",
      "Epoch 523, Validation Loss: 508492.46\n",
      "Epoch 524, Validation Loss: 775805.95\n",
      "Epoch 525, Validation Loss: 429878.99\n",
      "Epoch 526, Validation Loss: 567271.18\n",
      "Epoch 527, Validation Loss: 559809.95\n",
      "Epoch 528, Validation Loss: 531302.57\n",
      "Epoch 529, Validation Loss: 474610.86\n",
      "Epoch 530, Validation Loss: 496739.21\n",
      "Epoch 531, Validation Loss: 667653.96\n",
      "Epoch 532, Validation Loss: 517511.30\n",
      "Epoch 533, Validation Loss: 608487.17\n",
      "Epoch 534, Validation Loss: 466162.87\n",
      "Epoch 535, Validation Loss: 457270.08\n",
      "Epoch 536, Validation Loss: 491095.23\n",
      "Epoch 537, Validation Loss: 433814.55\n",
      "Epoch 538, Validation Loss: 437350.89\n",
      "Epoch 539, Validation Loss: 523417.95\n",
      "Epoch 540, Validation Loss: 441419.35\n",
      "Epoch 541, Validation Loss: 508366.58\n",
      "Epoch 542, Validation Loss: 823199.75\n",
      "Epoch 543, Validation Loss: 763662.66\n",
      "Epoch 544, Validation Loss: 454769.72\n",
      "Epoch 545, Validation Loss: 556807.29\n",
      "Epoch 546, Validation Loss: 429029.88\n",
      "Epoch 547, Validation Loss: 491028.60\n",
      "Epoch 548, Validation Loss: 606599.85\n",
      "Epoch 549, Validation Loss: 561954.89\n",
      "Epoch 550, Validation Loss: 550071.13\n",
      "Epoch 551, Validation Loss: 575744.60\n",
      "Epoch 552, Validation Loss: 496161.32\n",
      "Epoch 553, Validation Loss: 653189.53\n",
      "Epoch 554, Validation Loss: 500709.96\n",
      "Epoch 555, Validation Loss: 588255.42\n",
      "Epoch 556, Validation Loss: 771977.50\n",
      "Epoch 557, Validation Loss: 469049.81\n",
      "Epoch 558, Validation Loss: 425151.18\n",
      "Epoch 559, Validation Loss: 724464.42\n",
      "Epoch 560, Validation Loss: 562508.12\n",
      "Epoch 561, Validation Loss: 539814.53\n",
      "Epoch 562, Validation Loss: 431694.15\n",
      "Epoch 563, Validation Loss: 25763400220280778752.00\n",
      "Epoch 564, Validation Loss: 427318.10\n",
      "Epoch 565, Validation Loss: 760625.16\n",
      "Epoch 566, Validation Loss: 586464.39\n",
      "Epoch 567, Validation Loss: 472984.00\n",
      "Epoch 568, Validation Loss: 527431.58\n",
      "Epoch 569, Validation Loss: 646632.27\n",
      "Epoch 570, Validation Loss: 498992.48\n",
      "Epoch 571, Validation Loss: 692694.11\n",
      "Epoch 572, Validation Loss: 667842.88\n",
      "Epoch 573, Validation Loss: 688830.37\n",
      "Epoch 574, Validation Loss: 526079.11\n",
      "Epoch 575, Validation Loss: 594363.36\n",
      "Epoch 576, Validation Loss: 489963.72\n",
      "Epoch 577, Validation Loss: 863367.59\n",
      "Epoch 578, Validation Loss: 491798.59\n",
      "Epoch 579, Validation Loss: 603830.09\n",
      "Epoch 580, Validation Loss: 432913.43\n",
      "Epoch 581, Validation Loss: 507792.23\n",
      "Epoch 582, Validation Loss: 423532.80\n",
      "Epoch 583, Validation Loss: 421232.32\n",
      "Epoch 584, Validation Loss: 8098207421842615889154801664.00\n",
      "Epoch 585, Validation Loss: 446871.69\n",
      "Epoch 586, Validation Loss: 889692.31\n",
      "Epoch 587, Validation Loss: 546900.39\n",
      "Epoch 588, Validation Loss: 593843.45\n",
      "Epoch 589, Validation Loss: 504965.75\n",
      "Epoch 590, Validation Loss: 457935.53\n",
      "Epoch 591, Validation Loss: 429224.32\n",
      "Epoch 592, Validation Loss: 618077.32\n",
      "Epoch 593, Validation Loss: 604318.83\n",
      "Epoch 594, Validation Loss: 502036.13\n",
      "Epoch 595, Validation Loss: 415023.61\n",
      "Epoch 596, Validation Loss: 924799.38\n",
      "Epoch 597, Validation Loss: 437477.88\n",
      "Epoch 598, Validation Loss: 945887.54\n",
      "Epoch 599, Validation Loss: 747909.82\n",
      "Epoch 600, Validation Loss: 442656.95\n",
      "Epoch 601, Validation Loss: 473574.16\n",
      "Epoch 602, Validation Loss: 432652.91\n",
      "Epoch 603, Validation Loss: 430972.11\n",
      "Epoch 604, Validation Loss: 450081.23\n",
      "Epoch 605, Validation Loss: 660812.02\n",
      "Epoch 606, Validation Loss: 489225.34\n",
      "Epoch 607, Validation Loss: 789016.27\n",
      "Epoch 608, Validation Loss: 563133.89\n",
      "Epoch 609, Validation Loss: 502238.95\n",
      "Epoch 610, Validation Loss: 843126.79\n",
      "Epoch 611, Validation Loss: 651366.27\n",
      "Epoch 612, Validation Loss: 503366.61\n",
      "Epoch 613, Validation Loss: 439027.79\n",
      "Epoch 614, Validation Loss: 654951.45\n",
      "Epoch 615, Validation Loss: 610635.61\n",
      "Epoch 616, Validation Loss: 425190.54\n",
      "Epoch 617, Validation Loss: 883031.37\n",
      "Epoch 618, Validation Loss: 609472.19\n",
      "Epoch 619, Validation Loss: 601489.95\n",
      "Epoch 620, Validation Loss: 544604.63\n",
      "Epoch 621, Validation Loss: 511348.91\n",
      "Epoch 622, Validation Loss: 550803.22\n",
      "Epoch 623, Validation Loss: 682000.25\n",
      "Epoch 624, Validation Loss: 702827.95\n",
      "Epoch 625, Validation Loss: 439495.90\n",
      "Epoch 626, Validation Loss: 716970.12\n",
      "Epoch 627, Validation Loss: 489493.74\n",
      "Epoch 628, Validation Loss: 760272.32\n",
      "Epoch 629, Validation Loss: 523350.52\n",
      "Epoch 630, Validation Loss: 492818.42\n",
      "Epoch 631, Validation Loss: 621065.30\n",
      "Epoch 632, Validation Loss: 590357.56\n",
      "Epoch 633, Validation Loss: 412504.01\n",
      "Epoch 634, Validation Loss: 443629.89\n",
      "Epoch 635, Validation Loss: 941635.21\n",
      "Epoch 636, Validation Loss: 577145.82\n",
      "Epoch 637, Validation Loss: 424647.32\n",
      "Epoch 638, Validation Loss: 425852.09\n",
      "Epoch 639, Validation Loss: 451532.48\n",
      "Epoch 640, Validation Loss: 1587599228152327.75\n",
      "Epoch 641, Validation Loss: 255474455564.97\n",
      "Epoch 642, Validation Loss: 695960.43\n",
      "Epoch 643, Validation Loss: 434032.44\n",
      "Epoch 644, Validation Loss: 438275.65\n",
      "Epoch 645, Validation Loss: 466763.40\n",
      "Epoch 646, Validation Loss: 434923.27\n",
      "Epoch 647, Validation Loss: 411174.99\n",
      "Epoch 648, Validation Loss: 762968.09\n",
      "Epoch 649, Validation Loss: 438780.95\n",
      "Epoch 650, Validation Loss: 424411.51\n",
      "Epoch 651, Validation Loss: 600458.54\n",
      "Epoch 652, Validation Loss: 609598.14\n",
      "Epoch 653, Validation Loss: 454804.39\n",
      "Epoch 654, Validation Loss: 447443.06\n",
      "Epoch 655, Validation Loss: 477788.87\n",
      "Epoch 656, Validation Loss: 454585.38\n",
      "Epoch 657, Validation Loss: 419317.37\n",
      "Epoch 658, Validation Loss: 488772.66\n",
      "Epoch 659, Validation Loss: 525961.48\n",
      "Epoch 660, Validation Loss: 409007.35\n",
      "Epoch 661, Validation Loss: 482140.96\n",
      "Epoch 662, Validation Loss: 680975.96\n",
      "Epoch 663, Validation Loss: 753036.31\n",
      "Epoch 664, Validation Loss: 406361.46\n",
      "Epoch 665, Validation Loss: 403000.43\n",
      "Epoch 666, Validation Loss: 465260.27\n",
      "Epoch 667, Validation Loss: 610930.29\n",
      "Epoch 668, Validation Loss: 442536.79\n",
      "Epoch 669, Validation Loss: 592536.28\n",
      "Epoch 670, Validation Loss: 459069.74\n",
      "Epoch 671, Validation Loss: 632303.27\n",
      "Epoch 672, Validation Loss: 416384.27\n",
      "Epoch 673, Validation Loss: 429098.26\n",
      "Epoch 674, Validation Loss: 697254.59\n",
      "Epoch 675, Validation Loss: 468149.36\n",
      "Epoch 676, Validation Loss: 605431.12\n",
      "Epoch 677, Validation Loss: 519125.09\n",
      "Epoch 678, Validation Loss: 463065.19\n",
      "Epoch 679, Validation Loss: 713036.10\n",
      "Epoch 680, Validation Loss: 412159.10\n",
      "Epoch 681, Validation Loss: 423304.72\n",
      "Epoch 682, Validation Loss: 454121.12\n",
      "Epoch 683, Validation Loss: 419881.34\n",
      "Epoch 684, Validation Loss: 732517.65\n",
      "Epoch 685, Validation Loss: 540543.93\n",
      "Epoch 686, Validation Loss: 551073.38\n",
      "Epoch 687, Validation Loss: 471472.09\n",
      "Epoch 688, Validation Loss: 1045052.73\n",
      "Epoch 689, Validation Loss: 454048.40\n",
      "Epoch 690, Validation Loss: 567845.17\n",
      "Epoch 691, Validation Loss: 1044370.09\n",
      "Epoch 692, Validation Loss: 574489.34\n",
      "Epoch 693, Validation Loss: 481832.16\n",
      "Epoch 694, Validation Loss: 546396.22\n",
      "Epoch 695, Validation Loss: 641690.21\n",
      "Epoch 696, Validation Loss: 445790.01\n",
      "Epoch 697, Validation Loss: 742061.54\n",
      "Epoch 698, Validation Loss: 478901.84\n",
      "Epoch 699, Validation Loss: 540685.79\n",
      "Epoch 700, Validation Loss: 430066.44\n",
      "Epoch 701, Validation Loss: 416083.72\n",
      "Epoch 702, Validation Loss: 821680.50\n",
      "Epoch 703, Validation Loss: 512833.75\n",
      "Epoch 704, Validation Loss: 557644.13\n",
      "Epoch 705, Validation Loss: 497796.73\n",
      "Epoch 706, Validation Loss: 456876.50\n",
      "Epoch 707, Validation Loss: 761857.19\n",
      "Epoch 708, Validation Loss: 567810.58\n",
      "Epoch 709, Validation Loss: 464363.60\n",
      "Epoch 710, Validation Loss: 427447.37\n",
      "Epoch 711, Validation Loss: 789496.23\n",
      "Epoch 712, Validation Loss: 437060.49\n",
      "Epoch 713, Validation Loss: 627906.98\n",
      "Epoch 714, Validation Loss: 597721.49\n",
      "Epoch 715, Validation Loss: 436121.30\n",
      "Epoch 716, Validation Loss: 427676.42\n",
      "Epoch 717, Validation Loss: 650185.46\n",
      "Epoch 718, Validation Loss: 628217.58\n",
      "Epoch 719, Validation Loss: 767976.38\n",
      "Epoch 720, Validation Loss: 550192.03\n",
      "Epoch 721, Validation Loss: 1026562.05\n",
      "Epoch 722, Validation Loss: 424659.36\n",
      "Epoch 723, Validation Loss: 713479.51\n",
      "Epoch 724, Validation Loss: 508793.72\n",
      "Epoch 725, Validation Loss: 946495.16\n",
      "Epoch 726, Validation Loss: 443575.93\n",
      "Epoch 727, Validation Loss: 436303.09\n",
      "Epoch 728, Validation Loss: 560230.30\n",
      "Epoch 729, Validation Loss: 506242.26\n",
      "Epoch 730, Validation Loss: 489250.50\n",
      "Epoch 731, Validation Loss: 473018.35\n",
      "Epoch 732, Validation Loss: 670129.36\n",
      "Epoch 733, Validation Loss: 682159.97\n",
      "Epoch 734, Validation Loss: 839193.48\n",
      "Epoch 735, Validation Loss: 743528.36\n",
      "Epoch 736, Validation Loss: 504959.73\n",
      "Epoch 737, Validation Loss: 555694.42\n",
      "Epoch 738, Validation Loss: 531588.11\n",
      "Epoch 739, Validation Loss: 526901.41\n",
      "Epoch 740, Validation Loss: 965831.11\n",
      "Epoch 741, Validation Loss: 480296.15\n",
      "Epoch 742, Validation Loss: 522090.60\n",
      "Epoch 743, Validation Loss: 484058.75\n",
      "Epoch 744, Validation Loss: 498772.22\n",
      "Epoch 745, Validation Loss: 740037.47\n",
      "Epoch 746, Validation Loss: 473870.99\n",
      "Epoch 747, Validation Loss: 485594.09\n",
      "Epoch 748, Validation Loss: 725440.56\n",
      "Epoch 749, Validation Loss: 402495.86\n",
      "Epoch 750, Validation Loss: 758315.16\n",
      "Epoch 751, Validation Loss: 1019733.45\n",
      "Epoch 752, Validation Loss: 427968.00\n",
      "Epoch 753, Validation Loss: 467489.47\n",
      "Epoch 754, Validation Loss: 398685.35\n",
      "Epoch 755, Validation Loss: 463380.19\n",
      "Epoch 756, Validation Loss: 395204.99\n",
      "Epoch 757, Validation Loss: 402562.33\n",
      "Epoch 758, Validation Loss: 445170.62\n",
      "Epoch 759, Validation Loss: 444456.47\n",
      "Epoch 760, Validation Loss: 439492.38\n",
      "Epoch 761, Validation Loss: 857985.77\n",
      "Epoch 762, Validation Loss: 677442.58\n",
      "Epoch 763, Validation Loss: 540969.31\n",
      "Epoch 764, Validation Loss: 515916.76\n",
      "Epoch 765, Validation Loss: 671482.31\n",
      "Epoch 766, Validation Loss: 447328.93\n",
      "Epoch 767, Validation Loss: 566702.22\n",
      "Epoch 768, Validation Loss: 530738.93\n",
      "Epoch 769, Validation Loss: 520031.78\n",
      "Epoch 770, Validation Loss: 443349.14\n",
      "Epoch 771, Validation Loss: 539968.38\n",
      "Epoch 772, Validation Loss: 479582.57\n",
      "Epoch 773, Validation Loss: 489833.66\n",
      "Epoch 774, Validation Loss: 447854.25\n",
      "Epoch 775, Validation Loss: 534115.29\n",
      "Epoch 776, Validation Loss: 601566.52\n",
      "Epoch 777, Validation Loss: 760134.34\n",
      "Epoch 778, Validation Loss: 455199.80\n",
      "Epoch 779, Validation Loss: 414035.50\n",
      "Epoch 780, Validation Loss: 704487.49\n",
      "Epoch 781, Validation Loss: 664907.37\n",
      "Epoch 782, Validation Loss: 998166306460.34\n",
      "Epoch 783, Validation Loss: 613605.23\n",
      "Epoch 784, Validation Loss: 911276.68\n",
      "Epoch 785, Validation Loss: 754878.77\n",
      "Epoch 786, Validation Loss: 545201.08\n",
      "Epoch 787, Validation Loss: 414038.74\n",
      "Epoch 788, Validation Loss: 449152.92\n",
      "Epoch 789, Validation Loss: 512541.40\n",
      "Epoch 790, Validation Loss: 409264.12\n",
      "Epoch 791, Validation Loss: 486896.96\n",
      "Epoch 792, Validation Loss: 636298.75\n",
      "Epoch 793, Validation Loss: 933409.09\n",
      "Epoch 794, Validation Loss: 483510.11\n",
      "Epoch 795, Validation Loss: 686767.38\n",
      "Epoch 796, Validation Loss: 415393.23\n",
      "Epoch 797, Validation Loss: 408330.54\n",
      "Epoch 798, Validation Loss: 685618.95\n",
      "Epoch 799, Validation Loss: 524337.48\n",
      "Epoch 800, Validation Loss: 463626.28\n",
      "Epoch 801, Validation Loss: 613132.59\n",
      "Epoch 802, Validation Loss: 563328.09\n",
      "Epoch 803, Validation Loss: 644556.19\n",
      "Epoch 804, Validation Loss: 425977.75\n",
      "Epoch 805, Validation Loss: 744943.98\n",
      "Epoch 806, Validation Loss: 864086.68\n",
      "Epoch 807, Validation Loss: 525249.68\n",
      "Epoch 808, Validation Loss: 548915.19\n",
      "Epoch 809, Validation Loss: 413221.86\n",
      "Epoch 810, Validation Loss: 740867.06\n",
      "Epoch 811, Validation Loss: 559278.21\n",
      "Epoch 812, Validation Loss: 561894.87\n",
      "Epoch 813, Validation Loss: 600897.65\n",
      "Epoch 814, Validation Loss: 1031212.13\n",
      "Epoch 815, Validation Loss: 613796.01\n",
      "Epoch 816, Validation Loss: 476746.14\n",
      "Epoch 817, Validation Loss: 519327.08\n",
      "Epoch 818, Validation Loss: 470579.39\n",
      "Epoch 819, Validation Loss: 437199.28\n",
      "Epoch 820, Validation Loss: 431399.96\n",
      "Epoch 821, Validation Loss: 82691394398883349004288.00\n",
      "Epoch 822, Validation Loss: 500533.36\n",
      "Epoch 823, Validation Loss: 715759.36\n",
      "Epoch 824, Validation Loss: 589511.18\n",
      "Epoch 825, Validation Loss: 541095.39\n",
      "Epoch 826, Validation Loss: 509533.95\n",
      "Epoch 827, Validation Loss: 49577097375172570120192.00\n",
      "Epoch 828, Validation Loss: 432039.02\n",
      "Epoch 829, Validation Loss: 451951.86\n",
      "Epoch 830, Validation Loss: 671095.88\n",
      "Epoch 831, Validation Loss: 846697.96\n",
      "Epoch 832, Validation Loss: 911485068491811863920640.00\n",
      "Epoch 833, Validation Loss: 182368690861926.94\n",
      "Epoch 834, Validation Loss: 453144.25\n",
      "Epoch 835, Validation Loss: 589732.27\n",
      "Epoch 836, Validation Loss: 769875.79\n",
      "Epoch 837, Validation Loss: 8635516452842.76\n",
      "Epoch 838, Validation Loss: 560988.67\n",
      "Epoch 839, Validation Loss: 613450.33\n",
      "Epoch 840, Validation Loss: 551901.04\n",
      "Epoch 841, Validation Loss: 569967.03\n",
      "Epoch 842, Validation Loss: 490106.90\n",
      "Epoch 843, Validation Loss: 850419.30\n",
      "Epoch 844, Validation Loss: 601091.71\n",
      "Epoch 845, Validation Loss: 983042.55\n",
      "Epoch 846, Validation Loss: 562850.64\n",
      "Epoch 847, Validation Loss: 480564.90\n",
      "Epoch 848, Validation Loss: 553004.82\n",
      "Epoch 849, Validation Loss: 525246.18\n",
      "Epoch 850, Validation Loss: 136435514883274881105920.00\n",
      "Epoch 851, Validation Loss: 762632.50\n",
      "Epoch 852, Validation Loss: 1046946.12\n",
      "Epoch 853, Validation Loss: 589094.49\n",
      "Epoch 854, Validation Loss: 696936.77\n",
      "Epoch 855, Validation Loss: 411866.96\n",
      "Epoch 856, Validation Loss: 595744.53\n",
      "Epoch 857, Validation Loss: 531485.37\n",
      "Epoch 858, Validation Loss: 108594185041006432.00\n",
      "Epoch 859, Validation Loss: 441075.95\n",
      "Epoch 860, Validation Loss: 389682.91\n",
      "Epoch 861, Validation Loss: 54828173234529.73\n",
      "Epoch 862, Validation Loss: 468904.56\n",
      "Epoch 863, Validation Loss: 494513.21\n",
      "Epoch 864, Validation Loss: 485132.37\n",
      "Epoch 865, Validation Loss: 412584.03\n",
      "Epoch 866, Validation Loss: 629880.38\n",
      "Epoch 867, Validation Loss: 528055.54\n",
      "Epoch 868, Validation Loss: 441958.85\n",
      "Epoch 869, Validation Loss: 712328.43\n",
      "Epoch 870, Validation Loss: 531012.87\n",
      "Epoch 871, Validation Loss: 882776.21\n",
      "Epoch 872, Validation Loss: 558198.26\n",
      "Epoch 873, Validation Loss: 398318.60\n",
      "Epoch 874, Validation Loss: 460239.37\n",
      "Epoch 875, Validation Loss: 441580.96\n",
      "Epoch 876, Validation Loss: 550264.99\n",
      "Epoch 877, Validation Loss: 707782.02\n",
      "Epoch 878, Validation Loss: 518794.42\n",
      "Epoch 879, Validation Loss: 561937.35\n",
      "Epoch 880, Validation Loss: 1246134838364455.75\n",
      "Epoch 881, Validation Loss: 442414.96\n",
      "Epoch 882, Validation Loss: 327327772685555520.00\n",
      "Epoch 883, Validation Loss: 454866.78\n",
      "Epoch 884, Validation Loss: 530482.76\n",
      "Epoch 885, Validation Loss: 440554.90\n",
      "Epoch 886, Validation Loss: 513235.29\n",
      "Epoch 887, Validation Loss: 624111.96\n",
      "Epoch 888, Validation Loss: 525941.76\n",
      "Epoch 889, Validation Loss: 597441.56\n",
      "Epoch 890, Validation Loss: 545107.83\n",
      "Epoch 891, Validation Loss: 469146.81\n",
      "Epoch 892, Validation Loss: 565083.33\n",
      "Epoch 893, Validation Loss: 481512.40\n",
      "Epoch 894, Validation Loss: 43437635.88\n",
      "Epoch 895, Validation Loss: 630806.07\n",
      "Epoch 896, Validation Loss: 1457466872970250211557376.00\n",
      "Epoch 897, Validation Loss: 637414.48\n",
      "Epoch 898, Validation Loss: 734182.09\n",
      "Epoch 899, Validation Loss: 199278925643758853685248.00\n",
      "Epoch 900, Validation Loss: 707607553197.21\n",
      "Epoch 901, Validation Loss: 1138623.26\n",
      "Epoch 902, Validation Loss: 432254.47\n",
      "Epoch 903, Validation Loss: 432546.65\n",
      "Epoch 904, Validation Loss: 504515.53\n",
      "Epoch 905, Validation Loss: 465847.40\n",
      "Epoch 906, Validation Loss: 526218.42\n",
      "Epoch 907, Validation Loss: 568585.40\n",
      "Epoch 908, Validation Loss: 807500.70\n",
      "Epoch 909, Validation Loss: 589215.68\n",
      "Epoch 910, Validation Loss: 690578.54\n",
      "Epoch 911, Validation Loss: 783349.56\n",
      "Epoch 912, Validation Loss: 439157.48\n",
      "Epoch 913, Validation Loss: 577454.83\n",
      "Epoch 914, Validation Loss: 698977.29\n",
      "Epoch 915, Validation Loss: 740331.68\n",
      "Epoch 916, Validation Loss: 536353.13\n",
      "Epoch 917, Validation Loss: 557223.44\n",
      "Epoch 918, Validation Loss: 402918.74\n",
      "Epoch 919, Validation Loss: 539566.23\n",
      "Epoch 920, Validation Loss: 315716705040935.12\n",
      "Epoch 921, Validation Loss: 509175.59\n",
      "Epoch 922, Validation Loss: 412238.78\n",
      "Epoch 923, Validation Loss: 435468.79\n",
      "Epoch 924, Validation Loss: 728093.30\n",
      "Epoch 925, Validation Loss: 57208564951685432.00\n",
      "Epoch 926, Validation Loss: 593150.97\n",
      "Epoch 927, Validation Loss: 550581.49\n",
      "Epoch 928, Validation Loss: 498649.74\n",
      "Epoch 929, Validation Loss: 504875.31\n",
      "Epoch 930, Validation Loss: 856108.53\n",
      "Epoch 931, Validation Loss: 454437.69\n",
      "Epoch 932, Validation Loss: 677243.49\n",
      "Epoch 933, Validation Loss: 465292.95\n",
      "Epoch 934, Validation Loss: 562757.06\n",
      "Epoch 935, Validation Loss: 512314.84\n",
      "Epoch 936, Validation Loss: 468586.30\n",
      "Epoch 937, Validation Loss: 452968.90\n",
      "Epoch 938, Validation Loss: 611242.22\n",
      "Epoch 939, Validation Loss: 576189.46\n",
      "Epoch 940, Validation Loss: 425677.21\n",
      "Epoch 941, Validation Loss: 458444.53\n",
      "Epoch 942, Validation Loss: 525609.78\n",
      "Epoch 943, Validation Loss: 597712.32\n",
      "Epoch 944, Validation Loss: 611659.27\n",
      "Epoch 945, Validation Loss: 632132.64\n",
      "Epoch 946, Validation Loss: 399221.23\n",
      "Epoch 947, Validation Loss: 417345.21\n",
      "Epoch 948, Validation Loss: 484428.72\n",
      "Epoch 949, Validation Loss: 487040.43\n",
      "Epoch 950, Validation Loss: 661416.12\n",
      "Epoch 951, Validation Loss: 566088.39\n",
      "Epoch 952, Validation Loss: 452130.77\n",
      "Epoch 953, Validation Loss: 598310.87\n",
      "Epoch 954, Validation Loss: 411194.91\n",
      "Epoch 955, Validation Loss: 483810.16\n",
      "Epoch 956, Validation Loss: 591110.91\n",
      "Epoch 957, Validation Loss: 677835.39\n",
      "Epoch 958, Validation Loss: 624152.97\n",
      "Epoch 959, Validation Loss: 625769.54\n",
      "Epoch 960, Validation Loss: 419714.54\n",
      "Epoch 961, Validation Loss: 499173.04\n",
      "Epoch 962, Validation Loss: 489518.78\n",
      "Epoch 963, Validation Loss: 502909.70\n",
      "Epoch 964, Validation Loss: 590894.16\n",
      "Epoch 965, Validation Loss: 468737.23\n",
      "Epoch 966, Validation Loss: 488704.62\n",
      "Epoch 967, Validation Loss: 422297.27\n",
      "Epoch 968, Validation Loss: 433051.21\n",
      "Epoch 969, Validation Loss: 689686.16\n",
      "Epoch 970, Validation Loss: 481870.61\n",
      "Epoch 971, Validation Loss: 414465.29\n",
      "Epoch 972, Validation Loss: 477217.55\n",
      "Epoch 973, Validation Loss: 605973.12\n",
      "Epoch 974, Validation Loss: 649253.26\n",
      "Epoch 975, Validation Loss: 596962.94\n",
      "Epoch 976, Validation Loss: 877660.05\n",
      "Epoch 977, Validation Loss: 783229.60\n",
      "Epoch 978, Validation Loss: 725348.10\n",
      "Epoch 979, Validation Loss: 609132.58\n",
      "Epoch 980, Validation Loss: 474538.35\n",
      "Epoch 981, Validation Loss: 442481.02\n",
      "Epoch 982, Validation Loss: 643575.42\n",
      "Epoch 983, Validation Loss: 523964.37\n",
      "Epoch 984, Validation Loss: 416087.01\n",
      "Epoch 985, Validation Loss: 609522.21\n",
      "Epoch 986, Validation Loss: 734100.75\n",
      "Epoch 987, Validation Loss: 595845.89\n",
      "Epoch 988, Validation Loss: 536420.89\n",
      "Epoch 989, Validation Loss: 550717.84\n",
      "Epoch 990, Validation Loss: 788541.12\n",
      "Epoch 991, Validation Loss: 597596.49\n",
      "Epoch 992, Validation Loss: 317746310367779596577800192.00\n",
      "Epoch 993, Validation Loss: 525165.12\n",
      "Epoch 994, Validation Loss: 665337.35\n",
      "Epoch 995, Validation Loss: 453229.14\n",
      "Epoch 996, Validation Loss: 550042.68\n",
      "Epoch 997, Validation Loss: 617722.81\n",
      "Epoch 998, Validation Loss: 416927627956808583082934272.00\n",
      "Epoch 999, Validation Loss: 474088.63\n",
      "Epoch 1000, Validation Loss: 439485.41\n",
      "Epoch 1001, Validation Loss: 479813.04\n",
      "Epoch 1002, Validation Loss: 601029.84\n",
      "Epoch 1003, Validation Loss: 31837733658905305291948032.00\n",
      "Epoch 1004, Validation Loss: 431091.73\n",
      "Epoch 1005, Validation Loss: 414568.80\n",
      "Epoch 1006, Validation Loss: 588101.08\n",
      "Epoch 1007, Validation Loss: 903473.48\n",
      "Epoch 1008, Validation Loss: 427758.79\n",
      "Epoch 1009, Validation Loss: 469237.42\n",
      "Epoch 1010, Validation Loss: 508006.97\n",
      "Epoch 1011, Validation Loss: 519847.08\n",
      "Epoch 1012, Validation Loss: 1488582296694833308791472128.00\n",
      "Epoch 1013, Validation Loss: 469773.12\n",
      "Epoch 1014, Validation Loss: 437972.74\n",
      "Epoch 1015, Validation Loss: 452654.11\n",
      "Epoch 1016, Validation Loss: 498463.37\n",
      "Epoch 1017, Validation Loss: 663338.73\n",
      "Epoch 1018, Validation Loss: 727679.66\n",
      "Epoch 1019, Validation Loss: 5375606042772361676062720.00\n",
      "Epoch 1020, Validation Loss: 444712.29\n",
      "Epoch 1021, Validation Loss: 694983.03\n",
      "Epoch 1022, Validation Loss: 490749.84\n",
      "Epoch 1023, Validation Loss: 701272.68\n",
      "Epoch 1024, Validation Loss: 569748.85\n",
      "Epoch 1025, Validation Loss: 449759.27\n",
      "Epoch 1026, Validation Loss: 195138256823406584095834112.00\n",
      "Epoch 1027, Validation Loss: 482828.39\n",
      "Epoch 1028, Validation Loss: 399984.46\n",
      "Epoch 1029, Validation Loss: 500821.96\n",
      "Epoch 1030, Validation Loss: 464014.24\n",
      "Epoch 1031, Validation Loss: 560818.63\n",
      "Epoch 1032, Validation Loss: 635721.99\n",
      "Epoch 1033, Validation Loss: 4141719057531252605861232640.00\n",
      "Epoch 1034, Validation Loss: 9698420732749070467072.00\n",
      "Epoch 1035, Validation Loss: 661553.69\n",
      "Epoch 1036, Validation Loss: 410268.27\n",
      "Epoch 1037, Validation Loss: 476545.84\n",
      "Epoch 1038, Validation Loss: 569371.40\n",
      "Epoch 1039, Validation Loss: 514081.89\n",
      "Epoch 1040, Validation Loss: 687930.69\n",
      "Epoch 1041, Validation Loss: 439771.44\n",
      "Epoch 1042, Validation Loss: 693445.89\n",
      "Epoch 1043, Validation Loss: 185487963449532776448.00\n",
      "Epoch 1044, Validation Loss: 19519530616217195086086144.00\n",
      "Epoch 1045, Validation Loss: 645466.54\n",
      "Epoch 1046, Validation Loss: 393791.35\n",
      "Epoch 1047, Validation Loss: 6428254081083923654699384832.00\n",
      "Epoch 1048, Validation Loss: 9788007462436708810752.00\n",
      "Epoch 1049, Validation Loss: 509269.62\n",
      "Epoch 1050, Validation Loss: 615881.19\n",
      "Epoch 1051, Validation Loss: 408243.92\n",
      "Epoch 1052, Validation Loss: 802108.39\n",
      "Epoch 1053, Validation Loss: 452266.80\n",
      "Epoch 1054, Validation Loss: 508045.38\n",
      "Epoch 1055, Validation Loss: 451735.68\n",
      "Epoch 1056, Validation Loss: 415170.97\n",
      "Epoch 1057, Validation Loss: 13081157016977162240.00\n",
      "Epoch 1058, Validation Loss: 83172179577.77\n",
      "Epoch 1059, Validation Loss: 493019.23\n",
      "Early stopping at epoch 1059\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 1485.72 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 2000                   # number of training epochs\n",
    "warmup = 400                    # number of epochs to wait before enacting early stopping policy\n",
    "patience = 200                  # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:26<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Obj Val  Constraints Viol  Elapsed Time\n",
      "count     100.000000        100.000000    100.000000\n",
      "mean    72642.517708       3400.201152      0.044910\n",
      "std     16300.099220       4819.339689      0.006332\n",
      "min     46607.425245          0.000000      0.013127\n",
      "25%     59332.225938          0.000000      0.044367\n",
      "50%     67825.095512          0.000000      0.045351\n",
      "75%     82466.780814       6212.425504      0.047454\n",
      "max    113351.694185      17974.054885      0.053854\n",
      "Number of infeasible solution: 48\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lr_50-10000_s.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f038b4a-7343-4662-88db-78ef4c99a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
