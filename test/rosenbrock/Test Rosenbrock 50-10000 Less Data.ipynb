{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50     # steepness factor\n",
    "num_blocks = 10000 # number of expression blocks\n",
    "num_data = 1900    # number of data\n",
    "test_size = 100    # number of test size\n",
    "val_size = 1000    # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2bdd74-a0d1-4afa-b610-4f29559a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 2593960.00\n",
      "Epoch 9, Iters 125, Validation Loss: 1398688.17\n",
      "Epoch 19, Iters 250, Validation Loss: 1492346.91\n",
      "Epoch 28, Iters 375, Validation Loss: 260325571835065605816320.00\n",
      "Epoch 38, Iters 500, Validation Loss: 619333.93\n",
      "Epoch 48, Iters 625, Validation Loss: 814034.06\n",
      "Epoch 57, Iters 750, Validation Loss: 677244.72\n",
      "Epoch 67, Iters 875, Validation Loss: 996855.24\n",
      "Epoch 76, Iters 1000, Validation Loss: 676302.32\n",
      "Epoch 86, Iters 1125, Validation Loss: 537888.02\n",
      "Epoch 96, Iters 1250, Validation Loss: 551787.81\n",
      "Epoch 105, Iters 1375, Validation Loss: 586173.45\n",
      "Epoch 115, Iters 1500, Validation Loss: 792662.65\n",
      "Epoch 124, Iters 1625, Validation Loss: 879048.33\n",
      "Epoch 134, Iters 1750, Validation Loss: 531102.35\n",
      "Epoch 144, Iters 1875, Validation Loss: 704466.82\n",
      "Epoch 153, Iters 2000, Validation Loss: 569100.81\n",
      "Epoch 163, Iters 2125, Validation Loss: 463794.79\n",
      "Epoch 173, Iters 2250, Validation Loss: 465407.05\n",
      "Epoch 182, Iters 2375, Validation Loss: 627608.29\n",
      "Epoch 192, Iters 2500, Validation Loss: 632170.56\n",
      "Epoch 201, Iters 2625, Validation Loss: 685402.57\n",
      "Epoch 211, Iters 2750, Validation Loss: 495048.10\n",
      "Epoch 221, Iters 2875, Validation Loss: 485543.41\n",
      "Epoch 230, Iters 3000, Validation Loss: 734967.28\n",
      "Epoch 240, Iters 3125, Validation Loss: 540040.72\n",
      "Epoch 249, Iters 3250, Validation Loss: 992274951.28\n",
      "Epoch 259, Iters 3375, Validation Loss: 1110672460.00\n",
      "Epoch 269, Iters 3500, Validation Loss: 471328.45\n",
      "Epoch 278, Iters 3625, Validation Loss: 17241276.31\n",
      "Epoch 288, Iters 3750, Validation Loss: 882230.48\n",
      "Epoch 298, Iters 3875, Validation Loss: 723541.54\n",
      "Epoch 307, Iters 4000, Validation Loss: 510207.65\n",
      "Epoch 317, Iters 4125, Validation Loss: 477257.95\n",
      "Epoch 326, Iters 4250, Validation Loss: 466609.16\n",
      "Epoch 336, Iters 4375, Validation Loss: 535472.91\n",
      "Epoch 346, Iters 4500, Validation Loss: 831802.23\n",
      "Epoch 355, Iters 4625, Validation Loss: 507480.21\n",
      "Epoch 365, Iters 4750, Validation Loss: 445452.96\n",
      "Epoch 374, Iters 4875, Validation Loss: 780728.81\n",
      "Epoch 384, Iters 5000, Validation Loss: 887167.58\n",
      "Epoch 394, Iters 5125, Validation Loss: 505604.03\n",
      "Epoch 403, Iters 5250, Validation Loss: 884456.33\n",
      "Epoch 413, Iters 5375, Validation Loss: 872934.08\n",
      "Epoch 423, Iters 5500, Validation Loss: 737576.24\n",
      "Epoch 432, Iters 5625, Validation Loss: 1150216.87\n",
      "Epoch 442, Iters 5750, Validation Loss: 863757.88\n",
      "Epoch 451, Iters 5875, Validation Loss: 884411.49\n",
      "Epoch 461, Iters 6000, Validation Loss: 527370.97\n",
      "Epoch 471, Iters 6125, Validation Loss: 505754.85\n",
      "Epoch 480, Iters 6250, Validation Loss: 459763.90\n",
      "Epoch 490, Iters 6375, Validation Loss: 3810182410176299008.00\n",
      "Epoch 499, Iters 6500, Validation Loss: 491055.65\n",
      "Epoch 509, Iters 6625, Validation Loss: 493610.17\n",
      "Epoch 519, Iters 6750, Validation Loss: 490155.41\n",
      "Epoch 528, Iters 6875, Validation Loss: 1711165.81\n",
      "Epoch 538, Iters 7000, Validation Loss: 584121.48\n",
      "Epoch 548, Iters 7125, Validation Loss: 589003.31\n",
      "Epoch 557, Iters 7250, Validation Loss: 542498.75\n",
      "Early stopping at iters 7250\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 616.06 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 2000                   # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:15<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Obj Val  Constraints Viol  Elapsed Time\n",
      "count     100.000000        100.000000    100.000000\n",
      "mean   116535.142995       3776.220078      0.044383\n",
      "std     43407.541229       5268.707387      0.005147\n",
      "min     52025.125106          0.000000      0.009515\n",
      "25%     79130.375424          0.000000      0.043859\n",
      "50%    101980.723650          0.000000      0.044365\n",
      "75%    159769.287551       6858.142988      0.045342\n",
      "max    230771.101402      19733.778596      0.049931\n",
      "Number of infeasible solution: 48\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lr_50-10000_s.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7912a689-22cd-4d7b-a50f-d136dbdf5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                          int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 2346129.37\n",
      "Epoch 9, Iters 125, Validation Loss: 9639029.38\n",
      "Epoch 19, Iters 250, Validation Loss: 670705.99\n",
      "Epoch 28, Iters 375, Validation Loss: 60034891.11\n",
      "Epoch 38, Iters 500, Validation Loss: 1294628.04\n",
      "Epoch 48, Iters 625, Validation Loss: 699807.61\n",
      "Epoch 57, Iters 750, Validation Loss: 772766.15\n",
      "Epoch 67, Iters 875, Validation Loss: 875351.83\n",
      "Epoch 76, Iters 1000, Validation Loss: 700568.20\n",
      "Epoch 86, Iters 1125, Validation Loss: 1002653.13\n",
      "Epoch 96, Iters 1250, Validation Loss: 503047.70\n",
      "Epoch 105, Iters 1375, Validation Loss: 868768.35\n",
      "Epoch 115, Iters 1500, Validation Loss: 609918.90\n",
      "Epoch 124, Iters 1625, Validation Loss: 711054.95\n",
      "Epoch 134, Iters 1750, Validation Loss: 636627.67\n",
      "Epoch 144, Iters 1875, Validation Loss: 594657.29\n",
      "Epoch 153, Iters 2000, Validation Loss: 579242.49\n",
      "Epoch 163, Iters 2125, Validation Loss: 852831294.41\n",
      "Epoch 173, Iters 2250, Validation Loss: 651262.46\n",
      "Epoch 182, Iters 2375, Validation Loss: 967733.82\n",
      "Epoch 192, Iters 2500, Validation Loss: 483121.12\n",
      "Epoch 201, Iters 2625, Validation Loss: 506346.15\n",
      "Epoch 211, Iters 2750, Validation Loss: 501841.14\n",
      "Epoch 221, Iters 2875, Validation Loss: 506387.62\n",
      "Epoch 230, Iters 3000, Validation Loss: 502122.06\n",
      "Epoch 240, Iters 3125, Validation Loss: 680267.09\n",
      "Epoch 249, Iters 3250, Validation Loss: 618311.98\n",
      "Epoch 259, Iters 3375, Validation Loss: 601331.73\n",
      "Epoch 269, Iters 3500, Validation Loss: 561376.87\n",
      "Epoch 278, Iters 3625, Validation Loss: 493072.49\n",
      "Epoch 288, Iters 3750, Validation Loss: 506595.38\n",
      "Epoch 298, Iters 3875, Validation Loss: 678947.25\n",
      "Epoch 307, Iters 4000, Validation Loss: 485058.14\n",
      "Epoch 317, Iters 4125, Validation Loss: 502429.96\n",
      "Epoch 326, Iters 4250, Validation Loss: 499784.42\n",
      "Epoch 336, Iters 4375, Validation Loss: 459479.11\n",
      "Epoch 346, Iters 4500, Validation Loss: 486016.21\n",
      "Epoch 355, Iters 4625, Validation Loss: 439891.39\n",
      "Epoch 365, Iters 4750, Validation Loss: 669554.49\n",
      "Epoch 374, Iters 4875, Validation Loss: 550922.66\n",
      "Epoch 384, Iters 5000, Validation Loss: 437380.23\n",
      "Epoch 394, Iters 5125, Validation Loss: 407698.19\n",
      "Epoch 403, Iters 5250, Validation Loss: 621673.93\n",
      "Epoch 413, Iters 5375, Validation Loss: 491308.22\n",
      "Epoch 423, Iters 5500, Validation Loss: 473828.47\n",
      "Epoch 432, Iters 5625, Validation Loss: 710872.87\n",
      "Epoch 442, Iters 5750, Validation Loss: 61865855722212630528.00\n",
      "Epoch 451, Iters 5875, Validation Loss: 431435.35\n",
      "Epoch 461, Iters 6000, Validation Loss: 629346.36\n",
      "Epoch 471, Iters 6125, Validation Loss: 1758785117211.80\n",
      "Epoch 480, Iters 6250, Validation Loss: 668107.02\n",
      "Epoch 490, Iters 6375, Validation Loss: 516168.10\n",
      "Epoch 499, Iters 6500, Validation Loss: 589348.29\n",
      "Epoch 509, Iters 6625, Validation Loss: 559989.29\n",
      "Epoch 519, Iters 6750, Validation Loss: 450703.85\n",
      "Epoch 528, Iters 6875, Validation Loss: 749673.65\n",
      "Epoch 538, Iters 7000, Validation Loss: 572962.65\n",
      "Epoch 548, Iters 7125, Validation Loss: 856170.62\n",
      "Epoch 557, Iters 7250, Validation Loss: 630385.61\n",
      "Epoch 567, Iters 7375, Validation Loss: 745006.97\n",
      "Epoch 576, Iters 7500, Validation Loss: 623195.62\n",
      "Epoch 586, Iters 7625, Validation Loss: 664231.46\n",
      "Early stopping at iters 7625\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 673.34 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 2000                   # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:27<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Obj Val  Constraints Viol  Elapsed Time\n",
      "count     100.000000        100.000000    100.000000\n",
      "mean    69484.209608       3530.943184      0.044577\n",
      "std     10616.024689       5000.081876      0.005323\n",
      "min     52037.889660          0.000000      0.008630\n",
      "25%     62411.279522          0.000000      0.044102\n",
      "50%     69022.660138          0.000000      0.044822\n",
      "75%     76820.048043       6513.637742      0.045942\n",
      "max    101213.855519      18576.920802      0.052401\n",
      "Number of infeasible solution: 47\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lt_50-10000_s.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f038b4a-7343-4662-88db-78ef4c99a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
