{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50     # steepness factor\n",
    "num_blocks = 10000 # number of expression blocks\n",
    "num_data = 9100    # number of data\n",
    "test_size = 100    # number of test size\n",
    "val_size = 1000    # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2bdd74-a0d1-4afa-b610-4f29559a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 2509939.02\n",
      "Epoch 1, Validation Loss: 23547784.62\n",
      "Epoch 2, Validation Loss: 58453234.75\n",
      "Epoch 3, Validation Loss: 82014416.00\n",
      "Epoch 4, Validation Loss: 1776728.77\n",
      "Epoch 5, Validation Loss: 2318687.25\n",
      "Epoch 6, Validation Loss: 1643472.52\n",
      "Epoch 7, Validation Loss: 750567.14\n",
      "Epoch 8, Validation Loss: 900527072.00\n",
      "Epoch 9, Validation Loss: 910287.37\n",
      "Epoch 10, Validation Loss: 1253404.10\n",
      "Epoch 11, Validation Loss: 952552.71\n",
      "Epoch 12, Validation Loss: 858877.54\n",
      "Epoch 13, Validation Loss: 824673.31\n",
      "Epoch 14, Validation Loss: 174276908032.00\n",
      "Epoch 15, Validation Loss: 573625.55\n",
      "Epoch 16, Validation Loss: 783659.38\n",
      "Epoch 17, Validation Loss: 847936.79\n",
      "Epoch 18, Validation Loss: 823323.28\n",
      "Epoch 19, Validation Loss: 807027.33\n",
      "Epoch 20, Validation Loss: 514178.47\n",
      "Epoch 21, Validation Loss: 3645786747831932.00\n",
      "Epoch 22, Validation Loss: 2025600344028.87\n",
      "Epoch 23, Validation Loss: 737151.32\n",
      "Epoch 24, Validation Loss: 1058080698321831168.00\n",
      "Epoch 25, Validation Loss: 577916.02\n",
      "Epoch 26, Validation Loss: 729649.34\n",
      "Epoch 27, Validation Loss: 1189200.23\n",
      "Epoch 28, Validation Loss: 472520200.21\n",
      "Epoch 29, Validation Loss: 670385.35\n",
      "Epoch 30, Validation Loss: 903081.82\n",
      "Epoch 31, Validation Loss: 1509189.31\n",
      "Epoch 32, Validation Loss: 919324.65\n",
      "Epoch 33, Validation Loss: 993225.17\n",
      "Epoch 34, Validation Loss: 738986.55\n",
      "Epoch 35, Validation Loss: 3031774.06\n",
      "Epoch 36, Validation Loss: 68261195397.89\n",
      "Epoch 37, Validation Loss: 4231773.96\n",
      "Epoch 38, Validation Loss: 950274.89\n",
      "Epoch 39, Validation Loss: 893830.49\n",
      "Epoch 40, Validation Loss: 2481224.40\n",
      "Epoch 41, Validation Loss: 1426014.65\n",
      "Epoch 42, Validation Loss: 1631618.34\n",
      "Epoch 43, Validation Loss: 1001989.89\n",
      "Epoch 44, Validation Loss: 1157760.50\n",
      "Epoch 45, Validation Loss: 1575313.11\n",
      "Epoch 46, Validation Loss: 1106317.65\n",
      "Epoch 47, Validation Loss: 1101163.12\n",
      "Epoch 48, Validation Loss: 1260196.65\n",
      "Epoch 49, Validation Loss: 2068195.69\n",
      "Epoch 50, Validation Loss: 1219156.57\n",
      "Epoch 51, Validation Loss: 1359420.47\n",
      "Epoch 52, Validation Loss: 1587869.61\n",
      "Epoch 53, Validation Loss: 3171950.45\n",
      "Epoch 54, Validation Loss: 1860962.22\n",
      "Epoch 55, Validation Loss: 1731613.66\n",
      "Epoch 56, Validation Loss: 2034110.00\n",
      "Epoch 57, Validation Loss: 1636339.46\n",
      "Epoch 58, Validation Loss: 2010283.88\n",
      "Epoch 59, Validation Loss: 5807504.62\n",
      "Epoch 60, Validation Loss: 1992593.00\n",
      "Epoch 61, Validation Loss: 3296412.04\n",
      "Epoch 62, Validation Loss: 6278274.62\n",
      "Epoch 63, Validation Loss: 6171280.03\n",
      "Epoch 64, Validation Loss: 8747890.47\n",
      "Epoch 65, Validation Loss: 6719486.53\n",
      "Epoch 66, Validation Loss: 2269735.67\n",
      "Epoch 67, Validation Loss: 6480776.53\n",
      "Epoch 68, Validation Loss: 2908966.46\n",
      "Epoch 69, Validation Loss: 2949751.98\n",
      "Epoch 70, Validation Loss: 4843673.77\n",
      "Epoch 71, Validation Loss: 2777612.10\n",
      "Epoch 72, Validation Loss: 9785525.25\n",
      "Epoch 73, Validation Loss: 4860931.91\n",
      "Epoch 74, Validation Loss: 11611035.78\n",
      "Epoch 75, Validation Loss: 7347044.84\n",
      "Epoch 76, Validation Loss: 21583114.81\n",
      "Epoch 77, Validation Loss: 5528691.34\n",
      "Epoch 78, Validation Loss: 5510145.28\n",
      "Epoch 79, Validation Loss: 6613727.03\n",
      "Epoch 80, Validation Loss: 13633183.56\n",
      "Epoch 81, Validation Loss: 5566503.62\n",
      "Epoch 82, Validation Loss: 20659224.12\n",
      "Epoch 83, Validation Loss: 10745352.84\n",
      "Epoch 84, Validation Loss: 6397096.02\n",
      "Epoch 85, Validation Loss: 13418135.69\n",
      "Epoch 86, Validation Loss: 5879616.70\n",
      "Epoch 87, Validation Loss: 19454005.44\n",
      "Epoch 88, Validation Loss: 6952964.22\n",
      "Epoch 89, Validation Loss: 18029807.88\n",
      "Epoch 90, Validation Loss: 9411924.00\n",
      "Epoch 91, Validation Loss: 8282959.12\n",
      "Epoch 92, Validation Loss: 9146146.47\n",
      "Epoch 93, Validation Loss: 6930528.69\n",
      "Epoch 94, Validation Loss: 7037364.47\n",
      "Epoch 95, Validation Loss: 23278015.38\n",
      "Epoch 96, Validation Loss: 9652331.72\n",
      "Epoch 97, Validation Loss: 7305458.41\n",
      "Epoch 98, Validation Loss: 8749469.61\n",
      "Epoch 99, Validation Loss: 17858695.12\n",
      "Epoch 100, Validation Loss: 9971815.69\n",
      "Epoch 101, Validation Loss: 96297763461622124802736128.00\n",
      "Epoch 102, Validation Loss: 11517552.91\n",
      "Epoch 103, Validation Loss: 22042121.88\n",
      "Epoch 104, Validation Loss: 13411749.31\n",
      "Epoch 105, Validation Loss: 24321129.06\n",
      "Epoch 106, Validation Loss: 26014046.62\n",
      "Epoch 107, Validation Loss: 26509036.00\n",
      "Epoch 108, Validation Loss: 64394835.00\n",
      "Epoch 109, Validation Loss: 32734807.25\n",
      "Epoch 110, Validation Loss: 110373771.00\n",
      "Epoch 111, Validation Loss: 53906895.75\n",
      "Epoch 112, Validation Loss: 93302667.00\n",
      "Epoch 113, Validation Loss: 15393494.25\n",
      "Epoch 114, Validation Loss: 17661034.25\n",
      "Epoch 115, Validation Loss: 20189527.31\n",
      "Epoch 116, Validation Loss: 49018370.38\n",
      "Epoch 117, Validation Loss: 76972552.50\n",
      "Epoch 118, Validation Loss: 44590429.88\n",
      "Epoch 119, Validation Loss: 67953451.75\n",
      "Early stopping at epoch 119\n",
      "Training complete.\n",
      "The training time is 1279.12 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "growth_rate = 1.05              # growth rate of penalty weight\n",
    "warmup = 100                    # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, growth_rate, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:04<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Obj Val  Constraints Viol  Elapsed Time\n",
      "count     100.000000        100.000000    100.000000\n",
      "mean    63626.348273       1235.677313      0.043885\n",
      "std     28777.423522       2586.693146      0.005502\n",
      "min     31790.694680          0.000000      0.009685\n",
      "25%     43102.664582          0.000000      0.043583\n",
      "50%     58977.611022          0.000000      0.044210\n",
      "75%     73317.742547        280.030469      0.044947\n",
      "max    181913.900579      11011.112657      0.050132\n",
      "Number of infeasible solution: 29\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lr_50-10000_g.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7912a689-22cd-4d7b-a50f-d136dbdf5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 1024          # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                          int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 2261953.14\n",
      "Epoch 1, Validation Loss: 5502742.38\n",
      "Epoch 2, Validation Loss: 17991258.31\n",
      "Epoch 3, Validation Loss: 4205453.38\n",
      "Epoch 4, Validation Loss: 836171.16\n",
      "Epoch 5, Validation Loss: 6899973.69\n",
      "Epoch 6, Validation Loss: 12085742.38\n",
      "Epoch 7, Validation Loss: 1298501.09\n",
      "Epoch 8, Validation Loss: 1087976.26\n",
      "Epoch 9, Validation Loss: 921761.50\n",
      "Epoch 10, Validation Loss: 1376663.16\n",
      "Epoch 11, Validation Loss: 612936.82\n",
      "Epoch 12, Validation Loss: 762866.61\n",
      "Epoch 13, Validation Loss: 488358.23\n",
      "Epoch 14, Validation Loss: 671314.54\n",
      "Epoch 15, Validation Loss: 1021050.08\n",
      "Epoch 16, Validation Loss: 1672443.76\n",
      "Epoch 17, Validation Loss: 1435136.34\n",
      "Epoch 18, Validation Loss: 536777.08\n",
      "Epoch 19, Validation Loss: 503884.12\n",
      "Epoch 20, Validation Loss: 587396.50\n",
      "Epoch 21, Validation Loss: 619552.91\n",
      "Epoch 22, Validation Loss: 544987.35\n",
      "Epoch 23, Validation Loss: 1078910.28\n",
      "Epoch 24, Validation Loss: 2551614.24\n",
      "Epoch 25, Validation Loss: 743638.53\n",
      "Epoch 26, Validation Loss: 550786.89\n",
      "Epoch 27, Validation Loss: 1382958.76\n",
      "Epoch 28, Validation Loss: 679315.37\n",
      "Epoch 29, Validation Loss: 1173715.06\n",
      "Epoch 30, Validation Loss: 915422.50\n",
      "Epoch 31, Validation Loss: 1073878.26\n",
      "Epoch 32, Validation Loss: 730850.76\n",
      "Epoch 33, Validation Loss: 783386.30\n",
      "Epoch 34, Validation Loss: 896766.93\n",
      "Epoch 35, Validation Loss: 2231849899786240.00\n",
      "Epoch 36, Validation Loss: 1122318.29\n",
      "Epoch 37, Validation Loss: 891104.92\n",
      "Epoch 38, Validation Loss: 1650079.60\n",
      "Epoch 39, Validation Loss: 1082477.87\n",
      "Epoch 40, Validation Loss: 1153899.07\n",
      "Epoch 41, Validation Loss: 1194662.57\n",
      "Epoch 42, Validation Loss: 1057689.48\n",
      "Epoch 43, Validation Loss: 1435155.10\n",
      "Epoch 44, Validation Loss: 1436389.08\n",
      "Epoch 45, Validation Loss: 1268927.71\n",
      "Epoch 46, Validation Loss: 1629860.01\n",
      "Epoch 47, Validation Loss: 1526517.90\n",
      "Epoch 48, Validation Loss: 1597159.86\n",
      "Epoch 49, Validation Loss: 1297272.95\n",
      "Epoch 50, Validation Loss: 1432254.64\n",
      "Epoch 51, Validation Loss: 4868124.34\n",
      "Epoch 52, Validation Loss: 1474378.91\n",
      "Epoch 53, Validation Loss: 3359217.69\n",
      "Epoch 54, Validation Loss: 1817801.02\n",
      "Epoch 55, Validation Loss: 1856471.58\n",
      "Epoch 56, Validation Loss: 3492366.74\n",
      "Epoch 57, Validation Loss: 4863185.25\n",
      "Epoch 58, Validation Loss: 2831662.71\n",
      "Epoch 59, Validation Loss: 2724803.12\n",
      "Epoch 60, Validation Loss: 2667491.86\n",
      "Epoch 61, Validation Loss: 6113499.53\n",
      "Epoch 62, Validation Loss: 4111496.06\n",
      "Epoch 63, Validation Loss: 3146115.58\n",
      "Epoch 64, Validation Loss: 9247136.16\n",
      "Epoch 65, Validation Loss: 3981692.98\n",
      "Epoch 66, Validation Loss: 31048167.09\n",
      "Epoch 67, Validation Loss: 3068059.35\n",
      "Epoch 68, Validation Loss: 2993417.73\n",
      "Epoch 69, Validation Loss: 3363152.01\n",
      "Epoch 70, Validation Loss: 4755683.30\n",
      "Epoch 71, Validation Loss: 5615435.06\n",
      "Epoch 72, Validation Loss: 11624187.50\n",
      "Epoch 73, Validation Loss: 4174882.17\n",
      "Epoch 74, Validation Loss: 3601318.34\n",
      "Epoch 75, Validation Loss: 6149421.19\n",
      "Epoch 76, Validation Loss: 4280565.06\n",
      "Epoch 77, Validation Loss: 4977339.06\n",
      "Epoch 78, Validation Loss: 5154617.42\n",
      "Epoch 79, Validation Loss: 10727358.31\n",
      "Epoch 80, Validation Loss: 6712542.19\n",
      "Epoch 81, Validation Loss: 10376862.12\n",
      "Epoch 82, Validation Loss: 5409615.22\n",
      "Epoch 83, Validation Loss: 4916216.77\n",
      "Epoch 84, Validation Loss: 5385338.80\n",
      "Epoch 85, Validation Loss: 5836710.97\n",
      "Epoch 86, Validation Loss: 19726576.19\n",
      "Epoch 87, Validation Loss: 9184865.00\n",
      "Epoch 88, Validation Loss: 12590877.91\n",
      "Epoch 89, Validation Loss: 11515165.81\n",
      "Epoch 90, Validation Loss: 20473839.81\n",
      "Epoch 91, Validation Loss: 12273826.69\n",
      "Epoch 92, Validation Loss: 8605096.91\n",
      "Epoch 93, Validation Loss: 19967621.38\n",
      "Epoch 94, Validation Loss: 14994387.31\n",
      "Epoch 95, Validation Loss: 9910748.16\n",
      "Epoch 96, Validation Loss: 13295535.12\n",
      "Epoch 97, Validation Loss: 53435866.75\n",
      "Epoch 98, Validation Loss: 31942355.62\n",
      "Epoch 99, Validation Loss: 30356344.12\n",
      "Epoch 100, Validation Loss: 21625205.38\n",
      "Epoch 101, Validation Loss: 9962534.66\n",
      "Epoch 102, Validation Loss: 18118307.19\n",
      "Epoch 103, Validation Loss: 137251305.50\n",
      "Epoch 104, Validation Loss: 66752806.50\n",
      "Epoch 105, Validation Loss: 44659707.38\n",
      "Epoch 106, Validation Loss: 14583210.50\n",
      "Epoch 107, Validation Loss: 100969207.00\n",
      "Epoch 108, Validation Loss: 11694680.47\n",
      "Epoch 109, Validation Loss: 50551094371155968.00\n",
      "Epoch 110, Validation Loss: 19066684.56\n",
      "Epoch 111, Validation Loss: 19960916.56\n",
      "Epoch 112, Validation Loss: 19822770.75\n",
      "Epoch 113, Validation Loss: 27945034.19\n",
      "Epoch 114, Validation Loss: 30643647.88\n",
      "Epoch 115, Validation Loss: 20503890.06\n",
      "Epoch 116, Validation Loss: 62782641.00\n",
      "Epoch 117, Validation Loss: 180324544.00\n",
      "Epoch 118, Validation Loss: 77907425.50\n",
      "Epoch 119, Validation Loss: 25165126.44\n",
      "Early stopping at epoch 119\n",
      "Training complete.\n",
      "The training time is 1317.13 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "growth_rate = 1.05              # growth rate of penalty weight\n",
    "warmup = 100                    # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, growth_rate, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:08<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count    100.000000        100.000000    100.000000\n",
      "mean   63734.967524       1512.467540      0.044170\n",
      "std    14244.809246       2494.979695      0.003695\n",
      "min    36076.500470          0.000000      0.018102\n",
      "25%    53311.875956          0.000000      0.043784\n",
      "50%    64431.540511          0.000000      0.044155\n",
      "75%    73679.794544       2364.137532      0.044893\n",
      "max    95452.911812       9354.581696      0.051168\n",
      "Number of infeasible solution: 39\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_lr_50-10000_g.csv\")\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f038b4a-7343-4662-88db-78ef4c99a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
