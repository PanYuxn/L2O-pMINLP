{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50    # steepness factor\n",
    "num_blocks = 2    # number of expression blocks\n",
    "num_data = 5000   # number of data\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "loader_train = DataLoader(data_train, batch_size=32, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size=32, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size=32, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e326fa-de2f-415e-a4d4-1f28eef6511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                         | 53/1000 [06:29<1:55:56,  7.35s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test,a_test))):\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    tick = time.time()\n",
    "    xval, objval = model.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(xval.values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/rb_exact_m.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96304fbd-08f5-4be7-a81e-83c85332029c",
   "metadata": {},
   "source": [
    "## Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "356187af-e02d-4478-bf78-ada6a2e1b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_heur = model.first_solution_heuristic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4c7fc52-cbbc-4414-bf1d-316d65c8db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:25<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000            1000.0   1000.000000\n",
      "mean    950.369241               0.0      0.084850\n",
      "std     616.480055               0.0      0.039165\n",
      "min     119.733136               0.0      0.059156\n",
      "25%     321.880600               0.0      0.062185\n",
      "50%     806.734458               0.0      0.075879\n",
      "75%    1499.065030               0.0      0.078666\n",
      "max    2022.924515               0.0      0.388860\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test,a_test))):\n",
    "    model_heur.set_param_val({\"p\":p, \"a\":a})\n",
    "    tick = time.time()\n",
    "    xval, objval = model_heur.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(xval.values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model_heur.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/rb_heur_m.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 4       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 32            # width of hidden layers for solution mapping\n",
    "lr = 1e-2             # learning rate\n",
    "batch_size = 64       # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# define Rosenbrock objective functions and constraints for both problem types\n",
    "obj_rel, constrs_rel = nmRosenbrock([\"x\"], [\"p\", \"a\"], steepness, num_blocks, penalty_weight=penalty_weight)\n",
    "obj_rnd, constrs_rnd = nmRosenbrock([\"x_rnd\"], [\"p\", \"a\"], steepness, num_blocks, penalty_weight=penalty_weight)\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],\n",
    "                       output_keys=[\"x_rnd\"], int_ind=model.int_ind, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = [smap, rnd]\n",
    "loss = nm.loss.PenaltyLoss(obj_rnd, constrs_rnd)\n",
    "problem = nm.problem.Problem(components, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 104.50736236572266\n",
      "epoch: 1  train_loss: 49.16930389404297\n",
      "epoch: 2  train_loss: 44.45543670654297\n",
      "epoch: 3  train_loss: 35.22999954223633\n",
      "epoch: 4  train_loss: 34.56815719604492\n",
      "epoch: 5  train_loss: 27.8295955657959\n",
      "epoch: 6  train_loss: 28.724287033081055\n",
      "epoch: 7  train_loss: 31.84865951538086\n",
      "epoch: 8  train_loss: 27.3794002532959\n",
      "epoch: 9  train_loss: 23.089242935180664\n",
      "epoch: 10  train_loss: 20.871292114257812\n",
      "epoch: 11  train_loss: 18.80219078063965\n",
      "epoch: 12  train_loss: 19.508909225463867\n",
      "epoch: 13  train_loss: 17.975379943847656\n",
      "epoch: 14  train_loss: 18.356740951538086\n",
      "epoch: 15  train_loss: 17.13743782043457\n",
      "epoch: 16  train_loss: 18.1928653717041\n",
      "epoch: 17  train_loss: 13.30143928527832\n",
      "epoch: 18  train_loss: 13.790485382080078\n",
      "epoch: 19  train_loss: 12.904794692993164\n",
      "epoch: 20  train_loss: 14.5535306930542\n",
      "epoch: 21  train_loss: 12.94597339630127\n",
      "epoch: 22  train_loss: 12.660889625549316\n",
      "epoch: 23  train_loss: 15.191707611083984\n",
      "epoch: 24  train_loss: 12.7969331741333\n",
      "epoch: 25  train_loss: 12.89606761932373\n",
      "epoch: 26  train_loss: 13.158745765686035\n",
      "epoch: 27  train_loss: 12.880878448486328\n",
      "epoch: 28  train_loss: 12.217449188232422\n",
      "epoch: 29  train_loss: 12.661105155944824\n",
      "epoch: 30  train_loss: 13.02100658416748\n",
      "epoch: 31  train_loss: 13.282583236694336\n",
      "epoch: 32  train_loss: 13.550216674804688\n",
      "epoch: 33  train_loss: 13.64780330657959\n",
      "epoch: 34  train_loss: 13.264726638793945\n",
      "epoch: 35  train_loss: 12.747758865356445\n",
      "epoch: 36  train_loss: 12.58414363861084\n",
      "epoch: 37  train_loss: 13.554905891418457\n",
      "epoch: 38  train_loss: 13.263618469238281\n",
      "epoch: 39  train_loss: 13.562039375305176\n",
      "epoch: 40  train_loss: 12.51027774810791\n",
      "epoch: 41  train_loss: 13.511019706726074\n",
      "epoch: 42  train_loss: 13.59985637664795\n",
      "epoch: 43  train_loss: 13.272869110107422\n",
      "epoch: 44  train_loss: 13.327698707580566\n",
      "epoch: 45  train_loss: 13.543978691101074\n",
      "epoch: 46  train_loss: 12.888923645019531\n",
      "Early stopping!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.Adam(problem.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test, optimizer, \n",
    "                             epochs=epochs, patience=patience, warmup=warmup)\n",
    "# training for the rounding problem\n",
    "best_model = trainer.train()\n",
    "# load best model dict\n",
    "problem.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 304.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean     13.494995          0.000381      0.002816\n",
      "std       8.372295          0.006183      0.000833\n",
      "min       0.172183          0.000000      0.001000\n",
      "25%       7.683434          0.000000      0.002006\n",
      "50%      11.968182          0.000000      0.002996\n",
      "75%      17.553032          0.000000      0.003018\n",
      "max      45.346165          0.134142      0.007729\n",
      "Number of infeasible solution: 4\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test,a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/rb_nm_m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5ebaf-0fb6-4a76-9e61-8ccb3abc99dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
