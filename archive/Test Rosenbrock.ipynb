{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f6dc2d9310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "num_data = 5000   # number of data\n",
    "num_vars = 5      # number of decision variables\n",
    "num_ints = 5      # number of integer decision variables\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_train = np.random.uniform(1.0, 6.0, (train_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(0.2, 1.2, (train_size, num_vars-1)).astype(np.float32)\n",
    "p_test = np.random.uniform(1.0, 6.0, (test_size, 1)).astype(np.float32)\n",
    "a_test = np.random.uniform(0.2, 1.2, (test_size, num_vars-1)).astype(np.float32)\n",
    "p_dev = np.random.uniform(1.0, 6.0, (val_size, 1)).astype(np.float32)\n",
    "a_dev = np.random.uniform(0.2, 1.2, (val_size, num_vars-1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7678b7-f3c9-4066-816b-a13131bcd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91eaf9b-55bd-417f-a544-84fde74c6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "loader_train = DataLoader(data_train, batch_size=32, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size=32, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size=32, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f16db-28e1-4c9e-bdd3-b747f670c04d",
   "metadata": {},
   "source": [
    "## NM Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c1c5a4-038b-4776-8a44-8ebb5a351e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuromancer as nm\n",
    "from problem.neural import probRosenbrock\n",
    "\n",
    "def getNMProb(round_module):\n",
    "    # parameters\n",
    "    p = nm.constraint.variable(\"p\")\n",
    "    a = nm.constraint.variable(\"a\")\n",
    "    # variables\n",
    "    x_bar = nm.constraint.variable(\"x_bar\")\n",
    "    x_rnd = nm.constraint.variable(\"x_rnd\")\n",
    "\n",
    "    # model\n",
    "    obj_bar, constrs_bar = probRosenbrock(x_bar, p, a, num_vars=num_vars, alpha=100)\n",
    "    obj_rnd, constrs_rnd = probRosenbrock(x_rnd, p, a, num_vars=num_vars, alpha=100)\n",
    "\n",
    "    # define neural architecture for the solution mapping\n",
    "    func = nm.modules.blocks.MLP(insize=num_vars, outsize=num_vars, bias=True,\n",
    "                                 linear_map=nm.slim.maps[\"linear\"], nonlin=nn.ReLU, hsizes=[80]*4)\n",
    "    # solution map from model parameters: sol_map(p) -> x\n",
    "    sol_map = nm.system.Node(func, [\"p\", \"a\"], [\"x_bar\"], name=\"smap\")\n",
    "\n",
    "    # penalty loss for mapping\n",
    "    components = [sol_map]\n",
    "    loss = nm.loss.PenaltyLoss(obj_bar, constrs_bar)\n",
    "    problem = nm.problem.Problem(components, loss)\n",
    "\n",
    "    # penalty loss for rounding\n",
    "    components = [sol_map, round_module]\n",
    "    loss = nm.loss.PenaltyLoss(obj_rnd, constrs_rnd)\n",
    "    problem_rnd = nm.problem.Problem(components, loss)\n",
    "\n",
    "    return problem, problem_rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.solver import exactRosenbrock\n",
    "model = exactRosenbrock(n_vars=num_vars, n_integers=num_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e326fa-de2f-415e-a4d4-1f28eef6511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:38<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000            1000.0   1000.000000\n",
      "mean      1.786264               0.0      0.097874\n",
      "std       1.361469               0.0      0.033692\n",
      "min       0.000000               0.0      0.072185\n",
      "25%       0.466428               0.0      0.076158\n",
      "50%       1.731629               0.0      0.090455\n",
      "75%       2.953879               0.0      0.093186\n",
      "max       4.199299               0.0      0.260935\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    model.setParamValue(p, *a)\n",
    "    tick = time.time()\n",
    "    xval, objval = model.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    sols.append(list(xval.values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30ef9e5-41b5-4b4b-87b3-6c628fa51430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>1.634025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>0.261138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>1.244660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>3.591436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>4.187316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>4.089960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>1.625817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>0.959324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>1.077039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol   Obj Val  Constraints Viol  Elapsed Time\n",
       "0    [1.0, 0.0, 1.0, 1.0, 0.0]  1.634025               0.0      0.129671\n",
       "1    [1.0, 1.0, 1.0, 1.0, 0.0]  0.261138               0.0      0.090487\n",
       "2    [1.0, 1.0, 1.0, 0.0, 0.0]  1.244660               0.0      0.077497\n",
       "3    [1.0, 0.0, 0.0, 0.0, 0.0]  3.591436               0.0      0.075948\n",
       "4    [1.0, 0.0, 0.0, 0.0, 0.0]  4.187316               0.0      0.076479\n",
       "..                         ...       ...               ...           ...\n",
       "995  [1.0, 0.0, 0.0, 0.0, 0.0]  4.089960               0.0      0.182148\n",
       "996  [1.0, 1.0, 1.0, 0.0, 0.0]  1.625817               0.0      0.182140\n",
       "997  [1.0, 1.0, 1.0, 1.0, 0.0]  0.959324               0.0      0.105354\n",
       "998  [1.0, 1.0, 1.0, 1.0, 0.0]  1.077039               0.0      0.090769\n",
       "999  [1.0, 1.0, 1.0, 1.0, 1.0]  0.000000               0.0      0.092748\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e1f73-eaa5-40d9-97fb-3b70009df41b",
   "metadata": {},
   "source": [
    "## Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987f3b11-c41c-4012-b2ef-935f62099616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristic import naive_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161556c9-67af-4686-bfec-d0fdea488bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relaxed model\n",
    "model_rel = model.relax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a6d751-9afa-4b4c-abbb-1b2c9ba6ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [14:25<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      0.490161          1.027246      0.864290\n",
      "std       0.687427          0.742127      0.213636\n",
      "min       0.000000          0.000000      0.435925\n",
      "25%       0.000000          0.266070      0.679214\n",
      "50%       0.000000          1.083178      0.787029\n",
      "75%       0.872345          1.644168      0.994702\n",
      "max       3.176095          2.577283      1.525655\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    model.setParamValue(p, *a)\n",
    "    model_rel.setParamValue(p, *a)\n",
    "    tick = time.time()\n",
    "    xval_init, _ = model_rel.solve(\"scip\", max_iter=100)\n",
    "    naive_round(xval_init, model)\n",
    "    tock = time.time()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(list(xval.values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d215ec-0d10-4803-a119-44070bb93b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 0]</td>\n",
       "      <td>0.229294</td>\n",
       "      <td>0.501649</td>\n",
       "      <td>0.794145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266266</td>\n",
       "      <td>0.791898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.186666</td>\n",
       "      <td>0.786137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 0, 0]</td>\n",
       "      <td>1.407886</td>\n",
       "      <td>1.583487</td>\n",
       "      <td>0.672993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 0]</td>\n",
       "      <td>1.168298</td>\n",
       "      <td>2.072099</td>\n",
       "      <td>0.777687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[1, 1, 1, 0, 0]</td>\n",
       "      <td>2.049713</td>\n",
       "      <td>1.962043</td>\n",
       "      <td>0.789336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.136647</td>\n",
       "      <td>0.771636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414065</td>\n",
       "      <td>0.772562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274599</td>\n",
       "      <td>0.989056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.525655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Sol   Obj Val  Constraints Viol  Elapsed Time\n",
       "0    [1, 1, 1, 1, 0]  0.229294          0.501649      0.794145\n",
       "1    [1, 1, 1, 1, 1]  0.000000          0.266266      0.791898\n",
       "2    [1, 1, 1, 1, 1]  0.000000          1.186666      0.786137\n",
       "3    [1, 1, 1, 0, 0]  1.407886          1.583487      0.672993\n",
       "4    [1, 1, 1, 1, 0]  1.168298          2.072099      0.777687\n",
       "..               ...       ...               ...           ...\n",
       "995  [1, 1, 1, 0, 0]  2.049713          1.962043      0.789336\n",
       "996  [1, 1, 1, 1, 1]  0.000000          1.136647      0.771636\n",
       "997  [1, 1, 1, 1, 1]  0.000000          0.414065      0.772562\n",
       "998  [1, 1, 1, 1, 1]  0.000000          0.274599      0.989056\n",
       "999  [1, 1, 1, 1, 1]  0.000000          0.000000      1.525655\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d961673a-7420-4260-838a-1ef2fb765ceb",
   "metadata": {},
   "source": [
    "## Learning to Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec0072d-675a-4430-ac06-07936115a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.round import roundModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                        int_ind={\"x_bar\":model.int_ind}, name=\"round\")\n",
    "_, problem = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea14d3a4-62f7-409b-874e-c9c58e0322a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 49.70849609375\n",
      "epoch: 1  train_loss: 41.51247024536133\n",
      "epoch: 2  train_loss: 40.15127944946289\n",
      "epoch: 3  train_loss: 50.554386138916016\n",
      "epoch: 4  train_loss: 45.82106018066406\n",
      "epoch: 5  train_loss: 49.82112121582031\n",
      "epoch: 6  train_loss: 40.62741470336914\n",
      "epoch: 7  train_loss: 39.87377166748047\n",
      "epoch: 8  train_loss: 47.59299087524414\n",
      "epoch: 9  train_loss: 42.070716857910156\n",
      "epoch: 10  train_loss: 41.75148010253906\n",
      "epoch: 11  train_loss: 37.79279327392578\n",
      "epoch: 12  train_loss: 46.500038146972656\n",
      "epoch: 13  train_loss: 39.58802032470703\n",
      "epoch: 14  train_loss: 45.82360076904297\n",
      "epoch: 15  train_loss: 49.97172546386719\n",
      "epoch: 16  train_loss: 31.36939239501953\n",
      "epoch: 17  train_loss: 40.5133171081543\n",
      "epoch: 18  train_loss: 38.941890716552734\n",
      "epoch: 19  train_loss: 26.786985397338867\n",
      "epoch: 20  train_loss: 28.458574295043945\n",
      "epoch: 21  train_loss: 25.684894561767578\n",
      "epoch: 22  train_loss: 28.383136749267578\n",
      "epoch: 23  train_loss: 26.57742691040039\n",
      "epoch: 24  train_loss: 43.52534484863281\n",
      "epoch: 25  train_loss: 40.52865219116211\n",
      "epoch: 26  train_loss: 32.44198226928711\n",
      "epoch: 27  train_loss: 43.12491226196289\n",
      "epoch: 28  train_loss: 44.91938018798828\n",
      "epoch: 29  train_loss: 33.34228515625\n",
      "epoch: 30  train_loss: 18.703275680541992\n",
      "epoch: 31  train_loss: 23.830013275146484\n",
      "epoch: 32  train_loss: 39.30241394042969\n",
      "epoch: 33  train_loss: 40.1699333190918\n",
      "epoch: 34  train_loss: 33.57280731201172\n",
      "epoch: 35  train_loss: 27.90878677368164\n",
      "epoch: 36  train_loss: 32.644596099853516\n",
      "epoch: 37  train_loss: 25.16240119934082\n",
      "epoch: 38  train_loss: 54.91907501220703\n",
      "epoch: 39  train_loss: 49.79977798461914\n",
      "epoch: 40  train_loss: 51.61915588378906\n",
      "epoch: 41  train_loss: 49.10498046875\n",
      "epoch: 42  train_loss: 52.333683013916016\n",
      "epoch: 43  train_loss: 56.93072509765625\n",
      "epoch: 44  train_loss: 44.83806610107422\n",
      "epoch: 45  train_loss: 62.353416442871094\n",
      "epoch: 46  train_loss: 54.86134719848633\n",
      "epoch: 47  train_loss: 52.71677017211914\n",
      "epoch: 48  train_loss: 29.382095336914062\n",
      "epoch: 49  train_loss: 34.290245056152344\n",
      "epoch: 50  train_loss: 38.36418914794922\n",
      "epoch: 51  train_loss: 37.90885543823242\n",
      "epoch: 52  train_loss: 31.834516525268555\n",
      "epoch: 53  train_loss: 32.25574493408203\n",
      "epoch: 54  train_loss: 22.86781120300293\n",
      "epoch: 55  train_loss: 24.081729888916016\n",
      "epoch: 56  train_loss: 30.568222045898438\n",
      "epoch: 57  train_loss: 32.60178756713867\n",
      "epoch: 58  train_loss: 25.963228225708008\n",
      "epoch: 59  train_loss: 41.927032470703125\n",
      "epoch: 60  train_loss: 44.99372100830078\n",
      "epoch: 61  train_loss: 30.726232528686523\n",
      "epoch: 62  train_loss: 33.80022048950195\n",
      "epoch: 63  train_loss: 42.083805084228516\n",
      "epoch: 64  train_loss: 44.8328742980957\n",
      "epoch: 65  train_loss: 35.638126373291016\n",
      "epoch: 66  train_loss: 37.132530212402344\n",
      "epoch: 67  train_loss: 33.09760284423828\n",
      "epoch: 68  train_loss: 52.80056381225586\n",
      "epoch: 69  train_loss: 22.53054428100586\n",
      "epoch: 70  train_loss: 37.79369354248047\n",
      "epoch: 71  train_loss: 42.547611236572266\n",
      "epoch: 72  train_loss: 55.63594436645508\n",
      "epoch: 73  train_loss: 33.663787841796875\n",
      "epoch: 74  train_loss: 26.63146209716797\n",
      "epoch: 75  train_loss: 30.347936630249023\n",
      "epoch: 76  train_loss: 58.81232452392578\n",
      "epoch: 77  train_loss: 35.66627502441406\n",
      "epoch: 78  train_loss: 55.187931060791016\n",
      "epoch: 79  train_loss: 51.707149505615234\n",
      "epoch: 80  train_loss: 33.41343307495117\n",
      "epoch: 81  train_loss: 54.98170471191406\n",
      "epoch: 82  train_loss: 54.614864349365234\n",
      "epoch: 83  train_loss: 40.99385070800781\n",
      "epoch: 84  train_loss: 37.16100311279297\n",
      "epoch: 85  train_loss: 35.60750198364258\n",
      "epoch: 86  train_loss: 43.148990631103516\n",
      "epoch: 87  train_loss: 36.961387634277344\n",
      "epoch: 88  train_loss: 35.296329498291016\n",
      "epoch: 89  train_loss: 33.0561408996582\n",
      "epoch: 90  train_loss: 31.741870880126953\n",
      "epoch: 91  train_loss: 41.70676040649414\n",
      "epoch: 92  train_loss: 31.949298858642578\n",
      "epoch: 93  train_loss: 39.72056579589844\n",
      "epoch: 94  train_loss: 19.189943313598633\n",
      "epoch: 95  train_loss: 27.702579498291016\n",
      "epoch: 96  train_loss: 26.443897247314453\n",
      "epoch: 97  train_loss: 29.333038330078125\n",
      "epoch: 98  train_loss: 36.631351470947266\n",
      "epoch: 99  train_loss: 47.89558029174805\n",
      "epoch: 100  train_loss: 59.96437454223633\n",
      "epoch: 101  train_loss: 37.926170349121094\n",
      "epoch: 102  train_loss: 33.80072021484375\n",
      "epoch: 103  train_loss: 48.59488296508789\n",
      "epoch: 104  train_loss: 56.154170989990234\n",
      "epoch: 105  train_loss: 49.32158660888672\n",
      "epoch: 106  train_loss: 67.3429183959961\n",
      "epoch: 107  train_loss: 35.531898498535156\n",
      "epoch: 108  train_loss: 33.8956413269043\n",
      "epoch: 109  train_loss: 40.5483283996582\n",
      "epoch: 110  train_loss: 53.459712982177734\n",
      "epoch: 111  train_loss: 46.87699508666992\n",
      "epoch: 112  train_loss: 53.34752655029297\n",
      "epoch: 113  train_loss: 39.30107116699219\n",
      "epoch: 114  train_loss: 32.891170501708984\n",
      "epoch: 115  train_loss: 33.62191390991211\n",
      "epoch: 116  train_loss: 33.53410339355469\n",
      "epoch: 117  train_loss: 48.58388137817383\n",
      "epoch: 118  train_loss: 48.21250534057617\n",
      "epoch: 119  train_loss: 58.45820617675781\n",
      "epoch: 120  train_loss: 38.2036018371582\n",
      "epoch: 121  train_loss: 36.246620178222656\n",
      "epoch: 122  train_loss: 19.718069076538086\n",
      "epoch: 123  train_loss: 37.93036651611328\n",
      "epoch: 124  train_loss: 52.54172897338867\n",
      "epoch: 125  train_loss: 50.12855911254883\n",
      "epoch: 126  train_loss: 53.24464416503906\n",
      "epoch: 127  train_loss: 46.45599365234375\n",
      "epoch: 128  train_loss: 45.3583869934082\n",
      "epoch: 129  train_loss: 40.88192367553711\n",
      "epoch: 130  train_loss: 46.10515594482422\n",
      "epoch: 131  train_loss: 62.674354553222656\n",
      "epoch: 132  train_loss: 58.01472473144531\n",
      "epoch: 133  train_loss: 46.89524841308594\n",
      "epoch: 134  train_loss: 56.954017639160156\n",
      "epoch: 135  train_loss: 46.08685302734375\n",
      "epoch: 136  train_loss: 41.12287139892578\n",
      "epoch: 137  train_loss: 40.73546600341797\n",
      "epoch: 138  train_loss: 46.3673210144043\n",
      "epoch: 139  train_loss: 54.0826530456543\n",
      "epoch: 140  train_loss: 54.11771774291992\n",
      "epoch: 141  train_loss: 56.66830062866211\n",
      "epoch: 142  train_loss: 45.98710632324219\n",
      "epoch: 143  train_loss: 55.46737289428711\n",
      "epoch: 144  train_loss: 46.11493682861328\n",
      "epoch: 145  train_loss: 35.566123962402344\n",
      "epoch: 146  train_loss: 36.945838928222656\n",
      "epoch: 147  train_loss: 66.9978256225586\n",
      "epoch: 148  train_loss: 65.83106994628906\n",
      "epoch: 149  train_loss: 41.41616439819336\n",
      "epoch: 150  train_loss: 35.1116828918457\n",
      "epoch: 151  train_loss: 48.94696807861328\n",
      "epoch: 152  train_loss: 29.857501983642578\n",
      "epoch: 153  train_loss: 33.9711799621582\n",
      "epoch: 154  train_loss: 31.539255142211914\n",
      "epoch: 155  train_loss: 36.363285064697266\n",
      "epoch: 156  train_loss: 29.809354782104492\n",
      "epoch: 157  train_loss: 26.524988174438477\n",
      "epoch: 158  train_loss: 32.55878448486328\n",
      "epoch: 159  train_loss: 43.14395523071289\n",
      "epoch: 160  train_loss: 42.027748107910156\n",
      "epoch: 161  train_loss: 37.02313232421875\n",
      "epoch: 162  train_loss: 43.184898376464844\n",
      "epoch: 163  train_loss: 52.23621368408203\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b034b7-d404-4e6d-aa6f-11ae008ef1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 253.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      4.635183          0.187780      0.003456\n",
      "std       0.665417          0.358798      0.000792\n",
      "min       2.391423          0.000000      0.001996\n",
      "25%       4.182341          0.000000      0.003000\n",
      "50%       4.613650          0.000000      0.003140\n",
      "75%       5.032913          0.211223      0.003997\n",
      "max       8.252681          2.135950      0.006531\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # eval\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef53dacf-0aa4-4142-9252-ef6195fc9bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.306289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>4.530400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>4.081789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>4.189243</td>\n",
       "      <td>0.583487</td>\n",
       "      <td>0.005495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>5.372702</td>\n",
       "      <td>0.072099</td>\n",
       "      <td>0.004017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>4.807213</td>\n",
       "      <td>0.962043</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>5.250714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>5.319346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>5.160257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.766097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol   Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (1.0, 0.0, 1.0, 0.0, 1.0)  3.306289          0.000000      0.005077\n",
       "1    (1.0, 0.0, 1.0, 0.0, 1.0)  4.530400          0.000000      0.005055\n",
       "2    (1.0, 0.0, 1.0, 0.0, 1.0)  4.081789          0.000000      0.005428\n",
       "3    (1.0, 0.0, 1.0, 0.0, 0.0)  4.189243          0.583487      0.005495\n",
       "4    (1.0, 0.0, 1.0, 0.0, 0.0)  5.372702          0.072099      0.004017\n",
       "..                         ...       ...               ...           ...\n",
       "995  (1.0, 0.0, 1.0, 0.0, 0.0)  4.807213          0.962043      0.003000\n",
       "996  (1.0, 0.0, 1.0, 0.0, 1.0)  5.250714          0.000000      0.002504\n",
       "997  (1.0, 0.0, 1.0, 0.0, 1.0)  5.319346          0.000000      0.003005\n",
       "998  (1.0, 0.0, 1.0, 0.0, 1.0)  5.160257          0.000000      0.003608\n",
       "999  (1.0, 0.0, 1.0, 0.0, 1.0)  3.766097          0.000000      0.003004\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae6e5c-983f-4689-88e2-4ef26fe8e910",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "545cae68-65b7-4d0d-b87d-f021dfb0a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.threshold import roundThresholdModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                                 int_ind={\"x_bar\":model.int_ind}, name=\"round\")\n",
    "_, problem = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18744735-a740-489c-bd05-49988544dfac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 57.52654266357422\n",
      "epoch: 1  train_loss: 45.62474060058594\n",
      "epoch: 2  train_loss: 36.37605285644531\n",
      "epoch: 3  train_loss: 43.228328704833984\n",
      "epoch: 4  train_loss: 41.60516357421875\n",
      "epoch: 5  train_loss: 41.10173034667969\n",
      "epoch: 6  train_loss: 45.800567626953125\n",
      "epoch: 7  train_loss: 45.91948699951172\n",
      "epoch: 8  train_loss: 54.22880554199219\n",
      "epoch: 9  train_loss: 53.48687744140625\n",
      "epoch: 10  train_loss: 53.12178039550781\n",
      "epoch: 11  train_loss: 58.54276657104492\n",
      "epoch: 12  train_loss: 62.96484375\n",
      "epoch: 13  train_loss: 68.48212432861328\n",
      "epoch: 14  train_loss: 57.43519973754883\n",
      "epoch: 15  train_loss: 58.23943328857422\n",
      "epoch: 16  train_loss: 65.05147552490234\n",
      "epoch: 17  train_loss: 62.89979934692383\n",
      "epoch: 18  train_loss: 68.83914947509766\n",
      "epoch: 19  train_loss: 69.84069061279297\n",
      "epoch: 20  train_loss: 73.07505798339844\n",
      "epoch: 21  train_loss: 73.09027862548828\n",
      "epoch: 22  train_loss: 71.87255859375\n",
      "epoch: 23  train_loss: 69.55891418457031\n",
      "epoch: 24  train_loss: 85.33383178710938\n",
      "epoch: 25  train_loss: 78.64768981933594\n",
      "epoch: 26  train_loss: 74.78836822509766\n",
      "epoch: 27  train_loss: 83.17051696777344\n",
      "epoch: 28  train_loss: 82.2547378540039\n",
      "epoch: 29  train_loss: 79.9564208984375\n",
      "epoch: 30  train_loss: 71.31586456298828\n",
      "epoch: 31  train_loss: 73.95552062988281\n",
      "epoch: 32  train_loss: 71.07565307617188\n",
      "epoch: 33  train_loss: 77.25051879882812\n",
      "epoch: 34  train_loss: 95.21157836914062\n",
      "epoch: 35  train_loss: 92.88217163085938\n",
      "epoch: 36  train_loss: 86.46028137207031\n",
      "epoch: 37  train_loss: 92.31503295898438\n",
      "epoch: 38  train_loss: 86.13915252685547\n",
      "epoch: 39  train_loss: 89.45137023925781\n",
      "epoch: 40  train_loss: 79.71090698242188\n",
      "epoch: 41  train_loss: 85.1822738647461\n",
      "epoch: 42  train_loss: 86.26256561279297\n",
      "epoch: 43  train_loss: 89.6319580078125\n",
      "epoch: 44  train_loss: 81.73242950439453\n",
      "epoch: 45  train_loss: 83.60310363769531\n",
      "epoch: 46  train_loss: 71.18938446044922\n",
      "epoch: 47  train_loss: 83.1888427734375\n",
      "epoch: 48  train_loss: 89.63766479492188\n",
      "epoch: 49  train_loss: 89.63735961914062\n",
      "epoch: 50  train_loss: 99.26467895507812\n",
      "epoch: 51  train_loss: 90.48334503173828\n",
      "epoch: 52  train_loss: 87.93376922607422\n",
      "epoch: 53  train_loss: 88.0984878540039\n",
      "epoch: 54  train_loss: 84.63125610351562\n",
      "epoch: 55  train_loss: 86.93733215332031\n",
      "epoch: 56  train_loss: 95.80000305175781\n",
      "epoch: 57  train_loss: 93.65621185302734\n",
      "epoch: 58  train_loss: 89.88484954833984\n",
      "epoch: 59  train_loss: 85.24664306640625\n",
      "epoch: 60  train_loss: 63.74293899536133\n",
      "epoch: 61  train_loss: 103.13243865966797\n",
      "epoch: 62  train_loss: 75.07125854492188\n",
      "epoch: 63  train_loss: 95.70347595214844\n",
      "epoch: 64  train_loss: 91.93980407714844\n",
      "epoch: 65  train_loss: 93.61986541748047\n",
      "epoch: 66  train_loss: 84.85299682617188\n",
      "epoch: 67  train_loss: 73.72969055175781\n",
      "epoch: 68  train_loss: 89.97489929199219\n",
      "epoch: 69  train_loss: 90.4391098022461\n",
      "epoch: 70  train_loss: 96.67642211914062\n",
      "epoch: 71  train_loss: 96.90567016601562\n",
      "epoch: 72  train_loss: 85.10087585449219\n",
      "epoch: 73  train_loss: 90.42621612548828\n",
      "epoch: 74  train_loss: 94.55107879638672\n",
      "epoch: 75  train_loss: 81.86030578613281\n",
      "epoch: 76  train_loss: 66.76956939697266\n",
      "epoch: 77  train_loss: 90.63338470458984\n",
      "epoch: 78  train_loss: 70.01103973388672\n",
      "epoch: 79  train_loss: 94.68238067626953\n",
      "epoch: 80  train_loss: 79.85842895507812\n",
      "epoch: 81  train_loss: 87.3447036743164\n",
      "epoch: 82  train_loss: 87.04232025146484\n",
      "epoch: 83  train_loss: 81.85177612304688\n",
      "epoch: 84  train_loss: 88.4196548461914\n",
      "epoch: 85  train_loss: 79.01069641113281\n",
      "epoch: 86  train_loss: 78.87006378173828\n",
      "epoch: 87  train_loss: 90.7605972290039\n",
      "epoch: 88  train_loss: 79.52867889404297\n",
      "epoch: 89  train_loss: 92.89768981933594\n",
      "epoch: 90  train_loss: 94.43547058105469\n",
      "epoch: 91  train_loss: 84.81609344482422\n",
      "epoch: 92  train_loss: 94.6994857788086\n",
      "epoch: 93  train_loss: 80.73968505859375\n",
      "epoch: 94  train_loss: 96.27637481689453\n",
      "epoch: 95  train_loss: 80.9494400024414\n",
      "epoch: 96  train_loss: 90.81448364257812\n",
      "epoch: 97  train_loss: 101.20954895019531\n",
      "epoch: 98  train_loss: 74.71871185302734\n",
      "epoch: 99  train_loss: 87.86068725585938\n",
      "epoch: 100  train_loss: 89.7264404296875\n",
      "epoch: 101  train_loss: 95.8794174194336\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234958b5-a9bd-4a1a-b56a-edd8f2cbd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 260.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean     20.475778          1.022164      0.003326\n",
      "std      12.800103          0.904140      0.000735\n",
      "min       4.000000          0.000000      0.001996\n",
      "25%       8.199815          0.180235      0.003000\n",
      "50%      22.165774          0.749944      0.003005\n",
      "75%      31.056224          1.703099      0.003595\n",
      "max      54.667122          3.435206      0.006511\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58dadbb8-4f2b-4c1e-b4b4-bd9acaf2e235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 1.0, -2.0, 0.0)</td>\n",
       "      <td>20.919400</td>\n",
       "      <td>1.501649</td>\n",
       "      <td>0.006274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 0.0, 0.0, -2.0, 0.0)</td>\n",
       "      <td>19.043393</td>\n",
       "      <td>0.266266</td>\n",
       "      <td>0.005022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 1.0, -1.0, 0.0)</td>\n",
       "      <td>7.815769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.708256</td>\n",
       "      <td>0.006302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 0.0, 0.0, -1.0, 0.0)</td>\n",
       "      <td>9.361666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.518979</td>\n",
       "      <td>0.002995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(1.0, 0.0, 0.0, -1.0, 0.0)</td>\n",
       "      <td>8.155153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(1.0, 0.0, 0.0, -2.0, 0.0)</td>\n",
       "      <td>29.884134</td>\n",
       "      <td>0.414065</td>\n",
       "      <td>0.003925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(1.0, 0.0, 0.0, -2.0, 0.0)</td>\n",
       "      <td>32.926288</td>\n",
       "      <td>0.274599</td>\n",
       "      <td>0.003003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(2.0, 0.0, 0.0, -2.0, 0.0)</td>\n",
       "      <td>24.478540</td>\n",
       "      <td>2.475116</td>\n",
       "      <td>0.002997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sol    Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (0.0, 0.0, 1.0, -2.0, 0.0)  20.919400          1.501649      0.006274\n",
       "1    (1.0, 0.0, 0.0, -2.0, 0.0)  19.043393          0.266266      0.005022\n",
       "2    (1.0, 0.0, 1.0, -1.0, 0.0)   7.815769          0.000000      0.005499\n",
       "3     (0.0, 0.0, 0.0, 0.0, 0.0)   4.000000          0.708256      0.006302\n",
       "4    (0.0, 0.0, 0.0, -1.0, 0.0)   9.361666          0.000000      0.005533\n",
       "..                          ...        ...               ...           ...\n",
       "995   (0.0, 0.0, 0.0, 0.0, 0.0)   4.000000          0.518979      0.002995\n",
       "996  (1.0, 0.0, 0.0, -1.0, 0.0)   8.155153          0.000000      0.002585\n",
       "997  (1.0, 0.0, 0.0, -2.0, 0.0)  29.884134          0.414065      0.003925\n",
       "998  (1.0, 0.0, 0.0, -2.0, 0.0)  32.926288          0.274599      0.003003\n",
       "999  (2.0, 0.0, 0.0, -2.0, 0.0)  24.478540          2.475116      0.002997\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c777ad-d5a3-4065-a137-123aa84c0df5",
   "metadata": {},
   "source": [
    "## Learning to Round with Fixed Solution Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64737e09-1735-4893-a0d6-c8ca73a91fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.round import roundModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                        int_ind={\"x_bar\":model.int_ind}, name=\"round\")\n",
    "problem_rel, problem_rnd = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b39c4a7-2b21-4384-9d85-2e479ce85965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 34.12492370605469\n",
      "epoch: 1  train_loss: 2.0818397998809814\n",
      "epoch: 2  train_loss: 0.470735639333725\n",
      "epoch: 3  train_loss: 0.437946081161499\n",
      "epoch: 4  train_loss: 0.4126089811325073\n",
      "epoch: 5  train_loss: 0.41550078988075256\n",
      "epoch: 6  train_loss: 0.3635338246822357\n",
      "epoch: 7  train_loss: 0.40750646591186523\n",
      "epoch: 8  train_loss: 0.45146796107292175\n",
      "epoch: 9  train_loss: 0.40358108282089233\n",
      "epoch: 10  train_loss: 0.3790501654148102\n",
      "epoch: 11  train_loss: 0.3917309045791626\n",
      "epoch: 12  train_loss: 0.37835943698883057\n",
      "epoch: 13  train_loss: 0.3908189535140991\n",
      "epoch: 14  train_loss: 0.3323489725589752\n",
      "epoch: 15  train_loss: 0.40534210205078125\n",
      "epoch: 16  train_loss: 0.3614099323749542\n",
      "epoch: 17  train_loss: 0.3596763610839844\n",
      "epoch: 18  train_loss: 0.352710485458374\n",
      "epoch: 19  train_loss: 0.3680935800075531\n",
      "epoch: 20  train_loss: 0.3954349160194397\n",
      "epoch: 21  train_loss: 0.3657650649547577\n",
      "epoch: 22  train_loss: 0.39406174421310425\n",
      "epoch: 23  train_loss: 0.38066908717155457\n",
      "epoch: 24  train_loss: 0.38598307967185974\n",
      "epoch: 25  train_loss: 0.35441163182258606\n",
      "epoch: 26  train_loss: 0.3503684103488922\n",
      "epoch: 27  train_loss: 0.3786686360836029\n",
      "epoch: 28  train_loss: 0.3917529881000519\n",
      "epoch: 29  train_loss: 0.3779190480709076\n",
      "epoch: 30  train_loss: 0.3713926076889038\n",
      "epoch: 31  train_loss: 0.3469946086406708\n",
      "epoch: 32  train_loss: 0.39772841334342957\n",
      "epoch: 33  train_loss: 0.3562614321708679\n",
      "epoch: 34  train_loss: 0.3717401325702667\n",
      "epoch: 35  train_loss: 0.3592173755168915\n",
      "epoch: 36  train_loss: 0.33612731099128723\n",
      "epoch: 37  train_loss: 0.34908655285835266\n",
      "epoch: 38  train_loss: 0.3848091959953308\n",
      "epoch: 39  train_loss: 0.35607507824897766\n",
      "epoch: 40  train_loss: 0.3038155436515808\n",
      "epoch: 41  train_loss: 0.3757472038269043\n",
      "epoch: 42  train_loss: 0.33878621459007263\n",
      "epoch: 43  train_loss: 0.36805981397628784\n",
      "epoch: 44  train_loss: 0.35590752959251404\n",
      "epoch: 45  train_loss: 0.3394666016101837\n",
      "epoch: 46  train_loss: 0.3481518030166626\n",
      "epoch: 47  train_loss: 0.36334463953971863\n",
      "epoch: 48  train_loss: 0.36087286472320557\n",
      "epoch: 49  train_loss: 0.32732006907463074\n",
      "epoch: 50  train_loss: 0.30470672249794006\n",
      "epoch: 51  train_loss: 0.34165850281715393\n",
      "epoch: 52  train_loss: 0.35417699813842773\n",
      "epoch: 53  train_loss: 0.3276229798793793\n",
      "epoch: 54  train_loss: 0.40584489703178406\n",
      "epoch: 55  train_loss: 0.3610973656177521\n",
      "epoch: 56  train_loss: 0.3245871067047119\n",
      "epoch: 57  train_loss: 0.33519870042800903\n",
      "epoch: 58  train_loss: 0.33276718854904175\n",
      "epoch: 59  train_loss: 0.36259153485298157\n",
      "epoch: 60  train_loss: 0.32377302646636963\n",
      "epoch: 61  train_loss: 0.30624595284461975\n",
      "epoch: 62  train_loss: 0.3577876091003418\n",
      "epoch: 63  train_loss: 0.33914753794670105\n",
      "epoch: 64  train_loss: 0.3165035545825958\n",
      "epoch: 65  train_loss: 0.3420194387435913\n",
      "epoch: 66  train_loss: 0.3213753402233124\n",
      "epoch: 67  train_loss: 0.305695503950119\n",
      "epoch: 68  train_loss: 0.39232733845710754\n",
      "epoch: 69  train_loss: 0.30842822790145874\n",
      "epoch: 70  train_loss: 0.28684714436531067\n",
      "epoch: 71  train_loss: 0.3306483030319214\n",
      "epoch: 72  train_loss: 0.300936222076416\n",
      "epoch: 73  train_loss: 0.2973904311656952\n",
      "epoch: 74  train_loss: 0.37469878792762756\n",
      "epoch: 75  train_loss: 0.36824020743370056\n",
      "epoch: 76  train_loss: 0.3103529214859009\n",
      "epoch: 77  train_loss: 0.29513099789619446\n",
      "epoch: 78  train_loss: 0.3304171562194824\n",
      "epoch: 79  train_loss: 0.3250468969345093\n",
      "epoch: 80  train_loss: 0.35565587878227234\n",
      "epoch: 81  train_loss: 0.30591967701911926\n",
      "epoch: 82  train_loss: 0.29060468077659607\n",
      "epoch: 83  train_loss: 0.3447854816913605\n",
      "epoch: 84  train_loss: 0.3002084791660309\n",
      "epoch: 85  train_loss: 0.3153234124183655\n",
      "epoch: 86  train_loss: 0.34774601459503174\n",
      "epoch: 87  train_loss: 0.30858346819877625\n",
      "epoch: 88  train_loss: 0.37953487038612366\n",
      "epoch: 89  train_loss: 0.33708447217941284\n",
      "epoch: 90  train_loss: 0.3608381450176239\n",
      "epoch: 91  train_loss: 0.3429583013057709\n",
      "epoch: 92  train_loss: 0.31684228777885437\n",
      "epoch: 93  train_loss: 0.33134743571281433\n",
      "epoch: 94  train_loss: 0.33321982622146606\n",
      "epoch: 95  train_loss: 0.3323204815387726\n",
      "epoch: 96  train_loss: 0.30221542716026306\n",
      "epoch: 97  train_loss: 0.32153570652008057\n",
      "epoch: 98  train_loss: 0.3440919518470764\n",
      "epoch: 99  train_loss: 0.32626649737358093\n",
      "epoch: 100  train_loss: 0.303577184677124\n",
      "epoch: 101  train_loss: 0.31502822041511536\n",
      "epoch: 102  train_loss: 0.366787850856781\n",
      "epoch: 103  train_loss: 0.30511388182640076\n",
      "epoch: 104  train_loss: 0.31423741579055786\n",
      "epoch: 105  train_loss: 0.3369084894657135\n",
      "epoch: 106  train_loss: 0.31661713123321533\n",
      "epoch: 107  train_loss: 0.3174034357070923\n",
      "epoch: 108  train_loss: 0.3192569315433502\n",
      "epoch: 109  train_loss: 0.2977636158466339\n",
      "epoch: 110  train_loss: 0.33896252512931824\n",
      "epoch: 111  train_loss: 0.3316808342933655\n",
      "epoch: 112  train_loss: 0.3099649250507355\n",
      "epoch: 113  train_loss: 0.33181944489479065\n",
      "epoch: 114  train_loss: 0.30099040269851685\n",
      "epoch: 115  train_loss: 0.2589523494243622\n",
      "epoch: 116  train_loss: 0.30375656485557556\n",
      "epoch: 117  train_loss: 0.3361283838748932\n",
      "epoch: 118  train_loss: 0.2738451659679413\n",
      "epoch: 119  train_loss: 0.2715553045272827\n",
      "epoch: 120  train_loss: 0.33365362882614136\n",
      "epoch: 121  train_loss: 0.2891347110271454\n",
      "epoch: 122  train_loss: 0.3040200173854828\n",
      "epoch: 123  train_loss: 0.32146602869033813\n",
      "epoch: 124  train_loss: 0.3008434772491455\n",
      "epoch: 125  train_loss: 0.3259739279747009\n",
      "epoch: 126  train_loss: 0.3008059561252594\n",
      "epoch: 127  train_loss: 0.3106037676334381\n",
      "epoch: 128  train_loss: 0.31781065464019775\n",
      "epoch: 129  train_loss: 0.3448743522167206\n",
      "epoch: 130  train_loss: 0.33416256308555603\n",
      "epoch: 131  train_loss: 0.33246374130249023\n",
      "epoch: 132  train_loss: 0.32024940848350525\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training for mapping\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem_rel.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_rel, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1efad3d-dd09-4aef-81dd-3ed3c31ffb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 178.39549255371094\n",
      "epoch: 1  train_loss: 182.28233337402344\n",
      "epoch: 2  train_loss: 178.78712463378906\n",
      "epoch: 3  train_loss: 179.03147888183594\n",
      "epoch: 4  train_loss: 177.77017211914062\n",
      "epoch: 5  train_loss: 182.65928649902344\n",
      "epoch: 6  train_loss: 179.82041931152344\n",
      "epoch: 7  train_loss: 179.13153076171875\n",
      "epoch: 8  train_loss: 181.82296752929688\n",
      "epoch: 9  train_loss: 178.97198486328125\n",
      "epoch: 10  train_loss: 185.7644805908203\n",
      "epoch: 11  train_loss: 177.5663604736328\n",
      "epoch: 12  train_loss: 178.91567993164062\n",
      "epoch: 13  train_loss: 177.6474609375\n",
      "epoch: 14  train_loss: 181.13919067382812\n",
      "epoch: 15  train_loss: 182.2436065673828\n",
      "epoch: 16  train_loss: 177.83518981933594\n",
      "epoch: 17  train_loss: 179.97897338867188\n",
      "epoch: 18  train_loss: 177.72219848632812\n",
      "epoch: 19  train_loss: 184.91534423828125\n",
      "epoch: 20  train_loss: 178.2413330078125\n",
      "epoch: 21  train_loss: 177.55377197265625\n",
      "epoch: 22  train_loss: 182.93743896484375\n",
      "epoch: 23  train_loss: 178.30929565429688\n",
      "epoch: 24  train_loss: 176.19358825683594\n",
      "epoch: 25  train_loss: 177.11178588867188\n",
      "epoch: 26  train_loss: 179.35108947753906\n",
      "epoch: 27  train_loss: 180.23890686035156\n",
      "epoch: 28  train_loss: 180.37889099121094\n",
      "epoch: 29  train_loss: 180.6983642578125\n",
      "epoch: 30  train_loss: 177.09140014648438\n",
      "epoch: 31  train_loss: 180.36085510253906\n",
      "epoch: 32  train_loss: 179.80860900878906\n",
      "epoch: 33  train_loss: 178.39805603027344\n",
      "epoch: 34  train_loss: 175.9570770263672\n",
      "epoch: 35  train_loss: 178.43951416015625\n",
      "epoch: 36  train_loss: 178.4239959716797\n",
      "epoch: 37  train_loss: 179.74835205078125\n",
      "epoch: 38  train_loss: 178.69898986816406\n",
      "epoch: 39  train_loss: 179.2428741455078\n",
      "epoch: 40  train_loss: 182.274658203125\n",
      "epoch: 41  train_loss: 181.28623962402344\n",
      "epoch: 42  train_loss: 180.5068359375\n",
      "epoch: 43  train_loss: 180.9408416748047\n",
      "epoch: 44  train_loss: 177.83262634277344\n",
      "epoch: 45  train_loss: 181.54222106933594\n",
      "epoch: 46  train_loss: 181.3885040283203\n",
      "epoch: 47  train_loss: 176.36351013183594\n",
      "epoch: 48  train_loss: 178.5585174560547\n",
      "epoch: 49  train_loss: 176.0979461669922\n",
      "epoch: 50  train_loss: 183.07354736328125\n",
      "epoch: 51  train_loss: 181.22317504882812\n",
      "epoch: 52  train_loss: 175.72373962402344\n",
      "epoch: 53  train_loss: 178.22357177734375\n",
      "epoch: 54  train_loss: 178.251708984375\n",
      "epoch: 55  train_loss: 182.24151611328125\n",
      "epoch: 56  train_loss: 179.0551300048828\n",
      "epoch: 57  train_loss: 181.06089782714844\n",
      "epoch: 58  train_loss: 182.87547302246094\n",
      "epoch: 59  train_loss: 178.32623291015625\n",
      "epoch: 60  train_loss: 181.14276123046875\n",
      "epoch: 61  train_loss: 180.0746307373047\n",
      "epoch: 62  train_loss: 178.1937713623047\n",
      "epoch: 63  train_loss: 178.20567321777344\n",
      "epoch: 64  train_loss: 182.8358154296875\n",
      "epoch: 65  train_loss: 182.1398162841797\n",
      "epoch: 66  train_loss: 183.21852111816406\n",
      "epoch: 67  train_loss: 179.4971466064453\n",
      "epoch: 68  train_loss: 179.20272827148438\n",
      "epoch: 69  train_loss: 175.24725341796875\n",
      "epoch: 70  train_loss: 183.37033081054688\n",
      "epoch: 71  train_loss: 184.1361541748047\n",
      "epoch: 72  train_loss: 177.9980926513672\n",
      "epoch: 73  train_loss: 179.66244506835938\n",
      "epoch: 74  train_loss: 180.8408203125\n",
      "epoch: 75  train_loss: 178.03286743164062\n",
      "epoch: 76  train_loss: 179.5727081298828\n",
      "epoch: 77  train_loss: 179.97979736328125\n",
      "epoch: 78  train_loss: 180.22821044921875\n",
      "epoch: 79  train_loss: 183.07196044921875\n",
      "epoch: 80  train_loss: 181.23707580566406\n",
      "epoch: 81  train_loss: 181.8931427001953\n",
      "epoch: 82  train_loss: 180.60098266601562\n",
      "epoch: 83  train_loss: 178.9465789794922\n",
      "epoch: 84  train_loss: 181.64242553710938\n",
      "epoch: 85  train_loss: 178.32650756835938\n",
      "epoch: 86  train_loss: 181.39781188964844\n",
      "epoch: 87  train_loss: 179.93467712402344\n",
      "epoch: 88  train_loss: 185.7511444091797\n",
      "epoch: 89  train_loss: 175.5966339111328\n",
      "epoch: 90  train_loss: 183.23275756835938\n",
      "epoch: 91  train_loss: 182.7223663330078\n",
      "epoch: 92  train_loss: 184.8504180908203\n",
      "epoch: 93  train_loss: 181.0487823486328\n",
      "epoch: 94  train_loss: 183.05157470703125\n",
      "epoch: 95  train_loss: 186.1623992919922\n",
      "epoch: 96  train_loss: 184.74851989746094\n",
      "epoch: 97  train_loss: 182.39138793945312\n",
      "epoch: 98  train_loss: 182.0724334716797\n",
      "epoch: 99  train_loss: 178.5674285888672\n",
      "epoch: 100  train_loss: 181.54666137695312\n",
      "epoch: 101  train_loss: 179.57920837402344\n",
      "epoch: 102  train_loss: 181.2154083251953\n",
      "epoch: 103  train_loss: 180.6473846435547\n",
      "epoch: 104  train_loss: 174.96485900878906\n",
      "epoch: 105  train_loss: 181.56869506835938\n",
      "epoch: 106  train_loss: 180.26556396484375\n",
      "epoch: 107  train_loss: 183.98121643066406\n",
      "epoch: 108  train_loss: 181.66026306152344\n",
      "epoch: 109  train_loss: 182.64804077148438\n",
      "epoch: 110  train_loss: 180.03680419921875\n",
      "epoch: 111  train_loss: 178.71018981933594\n",
      "epoch: 112  train_loss: 178.6854248046875\n",
      "epoch: 113  train_loss: 180.39744567871094\n",
      "epoch: 114  train_loss: 185.91807556152344\n",
      "epoch: 115  train_loss: 183.04278564453125\n",
      "epoch: 116  train_loss: 181.2415008544922\n",
      "epoch: 117  train_loss: 182.0614013671875\n",
      "epoch: 118  train_loss: 180.39573669433594\n",
      "epoch: 119  train_loss: 174.8112335205078\n",
      "epoch: 120  train_loss: 180.78407287597656\n",
      "epoch: 121  train_loss: 182.72999572753906\n",
      "epoch: 122  train_loss: 177.7069549560547\n",
      "epoch: 123  train_loss: 182.28640747070312\n",
      "epoch: 124  train_loss: 176.69480895996094\n",
      "epoch: 125  train_loss: 179.0658721923828\n",
      "epoch: 126  train_loss: 181.0869598388672\n",
      "epoch: 127  train_loss: 179.25540161132812\n",
      "epoch: 128  train_loss: 180.57101440429688\n",
      "epoch: 129  train_loss: 179.25607299804688\n",
      "epoch: 130  train_loss: 179.94627380371094\n",
      "epoch: 131  train_loss: 179.80996704101562\n",
      "epoch: 132  train_loss: 180.14566040039062\n",
      "epoch: 133  train_loss: 179.29373168945312\n",
      "epoch: 134  train_loss: 178.5481414794922\n",
      "epoch: 135  train_loss: 182.29188537597656\n",
      "epoch: 136  train_loss: 176.61160278320312\n",
      "epoch: 137  train_loss: 180.31451416015625\n",
      "epoch: 138  train_loss: 180.43663024902344\n",
      "epoch: 139  train_loss: 181.97250366210938\n",
      "epoch: 140  train_loss: 182.6258087158203\n",
      "epoch: 141  train_loss: 180.9948272705078\n",
      "epoch: 142  train_loss: 185.37277221679688\n",
      "epoch: 143  train_loss: 178.0148162841797\n",
      "epoch: 144  train_loss: 175.96414184570312\n",
      "epoch: 145  train_loss: 182.0469512939453\n",
      "epoch: 146  train_loss: 177.7239227294922\n",
      "epoch: 147  train_loss: 176.83804321289062\n",
      "epoch: 148  train_loss: 179.60472106933594\n",
      "epoch: 149  train_loss: 182.22157287597656\n",
      "epoch: 150  train_loss: 176.97312927246094\n",
      "epoch: 151  train_loss: 179.72689819335938\n",
      "epoch: 152  train_loss: 180.49534606933594\n",
      "epoch: 153  train_loss: 179.1493377685547\n",
      "epoch: 154  train_loss: 180.035888671875\n",
      "epoch: 155  train_loss: 180.08934020996094\n",
      "epoch: 156  train_loss: 179.76138305664062\n",
      "epoch: 157  train_loss: 182.0413055419922\n",
      "epoch: 158  train_loss: 180.3291778564453\n",
      "epoch: 159  train_loss: 179.14649963378906\n",
      "epoch: 160  train_loss: 180.9668426513672\n",
      "epoch: 161  train_loss: 178.85525512695312\n",
      "epoch: 162  train_loss: 180.95416259765625\n",
      "epoch: 163  train_loss: 179.15451049804688\n",
      "epoch: 164  train_loss: 178.39871215820312\n",
      "epoch: 165  train_loss: 179.64344787597656\n",
      "epoch: 166  train_loss: 184.1209259033203\n",
      "epoch: 167  train_loss: 184.95425415039062\n",
      "epoch: 168  train_loss: 178.9875946044922\n",
      "epoch: 169  train_loss: 180.36183166503906\n",
      "epoch: 170  train_loss: 179.87144470214844\n",
      "epoch: 171  train_loss: 184.42153930664062\n",
      "epoch: 172  train_loss: 176.11976623535156\n",
      "epoch: 173  train_loss: 179.2396697998047\n",
      "epoch: 174  train_loss: 179.4086456298828\n",
      "epoch: 175  train_loss: 178.79522705078125\n",
      "epoch: 176  train_loss: 180.7353515625\n",
      "epoch: 177  train_loss: 181.90855407714844\n",
      "epoch: 178  train_loss: 178.33047485351562\n",
      "epoch: 179  train_loss: 180.363525390625\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# freeze sol mapping\n",
    "#problem_rel.freeze()\n",
    "# training for rounding\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_rnd, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7858c207-11d3-4cfc-8e7a-13d831ee7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 242.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      6.605211          1.251305      0.003605\n",
      "std       5.420684          1.401519      0.001010\n",
      "min       0.000000          0.000000      0.001999\n",
      "25%       3.908666          0.392297      0.003000\n",
      "50%       4.418969          1.000000      0.003503\n",
      "75%       7.171421          1.430793      0.004000\n",
      "max      30.283837          8.258777      0.008512\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem_rnd(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec11267a-64f0-4ff5-bc2b-4f05787adb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>3.204402</td>\n",
       "      <td>0.749176</td>\n",
       "      <td>0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>2.422065</td>\n",
       "      <td>0.366867</td>\n",
       "      <td>0.005522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.906667</td>\n",
       "      <td>0.004508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>4.781358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>5.179335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0)</td>\n",
       "      <td>4.576891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>5.250714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(1.0, 1.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>1.774578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(1.0, 1.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>2.101038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(2.0, 1.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>4.864646</td>\n",
       "      <td>0.475116</td>\n",
       "      <td>0.002999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol   Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (1.0, 0.0, 0.0, 0.0, 0.0)  3.204402          0.749176      0.006099\n",
       "1    (1.0, 1.0, 0.0, 0.0, 0.0)  2.422065          0.366867      0.005522\n",
       "2    (0.0, 0.0, 0.0, 0.0, 0.0)  4.000000          1.906667      0.004508\n",
       "3    (0.0, 1.0, 0.0, 0.0, 0.0)  4.781358          1.000000      0.005611\n",
       "4    (0.0, 1.0, 0.0, 0.0, 0.0)  5.179335          1.000000      0.006524\n",
       "..                         ...       ...               ...           ...\n",
       "995  (0.0, 0.0, 0.0, 1.0, 0.0)  4.576891          1.000000      0.003509\n",
       "996  (1.0, 0.0, 1.0, 0.0, 1.0)  5.250714          0.000000      0.004222\n",
       "997  (1.0, 1.0, 1.0, 0.0, 0.0)  1.774578          0.000000      0.003005\n",
       "998  (1.0, 1.0, 1.0, 0.0, 0.0)  2.101038          0.000000      0.002506\n",
       "999  (2.0, 1.0, 1.0, 0.0, 0.0)  4.864646          0.475116      0.002999\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f140ecf-274f-4dcb-b26e-e76c46ca53e7",
   "metadata": {},
   "source": [
    "### Learning to Feasibility Pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddfd3db5-b61c-46dc-92ae-138ce002fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "# define neural architecture for the solution mapping\n",
    "sol_func = nm.modules.blocks.MLP(insize=num_vars, outsize=num_vars, bias=True,\n",
    "                                 linear_map=nm.slim.maps[\"linear\"], nonlin=nn.ReLU,\n",
    "                                 hsizes=[80]*4)\n",
    "# define neural architecture for rounding\n",
    "rnd_layer = netFC(input_dim=num_vars*2, hidden_dims=[80]*4, output_dim=num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9397410-cf75-46de-83b9-d975605b2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get nm optimization model\n",
    "from problem.neural import probRosenbrock\n",
    "def getProb(x, p, a):\n",
    "    return probRosenbrock(x, p, a, num_vars=num_vars, alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2903e087-27af-4738-b1f5-3c30d717ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import feasibilityPumpModel\n",
    "# feasibility pump model\n",
    "problem_rel, problem_fp = feasibilityPumpModel([\"p\", \"a\"], getProb, sol_func, rnd_layer, int_ind=model.int_ind, num_iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57c24ef8-218a-40f0-a448-f0b38851c3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 26.019447326660156\n",
      "epoch: 1  train_loss: 0.5018856525421143\n",
      "epoch: 2  train_loss: 0.4640052020549774\n",
      "epoch: 3  train_loss: 0.4077915847301483\n",
      "epoch: 4  train_loss: 0.39302703738212585\n",
      "epoch: 5  train_loss: 0.4387400150299072\n",
      "epoch: 6  train_loss: 0.4374125897884369\n",
      "epoch: 7  train_loss: 0.4021318256855011\n",
      "epoch: 8  train_loss: 0.4044865667819977\n",
      "epoch: 9  train_loss: 0.4192991852760315\n",
      "epoch: 10  train_loss: 0.34392988681793213\n",
      "epoch: 11  train_loss: 0.3829454481601715\n",
      "epoch: 12  train_loss: 0.3520008325576782\n",
      "epoch: 13  train_loss: 0.39323192834854126\n",
      "epoch: 14  train_loss: 0.37630024552345276\n",
      "epoch: 15  train_loss: 0.3270723223686218\n",
      "epoch: 16  train_loss: 0.4301745295524597\n",
      "epoch: 17  train_loss: 0.38404619693756104\n",
      "epoch: 18  train_loss: 0.3138093650341034\n",
      "epoch: 19  train_loss: 0.37943416833877563\n",
      "epoch: 20  train_loss: 0.28371384739875793\n",
      "epoch: 21  train_loss: 0.4230571985244751\n",
      "epoch: 22  train_loss: 0.3997431695461273\n",
      "epoch: 23  train_loss: 0.33807075023651123\n",
      "epoch: 24  train_loss: 0.39398181438446045\n",
      "epoch: 25  train_loss: 0.4050731360912323\n",
      "epoch: 26  train_loss: 0.39490702748298645\n",
      "epoch: 27  train_loss: 0.412779301404953\n",
      "epoch: 28  train_loss: 0.36278486251831055\n",
      "epoch: 29  train_loss: 0.3393099308013916\n",
      "epoch: 30  train_loss: 0.3675067126750946\n",
      "epoch: 31  train_loss: 0.29364117980003357\n",
      "epoch: 32  train_loss: 0.3853625953197479\n",
      "epoch: 33  train_loss: 0.35626107454299927\n",
      "epoch: 34  train_loss: 0.3660012483596802\n",
      "epoch: 35  train_loss: 0.33946171402931213\n",
      "epoch: 36  train_loss: 0.340879887342453\n",
      "epoch: 37  train_loss: 0.33075883984565735\n",
      "epoch: 38  train_loss: 0.3598509728908539\n",
      "epoch: 39  train_loss: 0.412724107503891\n",
      "epoch: 40  train_loss: 0.44742804765701294\n",
      "epoch: 41  train_loss: 0.375454843044281\n",
      "epoch: 42  train_loss: 0.3561696410179138\n",
      "epoch: 43  train_loss: 0.3665282130241394\n",
      "epoch: 44  train_loss: 0.41846758127212524\n",
      "epoch: 45  train_loss: 0.3829232454299927\n",
      "epoch: 46  train_loss: 0.32237109541893005\n",
      "epoch: 47  train_loss: 0.3735573887825012\n",
      "epoch: 48  train_loss: 0.2824662923812866\n",
      "epoch: 49  train_loss: 0.35974612832069397\n",
      "epoch: 50  train_loss: 0.3214470148086548\n",
      "epoch: 51  train_loss: 0.3616863489151001\n",
      "epoch: 52  train_loss: 0.34525904059410095\n",
      "epoch: 53  train_loss: 0.358346164226532\n",
      "epoch: 54  train_loss: 0.29048025608062744\n",
      "epoch: 55  train_loss: 0.2817864418029785\n",
      "epoch: 56  train_loss: 0.3354315161705017\n",
      "epoch: 57  train_loss: 0.27982690930366516\n",
      "epoch: 58  train_loss: 0.3295215368270874\n",
      "epoch: 59  train_loss: 0.33052948117256165\n",
      "epoch: 60  train_loss: 0.33346128463745117\n",
      "epoch: 61  train_loss: 0.35531458258628845\n",
      "epoch: 62  train_loss: 0.3009920120239258\n",
      "epoch: 63  train_loss: 0.3219674229621887\n",
      "epoch: 64  train_loss: 0.3547814190387726\n",
      "epoch: 65  train_loss: 0.3497820198535919\n",
      "epoch: 66  train_loss: 0.31063058972358704\n",
      "epoch: 67  train_loss: 0.34756460785865784\n",
      "epoch: 68  train_loss: 0.3310644328594208\n",
      "epoch: 69  train_loss: 0.3236043155193329\n",
      "epoch: 70  train_loss: 0.31342288851737976\n",
      "epoch: 71  train_loss: 0.3136959671974182\n",
      "epoch: 72  train_loss: 0.29280367493629456\n",
      "epoch: 73  train_loss: 0.2875623106956482\n",
      "epoch: 74  train_loss: 0.33229076862335205\n",
      "epoch: 75  train_loss: 0.32389384508132935\n",
      "epoch: 76  train_loss: 0.326935738325119\n",
      "epoch: 77  train_loss: 0.29399240016937256\n",
      "epoch: 78  train_loss: 0.27901965379714966\n",
      "epoch: 79  train_loss: 0.37749728560447693\n",
      "epoch: 80  train_loss: 0.30310431122779846\n",
      "epoch: 81  train_loss: 0.3446357548236847\n",
      "epoch: 82  train_loss: 0.34197041392326355\n",
      "epoch: 83  train_loss: 0.311891108751297\n",
      "epoch: 84  train_loss: 0.26817646622657776\n",
      "epoch: 85  train_loss: 0.3273451328277588\n",
      "epoch: 86  train_loss: 0.30681028962135315\n",
      "epoch: 87  train_loss: 0.31421059370040894\n",
      "epoch: 88  train_loss: 0.35207700729370117\n",
      "epoch: 89  train_loss: 0.25760266184806824\n",
      "epoch: 90  train_loss: 0.30428215861320496\n",
      "epoch: 91  train_loss: 0.3178844153881073\n",
      "epoch: 92  train_loss: 0.3304659128189087\n",
      "epoch: 93  train_loss: 0.3262649476528168\n",
      "epoch: 94  train_loss: 0.3123122751712799\n",
      "epoch: 95  train_loss: 0.32440075278282166\n",
      "epoch: 96  train_loss: 0.30522921681404114\n",
      "epoch: 97  train_loss: 0.33949077129364014\n",
      "epoch: 98  train_loss: 0.26557791233062744\n",
      "epoch: 99  train_loss: 0.32838311791419983\n",
      "epoch: 100  train_loss: 0.294767826795578\n",
      "epoch: 101  train_loss: 0.27722829580307007\n",
      "epoch: 102  train_loss: 0.30535510182380676\n",
      "epoch: 103  train_loss: 0.3034326732158661\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training for mapping\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem_rel.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_rel, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917856c4-f7db-4537-a59c-1499d0d27557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 1193.126953125\n",
      "epoch: 1  train_loss: 1210.1878662109375\n",
      "epoch: 2  train_loss: 1209.5623779296875\n",
      "epoch: 3  train_loss: 1194.9654541015625\n",
      "epoch: 4  train_loss: 1191.7130126953125\n",
      "epoch: 5  train_loss: 1195.9344482421875\n",
      "epoch: 6  train_loss: 1218.43603515625\n",
      "epoch: 7  train_loss: 1193.140380859375\n",
      "epoch: 8  train_loss: 1179.0643310546875\n",
      "epoch: 9  train_loss: 1194.7115478515625\n",
      "epoch: 10  train_loss: 1218.4249267578125\n",
      "epoch: 11  train_loss: 1198.94384765625\n",
      "epoch: 12  train_loss: 1207.5086669921875\n",
      "epoch: 13  train_loss: 1213.5775146484375\n",
      "epoch: 14  train_loss: 1213.363525390625\n",
      "epoch: 15  train_loss: 1214.5821533203125\n",
      "epoch: 16  train_loss: 1206.951171875\n",
      "epoch: 17  train_loss: 1204.026611328125\n",
      "epoch: 18  train_loss: 1192.2855224609375\n",
      "epoch: 19  train_loss: 1186.3773193359375\n",
      "epoch: 20  train_loss: 1199.818115234375\n",
      "epoch: 21  train_loss: 1199.17138671875\n",
      "epoch: 22  train_loss: 1203.8134765625\n",
      "epoch: 23  train_loss: 1206.350341796875\n",
      "epoch: 24  train_loss: 1200.0198974609375\n",
      "epoch: 25  train_loss: 1217.951904296875\n",
      "epoch: 26  train_loss: 1216.158203125\n",
      "epoch: 27  train_loss: 1207.4764404296875\n",
      "epoch: 28  train_loss: 1189.73583984375\n",
      "epoch: 29  train_loss: 1219.9769287109375\n",
      "epoch: 30  train_loss: 1191.5906982421875\n",
      "epoch: 31  train_loss: 1205.644775390625\n",
      "epoch: 32  train_loss: 1206.91259765625\n",
      "epoch: 33  train_loss: 1201.0126953125\n",
      "epoch: 34  train_loss: 1196.9981689453125\n",
      "epoch: 35  train_loss: 1192.5472412109375\n",
      "epoch: 36  train_loss: 1210.4991455078125\n",
      "epoch: 37  train_loss: 1218.2578125\n",
      "epoch: 38  train_loss: 1191.762939453125\n",
      "epoch: 39  train_loss: 1213.12646484375\n",
      "epoch: 40  train_loss: 1206.67333984375\n",
      "epoch: 41  train_loss: 1206.3797607421875\n",
      "epoch: 42  train_loss: 1180.27783203125\n",
      "epoch: 43  train_loss: 1212.670654296875\n",
      "epoch: 44  train_loss: 1185.7021484375\n",
      "epoch: 45  train_loss: 1197.76318359375\n",
      "epoch: 46  train_loss: 1206.98046875\n",
      "epoch: 47  train_loss: 1222.3060302734375\n",
      "epoch: 48  train_loss: 1201.4112548828125\n",
      "epoch: 49  train_loss: 1206.9327392578125\n",
      "epoch: 50  train_loss: 1198.27880859375\n",
      "epoch: 51  train_loss: 1196.0628662109375\n",
      "epoch: 52  train_loss: 1193.732666015625\n",
      "epoch: 53  train_loss: 1203.4141845703125\n",
      "epoch: 54  train_loss: 1208.7197265625\n",
      "epoch: 55  train_loss: 1184.61181640625\n",
      "epoch: 56  train_loss: 1205.9302978515625\n",
      "epoch: 57  train_loss: 1204.9573974609375\n",
      "epoch: 58  train_loss: 1206.1607666015625\n",
      "epoch: 59  train_loss: 1203.301513671875\n",
      "epoch: 60  train_loss: 1202.1407470703125\n",
      "epoch: 61  train_loss: 1204.2227783203125\n",
      "epoch: 62  train_loss: 1206.369140625\n",
      "epoch: 63  train_loss: 1216.552978515625\n",
      "epoch: 64  train_loss: 1208.0621337890625\n",
      "epoch: 65  train_loss: 1213.646240234375\n",
      "epoch: 66  train_loss: 1191.59521484375\n",
      "epoch: 67  train_loss: 1201.388916015625\n",
      "epoch: 68  train_loss: 1203.5235595703125\n",
      "epoch: 69  train_loss: 1198.136474609375\n",
      "epoch: 70  train_loss: 1203.459716796875\n",
      "epoch: 71  train_loss: 1198.2501220703125\n",
      "epoch: 72  train_loss: 1210.6280517578125\n",
      "epoch: 73  train_loss: 1199.231689453125\n",
      "epoch: 74  train_loss: 1216.370361328125\n",
      "epoch: 75  train_loss: 1208.923583984375\n",
      "epoch: 76  train_loss: 1204.2071533203125\n",
      "epoch: 77  train_loss: 1214.2181396484375\n",
      "epoch: 78  train_loss: 1193.16162109375\n",
      "epoch: 79  train_loss: 1190.842529296875\n",
      "epoch: 80  train_loss: 1221.664306640625\n",
      "epoch: 81  train_loss: 1216.3779296875\n",
      "epoch: 82  train_loss: 1195.477294921875\n",
      "epoch: 83  train_loss: 1203.5946044921875\n",
      "epoch: 84  train_loss: 1217.9482421875\n",
      "epoch: 85  train_loss: 1200.517333984375\n",
      "epoch: 86  train_loss: 1205.1656494140625\n",
      "epoch: 87  train_loss: 1193.798095703125\n",
      "epoch: 88  train_loss: 1182.690673828125\n",
      "epoch: 89  train_loss: 1202.9208984375\n",
      "epoch: 90  train_loss: 1194.2666015625\n",
      "epoch: 91  train_loss: 1198.8824462890625\n",
      "epoch: 92  train_loss: 1195.145263671875\n",
      "epoch: 93  train_loss: 1198.5125732421875\n",
      "epoch: 94  train_loss: 1197.266845703125\n",
      "epoch: 95  train_loss: 1212.11669921875\n",
      "epoch: 96  train_loss: 1213.3084716796875\n",
      "epoch: 97  train_loss: 1199.14599609375\n",
      "epoch: 98  train_loss: 1195.6268310546875\n",
      "epoch: 99  train_loss: 1195.5762939453125\n",
      "epoch: 100  train_loss: 1215.7742919921875\n",
      "epoch: 101  train_loss: 1190.3642578125\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# freeze sol mapping\n",
    "#problem_rel.freeze()\n",
    "# training for feasibility pump\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_fp, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb8b7b8b-96db-47cc-8140-91f75aa2f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:03<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      6.132644          2.709945      0.121376\n",
      "std      10.793020          2.556880      0.016714\n",
      "min       0.000000          0.000000      0.084781\n",
      "25%       1.509867          0.836753      0.106657\n",
      "50%       2.872057          1.832545      0.122832\n",
      "75%       6.214915          3.740688      0.134662\n",
      "max      86.704107         14.056717      0.199103\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem_fp(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "533d3c45-c238-46f4-89b6-382453f372bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 1.0, 0.0, 1.0, 1.0)</td>\n",
       "      <td>1.872594</td>\n",
       "      <td>0.501649</td>\n",
       "      <td>0.150280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 1.0, 1.0, 1.0, 3.0)</td>\n",
       "      <td>1.044551</td>\n",
       "      <td>8.266266</td>\n",
       "      <td>0.129654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 1.0, 1.0, 1.0, 1.0)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.186666</td>\n",
       "      <td>0.134938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>2.152665</td>\n",
       "      <td>2.583487</td>\n",
       "      <td>0.150752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 1.0, 0.0, 1.0, 1.0)</td>\n",
       "      <td>3.185387</td>\n",
       "      <td>2.072099</td>\n",
       "      <td>0.119994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(0.0, 0.0, 1.0, 1.0, 0.0)</td>\n",
       "      <td>3.194718</td>\n",
       "      <td>0.962043</td>\n",
       "      <td>0.152930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(2.0, 0.0, 0.0, 2.0, 1.0)</td>\n",
       "      <td>24.044279</td>\n",
       "      <td>5.136647</td>\n",
       "      <td>0.133409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(1.0, 2.0, 2.0, 0.0, 2.0)</td>\n",
       "      <td>24.262394</td>\n",
       "      <td>8.414065</td>\n",
       "      <td>0.131910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(1.0, 1.0, 1.0, 1.0, 1.0)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274599</td>\n",
       "      <td>0.136082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(2.0, 1.0, 0.0, 1.0, 1.0)</td>\n",
       "      <td>5.368344</td>\n",
       "      <td>1.475116</td>\n",
       "      <td>0.140969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol    Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (1.0, 1.0, 0.0, 1.0, 1.0)   1.872594          0.501649      0.150280\n",
       "1    (1.0, 1.0, 1.0, 1.0, 3.0)   1.044551          8.266266      0.129654\n",
       "2    (1.0, 1.0, 1.0, 1.0, 1.0)   0.000000          1.186666      0.134938\n",
       "3    (1.0, 1.0, 1.0, 0.0, 1.0)   2.152665          2.583487      0.150752\n",
       "4    (1.0, 1.0, 0.0, 1.0, 1.0)   3.185387          2.072099      0.119994\n",
       "..                         ...        ...               ...           ...\n",
       "995  (0.0, 0.0, 1.0, 1.0, 0.0)   3.194718          0.962043      0.152930\n",
       "996  (2.0, 0.0, 0.0, 2.0, 1.0)  24.044279          5.136647      0.133409\n",
       "997  (1.0, 2.0, 2.0, 0.0, 2.0)  24.262394          8.414065      0.131910\n",
       "998  (1.0, 1.0, 1.0, 1.0, 1.0)   0.000000          0.274599      0.136082\n",
       "999  (2.0, 1.0, 0.0, 1.0, 1.0)   5.368344          1.475116      0.140969\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d761fd9-ab80-4f5a-80ec-cfafb9539b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
