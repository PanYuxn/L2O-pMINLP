{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ff36a69310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "num_data = 5000   # number of data\n",
    "num_vars = 5      # number of decision variables\n",
    "num_ints = 5      # number of integer decision variables\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_train = np.random.uniform(2.0, 6.0, (train_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(6.0, 15.0, (train_size, num_vars)).astype(np.float32)\n",
    "p_test = np.random.uniform(6.0, 15.0, (test_size, 1)).astype(np.float32)\n",
    "a_test = np.random.uniform(0.2, 1.2, (test_size, num_vars)).astype(np.float32)\n",
    "p_dev = np.random.uniform(6.0, 15.0, (val_size, 1)).astype(np.float32)\n",
    "a_dev = np.random.uniform(0.2, 1.2, (val_size, num_vars)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7678b7-f3c9-4066-816b-a13131bcd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91eaf9b-55bd-417f-a544-84fde74c6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "loader_train = DataLoader(data_train, batch_size=32, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size=32, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size=32, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f16db-28e1-4c9e-bdd3-b747f670c04d",
   "metadata": {},
   "source": [
    "## NM Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c1c5a4-038b-4776-8a44-8ebb5a351e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuromancer as nm\n",
    "from problem.neural import probRastrigin\n",
    "\n",
    "def getNMProb(round_module):\n",
    "    # parameters\n",
    "    p = nm.constraint.variable(\"p\")\n",
    "    a = nm.constraint.variable(\"a\")\n",
    "    # variables\n",
    "    x_bar = nm.constraint.variable(\"x_bar\")\n",
    "    x_rnd = nm.constraint.variable(\"x_rnd\")\n",
    "\n",
    "    # model\n",
    "    obj_bar, constrs_bar = probRastrigin(x_bar, p, a, num_vars=num_vars, alpha=100)\n",
    "    obj_rnd, constrs_rnd = probRastrigin(x_rnd, p, a, num_vars=num_vars, alpha=100)\n",
    "\n",
    "    # define neural architecture for the solution mapping\n",
    "    func = nm.modules.blocks.MLP(insize=num_vars+1, outsize=num_vars, bias=True,\n",
    "                                 linear_map=nm.slim.maps[\"linear\"], nonlin=nn.ReLU, hsizes=[80]*4)\n",
    "    # solution map from model parameters: sol_map(p) -> x\n",
    "    sol_map = nm.system.Node(func, [\"p\", \"a\"], [\"x_bar\"], name=\"smap\")\n",
    "\n",
    "    # penalty loss for mapping\n",
    "    components = [sol_map]\n",
    "    loss = nm.loss.PenaltyLoss(obj_bar, constrs_bar)\n",
    "    problem = nm.problem.Problem(components, loss)\n",
    "\n",
    "    # penalty loss for rounding\n",
    "    components = [sol_map, round_module]\n",
    "    loss = nm.loss.PenaltyLoss(obj_rnd, constrs_rnd)\n",
    "    problem_rnd = nm.problem.Problem(components, loss)\n",
    "\n",
    "    return problem, problem_rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b99751-3a6e-46dc-9e33-fdf68d813034",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e7f07c-6a97-44d6-aca7-56f395e0c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.solver import exactRastrigin\n",
    "model = exactRastrigin(n_vars=num_vars, n_integers=num_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e326fa-de2f-415e-a4d4-1f28eef6511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:49<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000            1000.0   1000.000000\n",
      "mean      5.878000               0.0      0.108774\n",
      "std       1.317897               0.0      0.041968\n",
      "min       4.000000               0.0      0.072309\n",
      "25%       5.000000               0.0      0.089265\n",
      "50%       6.000000               0.0      0.091145\n",
      "75%       7.000000               0.0      0.106765\n",
      "max       8.000000               0.0      0.281110\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    model.setParamValue(p, *a)\n",
    "    tick = time.time()\n",
    "    xval, objval = model.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    sols.append(list(xval.values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30ef9e5-41b5-4b4b-87b3-6c628fa51430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2.0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 2.0]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 2.0]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2.0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2.0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2.0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 2.0]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol  Obj Val  Constraints Viol  Elapsed Time\n",
       "0    [2.0, 0.0, 1.0, 0.0, 1.0]      6.0               0.0      0.281110\n",
       "1    [0.0, 0.0, 1.0, 0.0, 2.0]      5.0               0.0      0.092675\n",
       "2    [2.0, 0.0, 1.0, 0.0, 1.0]      6.0               0.0      0.106111\n",
       "3    [0.0, 1.0, 1.0, 1.0, 2.0]      7.0               0.0      0.090138\n",
       "4    [0.0, 1.0, 1.0, 1.0, 2.0]      7.0               0.0      0.139288\n",
       "..                         ...      ...               ...           ...\n",
       "995  [1.0, 1.0, 0.0, 1.0, 1.0]      4.0               0.0      0.073948\n",
       "996  [0.0, 0.0, 1.0, 0.0, 2.0]      5.0               0.0      0.105913\n",
       "997  [0.0, 0.0, 1.0, 0.0, 2.0]      5.0               0.0      0.091118\n",
       "998  [0.0, 0.0, 1.0, 0.0, 2.0]      5.0               0.0      0.091660\n",
       "999  [0.0, 1.0, 1.0, 1.0, 2.0]      7.0               0.0      0.075424\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e1f73-eaa5-40d9-97fb-3b70009df41b",
   "metadata": {},
   "source": [
    "## Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987f3b11-c41c-4012-b2ef-935f62099616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristic import naive_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161556c9-67af-4686-bfec-d0fdea488bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relaxed model\n",
    "model_rel = model.relax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a6d751-9afa-4b4c-abbb-1b2c9ba6ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [33:34<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      5.378000          0.112628      2.013448\n",
      "std       1.292589          0.148134     19.919316\n",
      "min       3.000000          0.000000      0.366162\n",
      "25%       4.000000          0.000000      1.116277\n",
      "50%       5.000000          0.000143      1.329107\n",
      "75%       6.000000          0.227773      1.542366\n",
      "max       8.000000          0.510274    631.120111\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    model.setParamValue(p, *a)\n",
    "    model_rel.setParamValue(p, *a)\n",
    "    tick = time.time()\n",
    "    xval_init, _ = model_rel.solve(\"scip\", max_iter=100)\n",
    "    naive_round(xval_init, model)\n",
    "    tock = time.time()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(list(xval.values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15aa2e03-74e5-496b-833b-0233fea6f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, -1, 2, 1, 0]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.317917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1, 0, 0, 0, 2]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.204374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, -1, -1, 1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.123591</td>\n",
       "      <td>1.323012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1, -2, 0, 0, 1]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.225262</td>\n",
       "      <td>1.100195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 1, -1, 0, 1]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[0, -1, -1, -1, 0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.269571</td>\n",
       "      <td>0.890250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[1, 0, -1, 1, 1]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.887723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[2, 0, 0, 0, 0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.167210</td>\n",
       "      <td>0.991105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[0, 0, 2, 0, -1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[0, 1, 1, -2, 1]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.101464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sol  Obj Val  Constraints Viol  Elapsed Time\n",
       "0      [0, -1, 2, 1, 0]      6.0          0.000000      1.317917\n",
       "1      [-1, 0, 0, 0, 2]      5.0          0.000000      1.204374\n",
       "2     [1, -1, -1, 1, 1]      5.0          0.123591      1.323012\n",
       "3     [-1, -2, 0, 0, 1]      6.0          0.225262      1.100195\n",
       "4      [2, 1, -1, 0, 1]      7.0          0.000000      0.898111\n",
       "..                  ...      ...               ...           ...\n",
       "995  [0, -1, -1, -1, 0]      3.0          0.269571      0.890250\n",
       "996    [1, 0, -1, 1, 1]      4.0          0.023561      0.887723\n",
       "997     [2, 0, 0, 0, 0]      4.0          0.167210      0.991105\n",
       "998    [0, 0, 2, 0, -1]      5.0          0.000000      0.994902\n",
       "999    [0, 1, 1, -2, 1]      7.0          0.000000      1.101464\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d961673a-7420-4260-838a-1ef2fb765ceb",
   "metadata": {},
   "source": [
    "## Learning to Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec0072d-675a-4430-ac06-07936115a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.round import roundModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2+1, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                        int_ind={\"x_bar\":model.int_ind}, name=\"round\")\n",
    "_, problem = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea14d3a4-62f7-409b-874e-c9c58e0322a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 40.742042541503906\n",
      "epoch: 1  train_loss: 36.44521713256836\n",
      "epoch: 2  train_loss: 43.06996154785156\n",
      "epoch: 3  train_loss: 47.03972244262695\n",
      "epoch: 4  train_loss: 45.753028869628906\n",
      "epoch: 5  train_loss: 46.43376922607422\n",
      "epoch: 6  train_loss: 48.07091522216797\n",
      "epoch: 7  train_loss: 45.602291107177734\n",
      "epoch: 8  train_loss: 43.758934020996094\n",
      "epoch: 9  train_loss: 46.51628112792969\n",
      "epoch: 10  train_loss: 37.776885986328125\n",
      "epoch: 11  train_loss: 44.985107421875\n",
      "epoch: 12  train_loss: 50.42340087890625\n",
      "epoch: 13  train_loss: 42.19470977783203\n",
      "epoch: 14  train_loss: 45.432186126708984\n",
      "epoch: 15  train_loss: 31.21142578125\n",
      "epoch: 16  train_loss: 40.188018798828125\n",
      "epoch: 17  train_loss: 30.037540435791016\n",
      "epoch: 18  train_loss: 28.244909286499023\n",
      "epoch: 19  train_loss: 33.26726531982422\n",
      "epoch: 20  train_loss: 36.31312942504883\n",
      "epoch: 21  train_loss: 45.448524475097656\n",
      "epoch: 22  train_loss: 50.75492477416992\n",
      "epoch: 23  train_loss: 46.395694732666016\n",
      "epoch: 24  train_loss: 43.781192779541016\n",
      "epoch: 25  train_loss: 40.429412841796875\n",
      "epoch: 26  train_loss: 25.347309112548828\n",
      "epoch: 27  train_loss: 19.70463752746582\n",
      "epoch: 28  train_loss: 29.72032356262207\n",
      "epoch: 29  train_loss: 23.592031478881836\n",
      "epoch: 30  train_loss: 29.448572158813477\n",
      "epoch: 31  train_loss: 29.656251907348633\n",
      "epoch: 32  train_loss: 27.477523803710938\n",
      "epoch: 33  train_loss: 28.923686981201172\n",
      "epoch: 34  train_loss: 35.82080078125\n",
      "epoch: 35  train_loss: 39.760009765625\n",
      "epoch: 36  train_loss: 35.01023483276367\n",
      "epoch: 37  train_loss: 42.6596565246582\n",
      "epoch: 38  train_loss: 41.76621627807617\n",
      "epoch: 39  train_loss: 31.51276206970215\n",
      "epoch: 40  train_loss: 30.446617126464844\n",
      "epoch: 41  train_loss: 32.7133903503418\n",
      "epoch: 42  train_loss: 38.3098258972168\n",
      "epoch: 43  train_loss: 39.828895568847656\n",
      "epoch: 44  train_loss: 39.06337356567383\n",
      "epoch: 45  train_loss: 36.08845901489258\n",
      "epoch: 46  train_loss: 35.15380096435547\n",
      "epoch: 47  train_loss: 42.81896209716797\n",
      "epoch: 48  train_loss: 39.20484924316406\n",
      "epoch: 49  train_loss: 38.24587631225586\n",
      "epoch: 50  train_loss: 43.61194610595703\n",
      "epoch: 51  train_loss: 27.339311599731445\n",
      "epoch: 52  train_loss: 24.196496963500977\n",
      "epoch: 53  train_loss: 33.07080078125\n",
      "epoch: 54  train_loss: 27.47193717956543\n",
      "epoch: 55  train_loss: 26.977266311645508\n",
      "epoch: 56  train_loss: 39.80046844482422\n",
      "epoch: 57  train_loss: 43.87825012207031\n",
      "epoch: 58  train_loss: 53.25956726074219\n",
      "epoch: 59  train_loss: 60.75646209716797\n",
      "epoch: 60  train_loss: 59.848960876464844\n",
      "epoch: 61  train_loss: 52.13024139404297\n",
      "epoch: 62  train_loss: 50.52277374267578\n",
      "epoch: 63  train_loss: 48.51079559326172\n",
      "epoch: 64  train_loss: 52.715980529785156\n",
      "epoch: 65  train_loss: 74.72431182861328\n",
      "epoch: 66  train_loss: 42.96529769897461\n",
      "epoch: 67  train_loss: 54.501609802246094\n",
      "epoch: 68  train_loss: 43.513057708740234\n",
      "epoch: 69  train_loss: 42.380027770996094\n",
      "epoch: 70  train_loss: 46.153045654296875\n",
      "epoch: 71  train_loss: 38.029239654541016\n",
      "epoch: 72  train_loss: 57.98569107055664\n",
      "epoch: 73  train_loss: 45.659767150878906\n",
      "epoch: 74  train_loss: 49.56486892700195\n",
      "epoch: 75  train_loss: 42.17096710205078\n",
      "epoch: 76  train_loss: 45.43109893798828\n",
      "epoch: 77  train_loss: 46.53057098388672\n",
      "epoch: 78  train_loss: 42.32208251953125\n",
      "epoch: 79  train_loss: 52.36830520629883\n",
      "epoch: 80  train_loss: 60.29974365234375\n",
      "epoch: 81  train_loss: 53.7754020690918\n",
      "epoch: 82  train_loss: 58.61750793457031\n",
      "epoch: 83  train_loss: 68.40634155273438\n",
      "epoch: 84  train_loss: 47.38021469116211\n",
      "epoch: 85  train_loss: 50.16584396362305\n",
      "epoch: 86  train_loss: 77.36483764648438\n",
      "epoch: 87  train_loss: 68.92623901367188\n",
      "epoch: 88  train_loss: 58.210792541503906\n",
      "epoch: 89  train_loss: 78.48405456542969\n",
      "epoch: 90  train_loss: 49.33632278442383\n",
      "epoch: 91  train_loss: 57.27627182006836\n",
      "epoch: 92  train_loss: 56.93013000488281\n",
      "epoch: 93  train_loss: 54.802207946777344\n",
      "epoch: 94  train_loss: 47.69688034057617\n",
      "epoch: 95  train_loss: 46.33489227294922\n",
      "epoch: 96  train_loss: 40.17972946166992\n",
      "epoch: 97  train_loss: 43.30656814575195\n",
      "epoch: 98  train_loss: 40.40180206298828\n",
      "epoch: 99  train_loss: 59.87173843383789\n",
      "epoch: 100  train_loss: 55.57085418701172\n",
      "epoch: 101  train_loss: 91.20502471923828\n",
      "epoch: 102  train_loss: 79.45887756347656\n",
      "epoch: 103  train_loss: 68.7251205444336\n",
      "epoch: 104  train_loss: 64.2392349243164\n",
      "epoch: 105  train_loss: 57.712528228759766\n",
      "epoch: 106  train_loss: 60.41659164428711\n",
      "epoch: 107  train_loss: 58.76864242553711\n",
      "epoch: 108  train_loss: 58.58220291137695\n",
      "epoch: 109  train_loss: 44.59710693359375\n",
      "epoch: 110  train_loss: 47.34701919555664\n",
      "epoch: 111  train_loss: 41.191978454589844\n",
      "epoch: 112  train_loss: 67.61803436279297\n",
      "epoch: 113  train_loss: 65.0436019897461\n",
      "epoch: 114  train_loss: 49.0496711730957\n",
      "epoch: 115  train_loss: 58.508094787597656\n",
      "epoch: 116  train_loss: 53.86973190307617\n",
      "epoch: 117  train_loss: 53.36726379394531\n",
      "epoch: 118  train_loss: 59.77239990234375\n",
      "epoch: 119  train_loss: 57.755184173583984\n",
      "epoch: 120  train_loss: 55.5144157409668\n",
      "epoch: 121  train_loss: 62.494834899902344\n",
      "epoch: 122  train_loss: 57.9133415222168\n",
      "epoch: 123  train_loss: 65.03565979003906\n",
      "epoch: 124  train_loss: 46.229164123535156\n",
      "epoch: 125  train_loss: 54.173500061035156\n",
      "epoch: 126  train_loss: 52.9547233581543\n",
      "epoch: 127  train_loss: 63.57810974121094\n",
      "epoch: 128  train_loss: 53.462528228759766\n",
      "epoch: 129  train_loss: 46.90422439575195\n",
      "epoch: 130  train_loss: 46.6622428894043\n",
      "epoch: 131  train_loss: 40.1943244934082\n",
      "epoch: 132  train_loss: 48.00294876098633\n",
      "epoch: 133  train_loss: 46.34658432006836\n",
      "epoch: 134  train_loss: 45.86751937866211\n",
      "epoch: 135  train_loss: 66.2755126953125\n",
      "epoch: 136  train_loss: 57.72587585449219\n",
      "epoch: 137  train_loss: 51.24870300292969\n",
      "epoch: 138  train_loss: 49.280723571777344\n",
      "epoch: 139  train_loss: 40.09543991088867\n",
      "epoch: 140  train_loss: 45.04899978637695\n",
      "epoch: 141  train_loss: 47.81290054321289\n",
      "epoch: 142  train_loss: 49.5695915222168\n",
      "epoch: 143  train_loss: 40.59939193725586\n",
      "epoch: 144  train_loss: 40.823814392089844\n",
      "epoch: 145  train_loss: 66.44467163085938\n",
      "epoch: 146  train_loss: 57.85636901855469\n",
      "epoch: 147  train_loss: 46.335044860839844\n",
      "epoch: 148  train_loss: 43.196983337402344\n",
      "epoch: 149  train_loss: 50.02996826171875\n",
      "epoch: 150  train_loss: 56.61936950683594\n",
      "epoch: 151  train_loss: 57.55472946166992\n",
      "epoch: 152  train_loss: 54.39535140991211\n",
      "epoch: 153  train_loss: 37.85613250732422\n",
      "epoch: 154  train_loss: 33.238014221191406\n",
      "epoch: 155  train_loss: 34.86098098754883\n",
      "epoch: 156  train_loss: 31.886295318603516\n",
      "epoch: 157  train_loss: 37.83647155761719\n",
      "epoch: 158  train_loss: 36.85240936279297\n",
      "epoch: 159  train_loss: 41.94315719604492\n",
      "epoch: 160  train_loss: 51.57167434692383\n",
      "epoch: 161  train_loss: 32.412845611572266\n",
      "epoch: 162  train_loss: 20.988765716552734\n",
      "epoch: 163  train_loss: 20.63875961303711\n",
      "epoch: 164  train_loss: 26.496763229370117\n",
      "epoch: 165  train_loss: 30.14668083190918\n",
      "epoch: 166  train_loss: 56.71324920654297\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b034b7-d404-4e6d-aa6f-11ae008ef1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 139.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Obj Val  Constraints Viol  Elapsed Time\n",
      "count   1000.0       1000.000000   1000.000000\n",
      "mean       3.0          2.347360      0.006433\n",
      "std        0.0          1.291684      0.001273\n",
      "min        3.0          0.002752      0.004000\n",
      "25%        3.0          1.246561      0.005512\n",
      "50%        3.0          2.393041      0.006503\n",
      "75%        3.0          3.454771      0.007010\n",
      "max        3.0          4.499422      0.010529\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c21efb-aa5c-49b3-89a0-6b07d0acacc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.905608</td>\n",
       "      <td>0.010529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.810883</td>\n",
       "      <td>0.008532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.123591</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.225262</td>\n",
       "      <td>0.008520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.943377</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.269571</td>\n",
       "      <td>0.005510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.023561</td>\n",
       "      <td>0.004854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.167210</td>\n",
       "      <td>0.004688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.740112</td>\n",
       "      <td>0.004999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.612899</td>\n",
       "      <td>0.005005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol  Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          2.905608      0.010529\n",
       "1    (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          1.810883      0.008532\n",
       "2    (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          2.123591      0.008531\n",
       "3    (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          3.225262      0.008520\n",
       "4    (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          3.943377      0.007000\n",
       "..                         ...      ...               ...           ...\n",
       "995  (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          0.269571      0.005510\n",
       "996  (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          1.023561      0.004854\n",
       "997  (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          1.167210      0.004688\n",
       "998  (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          1.740112      0.004999\n",
       "999  (0.0, 1.0, 1.0, 0.0, 1.0)      3.0          3.612899      0.005005\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae6e5c-983f-4689-88e2-4ef26fe8e910",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "545cae68-65b7-4d0d-b87d-f021dfb0a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.threshold import roundThresholdModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2+1, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                                 int_ind={\"x_bar\":model.int_ind}, name=\"round\")\n",
    "_, problem = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18744735-a740-489c-bd05-49988544dfac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 59.326900482177734\n",
      "epoch: 1  train_loss: 41.29281234741211\n",
      "epoch: 2  train_loss: 39.73933029174805\n",
      "epoch: 3  train_loss: 41.40693664550781\n",
      "epoch: 4  train_loss: 41.0604133605957\n",
      "epoch: 5  train_loss: 41.2647819519043\n",
      "epoch: 6  train_loss: 41.20734786987305\n",
      "epoch: 7  train_loss: 40.80793380737305\n",
      "epoch: 8  train_loss: 37.508853912353516\n",
      "epoch: 9  train_loss: 43.864646911621094\n",
      "epoch: 10  train_loss: 39.26064682006836\n",
      "epoch: 11  train_loss: 39.99040222167969\n",
      "epoch: 12  train_loss: 38.344642639160156\n",
      "epoch: 13  train_loss: 41.38597106933594\n",
      "epoch: 14  train_loss: 40.20343017578125\n",
      "epoch: 15  train_loss: 37.5882453918457\n",
      "epoch: 16  train_loss: 39.66452407836914\n",
      "epoch: 17  train_loss: 41.60590362548828\n",
      "epoch: 18  train_loss: 41.98244094848633\n",
      "epoch: 19  train_loss: 40.917606353759766\n",
      "epoch: 20  train_loss: 42.18752670288086\n",
      "epoch: 21  train_loss: 42.41547393798828\n",
      "epoch: 22  train_loss: 41.26091766357422\n",
      "epoch: 23  train_loss: 45.06894302368164\n",
      "epoch: 24  train_loss: 41.41071319580078\n",
      "epoch: 25  train_loss: 41.659217834472656\n",
      "epoch: 26  train_loss: 42.71126937866211\n",
      "epoch: 27  train_loss: 44.22512435913086\n",
      "epoch: 28  train_loss: 43.10785675048828\n",
      "epoch: 29  train_loss: 44.079551696777344\n",
      "epoch: 30  train_loss: 41.74604034423828\n",
      "epoch: 31  train_loss: 46.61244583129883\n",
      "epoch: 32  train_loss: 47.06317901611328\n",
      "epoch: 33  train_loss: 45.24501419067383\n",
      "epoch: 34  train_loss: 46.393680572509766\n",
      "epoch: 35  train_loss: 51.2294807434082\n",
      "epoch: 36  train_loss: 48.458194732666016\n",
      "epoch: 37  train_loss: 49.28776550292969\n",
      "epoch: 38  train_loss: 49.38029479980469\n",
      "epoch: 39  train_loss: 51.19228744506836\n",
      "epoch: 40  train_loss: 48.727821350097656\n",
      "epoch: 41  train_loss: 48.48234939575195\n",
      "epoch: 42  train_loss: 45.471954345703125\n",
      "epoch: 43  train_loss: 49.700923919677734\n",
      "epoch: 44  train_loss: 47.33575439453125\n",
      "epoch: 45  train_loss: 49.7057991027832\n",
      "epoch: 46  train_loss: 46.841957092285156\n",
      "epoch: 47  train_loss: 48.98084259033203\n",
      "epoch: 48  train_loss: 49.1540412902832\n",
      "epoch: 49  train_loss: 47.230098724365234\n",
      "epoch: 50  train_loss: 45.74497604370117\n",
      "epoch: 51  train_loss: 49.753448486328125\n",
      "epoch: 52  train_loss: 49.84382629394531\n",
      "epoch: 53  train_loss: 48.07141876220703\n",
      "epoch: 54  train_loss: 48.908206939697266\n",
      "epoch: 55  train_loss: 48.92105484008789\n",
      "epoch: 56  train_loss: 47.315086364746094\n",
      "epoch: 57  train_loss: 50.6839485168457\n",
      "epoch: 58  train_loss: 46.40114974975586\n",
      "epoch: 59  train_loss: 48.499271392822266\n",
      "epoch: 60  train_loss: 48.380577087402344\n",
      "epoch: 61  train_loss: 53.32099914550781\n",
      "epoch: 62  train_loss: 48.37785720825195\n",
      "epoch: 63  train_loss: 51.169891357421875\n",
      "epoch: 64  train_loss: 52.41073226928711\n",
      "epoch: 65  train_loss: 49.20844268798828\n",
      "epoch: 66  train_loss: 49.045467376708984\n",
      "epoch: 67  train_loss: 50.053794860839844\n",
      "epoch: 68  train_loss: 48.86330032348633\n",
      "epoch: 69  train_loss: 50.92709732055664\n",
      "epoch: 70  train_loss: 47.0901985168457\n",
      "epoch: 71  train_loss: 47.087188720703125\n",
      "epoch: 72  train_loss: 47.725528717041016\n",
      "epoch: 73  train_loss: 50.34771728515625\n",
      "epoch: 74  train_loss: 51.19346237182617\n",
      "epoch: 75  train_loss: 54.79289245605469\n",
      "epoch: 76  train_loss: 51.8846321105957\n",
      "epoch: 77  train_loss: 49.38959503173828\n",
      "epoch: 78  train_loss: 48.331626892089844\n",
      "epoch: 79  train_loss: 51.4069709777832\n",
      "epoch: 80  train_loss: 48.47068786621094\n",
      "epoch: 81  train_loss: 53.745086669921875\n",
      "epoch: 82  train_loss: 50.9550666809082\n",
      "epoch: 83  train_loss: 50.99283218383789\n",
      "epoch: 84  train_loss: 49.538822174072266\n",
      "epoch: 85  train_loss: 47.969444274902344\n",
      "epoch: 86  train_loss: 52.98879623413086\n",
      "epoch: 87  train_loss: 50.12195587158203\n",
      "epoch: 88  train_loss: 47.79062271118164\n",
      "epoch: 89  train_loss: 52.635684967041016\n",
      "epoch: 90  train_loss: 53.48566818237305\n",
      "epoch: 91  train_loss: 51.185306549072266\n",
      "epoch: 92  train_loss: 50.708927154541016\n",
      "epoch: 93  train_loss: 55.24959945678711\n",
      "epoch: 94  train_loss: 51.58713912963867\n",
      "epoch: 95  train_loss: 56.31336212158203\n",
      "epoch: 96  train_loss: 53.59921646118164\n",
      "epoch: 97  train_loss: 51.432735443115234\n",
      "epoch: 98  train_loss: 50.68099594116211\n",
      "epoch: 99  train_loss: 54.474727630615234\n",
      "epoch: 100  train_loss: 52.38264083862305\n",
      "epoch: 101  train_loss: 55.21880340576172\n",
      "epoch: 102  train_loss: 52.736473083496094\n",
      "epoch: 103  train_loss: 54.69766616821289\n",
      "epoch: 104  train_loss: 52.18583679199219\n",
      "epoch: 105  train_loss: 52.0908203125\n",
      "epoch: 106  train_loss: 51.34250259399414\n",
      "epoch: 107  train_loss: 53.07775115966797\n",
      "epoch: 108  train_loss: 53.23011016845703\n",
      "epoch: 109  train_loss: 50.67784881591797\n",
      "epoch: 110  train_loss: 56.13044738769531\n",
      "epoch: 111  train_loss: 55.97814178466797\n",
      "epoch: 112  train_loss: 51.429988861083984\n",
      "epoch: 113  train_loss: 51.90616226196289\n",
      "epoch: 114  train_loss: 53.7977409362793\n",
      "epoch: 115  train_loss: 52.12009811401367\n",
      "epoch: 116  train_loss: 49.21192932128906\n",
      "epoch: 117  train_loss: 50.3305778503418\n",
      "epoch: 118  train_loss: 51.401824951171875\n",
      "epoch: 119  train_loss: 56.237022399902344\n",
      "epoch: 120  train_loss: 54.175254821777344\n",
      "epoch: 121  train_loss: 51.05143737792969\n",
      "epoch: 122  train_loss: 53.20738983154297\n",
      "epoch: 123  train_loss: 55.302677154541016\n",
      "epoch: 124  train_loss: 54.56036376953125\n",
      "epoch: 125  train_loss: 53.769832611083984\n",
      "epoch: 126  train_loss: 54.210853576660156\n",
      "epoch: 127  train_loss: 54.57956314086914\n",
      "epoch: 128  train_loss: 52.46267318725586\n",
      "epoch: 129  train_loss: 51.571205139160156\n",
      "epoch: 130  train_loss: 51.886863708496094\n",
      "epoch: 131  train_loss: 57.16204071044922\n",
      "epoch: 132  train_loss: 55.188419342041016\n",
      "epoch: 133  train_loss: 51.963722229003906\n",
      "epoch: 134  train_loss: 54.43369674682617\n",
      "epoch: 135  train_loss: 54.18250274658203\n",
      "epoch: 136  train_loss: 52.22687911987305\n",
      "epoch: 137  train_loss: 49.825050354003906\n",
      "epoch: 138  train_loss: 56.04863739013672\n",
      "epoch: 139  train_loss: 51.67253875732422\n",
      "epoch: 140  train_loss: 55.48735809326172\n",
      "epoch: 141  train_loss: 52.80638122558594\n",
      "epoch: 142  train_loss: 53.69344711303711\n",
      "epoch: 143  train_loss: 52.7398796081543\n",
      "epoch: 144  train_loss: 54.36223220825195\n",
      "epoch: 145  train_loss: 52.75993728637695\n",
      "epoch: 146  train_loss: 51.3748893737793\n",
      "epoch: 147  train_loss: 54.66755676269531\n",
      "epoch: 148  train_loss: 52.4581184387207\n",
      "epoch: 149  train_loss: 54.84534454345703\n",
      "epoch: 150  train_loss: 51.081932067871094\n",
      "epoch: 151  train_loss: 51.88645553588867\n",
      "epoch: 152  train_loss: 53.32231140136719\n",
      "epoch: 153  train_loss: 57.092430114746094\n",
      "epoch: 154  train_loss: 51.15858840942383\n",
      "epoch: 155  train_loss: 50.54951858520508\n",
      "epoch: 156  train_loss: 51.50005340576172\n",
      "epoch: 157  train_loss: 54.62067794799805\n",
      "epoch: 158  train_loss: 57.15309143066406\n",
      "epoch: 159  train_loss: 52.5722770690918\n",
      "epoch: 160  train_loss: 55.45416259765625\n",
      "epoch: 161  train_loss: 53.55194854736328\n",
      "epoch: 162  train_loss: 50.032630920410156\n",
      "epoch: 163  train_loss: 58.136474609375\n",
      "epoch: 164  train_loss: 54.2451057434082\n",
      "epoch: 165  train_loss: 57.185916900634766\n",
      "epoch: 166  train_loss: 49.96837615966797\n",
      "epoch: 167  train_loss: 55.213218688964844\n",
      "epoch: 168  train_loss: 52.37091064453125\n",
      "epoch: 169  train_loss: 54.03154754638672\n",
      "epoch: 170  train_loss: 54.026668548583984\n",
      "epoch: 171  train_loss: 53.17754364013672\n",
      "epoch: 172  train_loss: 51.32305908203125\n",
      "epoch: 173  train_loss: 54.472381591796875\n",
      "epoch: 174  train_loss: 48.8439826965332\n",
      "epoch: 175  train_loss: 53.45164108276367\n",
      "epoch: 176  train_loss: 56.20075225830078\n",
      "epoch: 177  train_loss: 56.65888977050781\n",
      "epoch: 178  train_loss: 52.135337829589844\n",
      "epoch: 179  train_loss: 56.971229553222656\n",
      "epoch: 180  train_loss: 54.49574661254883\n",
      "epoch: 181  train_loss: 52.880775451660156\n",
      "epoch: 182  train_loss: 54.865360260009766\n",
      "epoch: 183  train_loss: 53.39299392700195\n",
      "epoch: 184  train_loss: 55.223148345947266\n",
      "epoch: 185  train_loss: 52.0690803527832\n",
      "epoch: 186  train_loss: 53.3687858581543\n",
      "epoch: 187  train_loss: 49.65974044799805\n",
      "epoch: 188  train_loss: 52.95045471191406\n",
      "epoch: 189  train_loss: 55.32374954223633\n",
      "epoch: 190  train_loss: 51.375186920166016\n",
      "epoch: 191  train_loss: 51.71404266357422\n",
      "epoch: 192  train_loss: 55.14625549316406\n",
      "epoch: 193  train_loss: 50.88425827026367\n",
      "epoch: 194  train_loss: 49.82005310058594\n",
      "epoch: 195  train_loss: 56.12928009033203\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234958b5-a9bd-4a1a-b56a-edd8f2cbd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 136.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      4.813000          0.750917      0.006575\n",
      "std       0.390107          0.831895      0.001366\n",
      "min       4.000000          0.000000      0.003999\n",
      "25%       5.000000          0.000000      0.005525\n",
      "50%       5.000000          0.393041      0.006513\n",
      "75%       5.000000          1.454771      0.007341\n",
      "max       5.000000          2.499422      0.012532\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cdf8f7e-e400-40db-898b-42b588491ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.905608</td>\n",
       "      <td>0.010623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.123591</td>\n",
       "      <td>0.008512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.225262</td>\n",
       "      <td>0.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.943377</td>\n",
       "      <td>0.006004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(0.0, 0.0, 0.0, -2.0, 0.0)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(0.0, 0.0, -1.0, -2.0, 0.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.612899</td>\n",
       "      <td>0.006019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Sol  Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          0.905608      0.010623\n",
       "1    (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          0.000000      0.007516\n",
       "2    (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          0.123591      0.008512\n",
       "3    (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          1.225262      0.007504\n",
       "4    (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          1.943377      0.006004\n",
       "..                           ...      ...               ...           ...\n",
       "995   (0.0, 0.0, 0.0, -2.0, 0.0)      4.0          0.000000      0.004000\n",
       "996  (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          0.000000      0.005527\n",
       "997  (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          0.000000      0.006513\n",
       "998  (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          0.000000      0.007543\n",
       "999  (0.0, 0.0, -1.0, -2.0, 0.0)      5.0          1.612899      0.006019\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c777ad-d5a3-4065-a137-123aa84c0df5",
   "metadata": {},
   "source": [
    "## Learning to Round with Fixed Solution Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64737e09-1735-4893-a0d6-c8ca73a91fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "from model.round import roundModel\n",
    "# round x\n",
    "layers_rnd = netFC(input_dim=num_vars*2+1, hidden_dims=[80]*4, output_dim=num_vars)\n",
    "round_func = roundModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x_bar\"], output_keys=[\"x_rnd\"],\n",
    "                        int_ind={\"x_bar\":model.int_ind}, name=\"round\")\n",
    "problem_rel, problem_rnd = getNMProb(round_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b39c4a7-2b21-4384-9d85-2e479ce85965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 200.56048583984375\n",
      "epoch: 1  train_loss: 200.05564880371094\n",
      "epoch: 2  train_loss: 200.00062561035156\n",
      "epoch: 3  train_loss: 199.98989868164062\n",
      "epoch: 4  train_loss: 200.00938415527344\n",
      "epoch: 5  train_loss: 200.00672912597656\n",
      "epoch: 6  train_loss: 199.95262145996094\n",
      "epoch: 7  train_loss: 199.96778869628906\n",
      "epoch: 8  train_loss: 199.99769592285156\n",
      "epoch: 9  train_loss: 200.0087127685547\n",
      "epoch: 10  train_loss: 200.02859497070312\n",
      "epoch: 11  train_loss: 199.96282958984375\n",
      "epoch: 12  train_loss: 199.886962890625\n",
      "epoch: 13  train_loss: 199.97325134277344\n",
      "epoch: 14  train_loss: 199.9023895263672\n",
      "epoch: 15  train_loss: 199.96127319335938\n",
      "epoch: 16  train_loss: 199.89193725585938\n",
      "epoch: 17  train_loss: 200.06082153320312\n",
      "epoch: 18  train_loss: 200.04470825195312\n",
      "epoch: 19  train_loss: 199.99281311035156\n",
      "epoch: 20  train_loss: 199.95962524414062\n",
      "epoch: 21  train_loss: 199.9354248046875\n",
      "epoch: 22  train_loss: 199.9658966064453\n",
      "epoch: 23  train_loss: 199.99880981445312\n",
      "epoch: 24  train_loss: 199.963623046875\n",
      "epoch: 25  train_loss: 200.00997924804688\n",
      "epoch: 26  train_loss: 199.98402404785156\n",
      "epoch: 27  train_loss: 199.97621154785156\n",
      "epoch: 28  train_loss: 199.9806365966797\n",
      "epoch: 29  train_loss: 199.95425415039062\n",
      "epoch: 30  train_loss: 200.00132751464844\n",
      "epoch: 31  train_loss: 199.9900665283203\n",
      "epoch: 32  train_loss: 199.9945831298828\n",
      "epoch: 33  train_loss: 199.94358825683594\n",
      "epoch: 34  train_loss: 199.9888153076172\n",
      "epoch: 35  train_loss: 199.969482421875\n",
      "epoch: 36  train_loss: 199.9630584716797\n",
      "epoch: 37  train_loss: 199.9486541748047\n",
      "epoch: 38  train_loss: 200.05751037597656\n",
      "epoch: 39  train_loss: 200.03085327148438\n",
      "epoch: 40  train_loss: 200.0327606201172\n",
      "epoch: 41  train_loss: 199.988525390625\n",
      "epoch: 42  train_loss: 200.0350341796875\n",
      "epoch: 43  train_loss: 199.95469665527344\n",
      "epoch: 44  train_loss: 199.94215393066406\n",
      "epoch: 45  train_loss: 200.02626037597656\n",
      "epoch: 46  train_loss: 199.97911071777344\n",
      "epoch: 47  train_loss: 199.99851989746094\n",
      "epoch: 48  train_loss: 199.94500732421875\n",
      "epoch: 49  train_loss: 200.04249572753906\n",
      "epoch: 50  train_loss: 199.9743194580078\n",
      "epoch: 51  train_loss: 199.94894409179688\n",
      "epoch: 52  train_loss: 199.95518493652344\n",
      "epoch: 53  train_loss: 199.96131896972656\n",
      "epoch: 54  train_loss: 199.98703002929688\n",
      "epoch: 55  train_loss: 199.90333557128906\n",
      "epoch: 56  train_loss: 200.0168914794922\n",
      "epoch: 57  train_loss: 199.98110961914062\n",
      "epoch: 58  train_loss: 200.03689575195312\n",
      "epoch: 59  train_loss: 199.98080444335938\n",
      "epoch: 60  train_loss: 199.962890625\n",
      "epoch: 61  train_loss: 199.98931884765625\n",
      "epoch: 62  train_loss: 200.0186767578125\n",
      "epoch: 63  train_loss: 199.9448699951172\n",
      "epoch: 64  train_loss: 200.02178955078125\n",
      "epoch: 65  train_loss: 200.00144958496094\n",
      "epoch: 66  train_loss: 199.97169494628906\n",
      "epoch: 67  train_loss: 199.9654083251953\n",
      "epoch: 68  train_loss: 199.95330810546875\n",
      "epoch: 69  train_loss: 200.02407836914062\n",
      "epoch: 70  train_loss: 200.0026397705078\n",
      "epoch: 71  train_loss: 199.98861694335938\n",
      "epoch: 72  train_loss: 199.95632934570312\n",
      "epoch: 73  train_loss: 200.03286743164062\n",
      "epoch: 74  train_loss: 200.02200317382812\n",
      "epoch: 75  train_loss: 199.97691345214844\n",
      "epoch: 76  train_loss: 199.9119873046875\n",
      "epoch: 77  train_loss: 199.971923828125\n",
      "epoch: 78  train_loss: 199.9776153564453\n",
      "epoch: 79  train_loss: 199.968505859375\n",
      "epoch: 80  train_loss: 200.0356903076172\n",
      "epoch: 81  train_loss: 199.9600830078125\n",
      "epoch: 82  train_loss: 200.0298309326172\n",
      "epoch: 83  train_loss: 199.9754180908203\n",
      "epoch: 84  train_loss: 199.9923095703125\n",
      "epoch: 85  train_loss: 200.01683044433594\n",
      "epoch: 86  train_loss: 199.91763305664062\n",
      "epoch: 87  train_loss: 200.02517700195312\n",
      "epoch: 88  train_loss: 199.92250061035156\n",
      "epoch: 89  train_loss: 199.99562072753906\n",
      "epoch: 90  train_loss: 199.98214721679688\n",
      "epoch: 91  train_loss: 199.9726104736328\n",
      "epoch: 92  train_loss: 199.9850616455078\n",
      "epoch: 93  train_loss: 199.97967529296875\n",
      "epoch: 94  train_loss: 199.95822143554688\n",
      "epoch: 95  train_loss: 199.98892211914062\n",
      "epoch: 96  train_loss: 199.99224853515625\n",
      "epoch: 97  train_loss: 200.02784729003906\n",
      "epoch: 98  train_loss: 199.97108459472656\n",
      "epoch: 99  train_loss: 200.00006103515625\n",
      "epoch: 100  train_loss: 199.99490356445312\n",
      "epoch: 101  train_loss: 199.97943115234375\n",
      "epoch: 102  train_loss: 200.00706481933594\n",
      "epoch: 103  train_loss: 200.00482177734375\n",
      "epoch: 104  train_loss: 199.9612274169922\n",
      "epoch: 105  train_loss: 200.00689697265625\n",
      "epoch: 106  train_loss: 199.93307495117188\n",
      "epoch: 107  train_loss: 199.92198181152344\n",
      "epoch: 108  train_loss: 199.9952392578125\n",
      "epoch: 109  train_loss: 199.98777770996094\n",
      "epoch: 110  train_loss: 199.99220275878906\n",
      "epoch: 111  train_loss: 199.99771118164062\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training for mapping\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem_rel.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_rel, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1efad3d-dd09-4aef-81dd-3ed3c31ffb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 113.4201889038086\n",
      "epoch: 1  train_loss: 111.99301147460938\n",
      "epoch: 2  train_loss: 112.25984191894531\n",
      "epoch: 3  train_loss: 113.07791900634766\n",
      "epoch: 4  train_loss: 112.0425033569336\n",
      "epoch: 5  train_loss: 113.03713989257812\n",
      "epoch: 6  train_loss: 113.28978729248047\n",
      "epoch: 7  train_loss: 112.51097106933594\n",
      "epoch: 8  train_loss: 110.89220428466797\n",
      "epoch: 9  train_loss: 110.82777404785156\n",
      "epoch: 10  train_loss: 110.6501693725586\n",
      "epoch: 11  train_loss: 112.83306884765625\n",
      "epoch: 12  train_loss: 112.2095947265625\n",
      "epoch: 13  train_loss: 112.64315795898438\n",
      "epoch: 14  train_loss: 112.79176330566406\n",
      "epoch: 15  train_loss: 113.62065887451172\n",
      "epoch: 16  train_loss: 111.35653686523438\n",
      "epoch: 17  train_loss: 113.41866302490234\n",
      "epoch: 18  train_loss: 112.29954528808594\n",
      "epoch: 19  train_loss: 111.8309326171875\n",
      "epoch: 20  train_loss: 114.70136260986328\n",
      "epoch: 21  train_loss: 113.65640258789062\n",
      "epoch: 22  train_loss: 113.66444396972656\n",
      "epoch: 23  train_loss: 112.0245590209961\n",
      "epoch: 24  train_loss: 113.31755065917969\n",
      "epoch: 25  train_loss: 111.2506103515625\n",
      "epoch: 26  train_loss: 111.93517303466797\n",
      "epoch: 27  train_loss: 111.48029327392578\n",
      "epoch: 28  train_loss: 112.82183837890625\n",
      "epoch: 29  train_loss: 113.73834228515625\n",
      "epoch: 30  train_loss: 112.65906524658203\n",
      "epoch: 31  train_loss: 112.92323303222656\n",
      "epoch: 32  train_loss: 112.50170135498047\n",
      "epoch: 33  train_loss: 113.47566986083984\n",
      "epoch: 34  train_loss: 112.18663024902344\n",
      "epoch: 35  train_loss: 112.56077575683594\n",
      "epoch: 36  train_loss: 111.19490051269531\n",
      "epoch: 37  train_loss: 111.77989959716797\n",
      "epoch: 38  train_loss: 112.2983627319336\n",
      "epoch: 39  train_loss: 112.04468536376953\n",
      "epoch: 40  train_loss: 112.31161499023438\n",
      "epoch: 41  train_loss: 112.02262878417969\n",
      "epoch: 42  train_loss: 111.11504364013672\n",
      "epoch: 43  train_loss: 113.0306167602539\n",
      "epoch: 44  train_loss: 114.02137756347656\n",
      "epoch: 45  train_loss: 113.52268981933594\n",
      "epoch: 46  train_loss: 113.65691375732422\n",
      "epoch: 47  train_loss: 114.2004165649414\n",
      "epoch: 48  train_loss: 114.46691131591797\n",
      "epoch: 49  train_loss: 113.98738861083984\n",
      "epoch: 50  train_loss: 112.4660873413086\n",
      "epoch: 51  train_loss: 112.51565551757812\n",
      "epoch: 52  train_loss: 112.71162414550781\n",
      "epoch: 53  train_loss: 113.58271789550781\n",
      "epoch: 54  train_loss: 110.04940795898438\n",
      "epoch: 55  train_loss: 113.86659240722656\n",
      "epoch: 56  train_loss: 112.41412353515625\n",
      "epoch: 57  train_loss: 111.75341796875\n",
      "epoch: 58  train_loss: 113.67829895019531\n",
      "epoch: 59  train_loss: 112.94313049316406\n",
      "epoch: 60  train_loss: 112.09536743164062\n",
      "epoch: 61  train_loss: 112.93453216552734\n",
      "epoch: 62  train_loss: 111.16641998291016\n",
      "epoch: 63  train_loss: 112.27108001708984\n",
      "epoch: 64  train_loss: 113.13482666015625\n",
      "epoch: 65  train_loss: 111.68720245361328\n",
      "epoch: 66  train_loss: 111.31063842773438\n",
      "epoch: 67  train_loss: 111.1969985961914\n",
      "epoch: 68  train_loss: 112.77205657958984\n",
      "epoch: 69  train_loss: 113.00572204589844\n",
      "epoch: 70  train_loss: 113.84323120117188\n",
      "epoch: 71  train_loss: 110.66357421875\n",
      "epoch: 72  train_loss: 111.85262298583984\n",
      "epoch: 73  train_loss: 112.98673248291016\n",
      "epoch: 74  train_loss: 113.64019012451172\n",
      "epoch: 75  train_loss: 113.27975463867188\n",
      "epoch: 76  train_loss: 112.0801010131836\n",
      "epoch: 77  train_loss: 112.42056274414062\n",
      "epoch: 78  train_loss: 112.14849090576172\n",
      "epoch: 79  train_loss: 112.80638122558594\n",
      "epoch: 80  train_loss: 113.2508316040039\n",
      "epoch: 81  train_loss: 113.3161849975586\n",
      "epoch: 82  train_loss: 112.34656524658203\n",
      "epoch: 83  train_loss: 112.23666381835938\n",
      "epoch: 84  train_loss: 111.70162963867188\n",
      "epoch: 85  train_loss: 111.40946960449219\n",
      "epoch: 86  train_loss: 111.61805725097656\n",
      "epoch: 87  train_loss: 112.6601333618164\n",
      "epoch: 88  train_loss: 111.52349090576172\n",
      "epoch: 89  train_loss: 112.35993957519531\n",
      "epoch: 90  train_loss: 111.03145599365234\n",
      "epoch: 91  train_loss: 114.32490539550781\n",
      "epoch: 92  train_loss: 114.1142578125\n",
      "epoch: 93  train_loss: 112.49124908447266\n",
      "epoch: 94  train_loss: 111.89723205566406\n",
      "epoch: 95  train_loss: 110.9448471069336\n",
      "epoch: 96  train_loss: 114.22368621826172\n",
      "epoch: 97  train_loss: 113.09441375732422\n",
      "epoch: 98  train_loss: 113.12218475341797\n",
      "epoch: 99  train_loss: 112.36807250976562\n",
      "epoch: 100  train_loss: 112.41958618164062\n",
      "epoch: 101  train_loss: 113.06022644042969\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# freeze sol mapping\n",
    "#problem_rel.freeze()\n",
    "# training for rounding\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_rnd, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7858c207-11d3-4cfc-8e7a-13d831ee7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 138.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean      2.266000          3.081360      0.006489\n",
      "std       0.640042          1.120670      0.001113\n",
      "min       1.000000          0.045919      0.003995\n",
      "25%       2.000000          2.243437      0.005653\n",
      "50%       2.000000          3.021045      0.006512\n",
      "75%       3.000000          3.992779      0.007010\n",
      "max       3.000000          5.490592      0.010534\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem_rnd(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6621286f-2b5b-4c83-abe1-51a41e90b193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.905608</td>\n",
       "      <td>0.009708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.810883</td>\n",
       "      <td>0.008515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.123591</td>\n",
       "      <td>0.009517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.225262</td>\n",
       "      <td>0.007536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.943377</td>\n",
       "      <td>0.008521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.269571</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.023561</td>\n",
       "      <td>0.005681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.167210</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.740112</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.612899</td>\n",
       "      <td>0.007032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sol  Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (1.0, 0.0, 1.0, 0.0, 0.0)      2.0          3.905608      0.009708\n",
       "1    (1.0, 0.0, 1.0, 0.0, 1.0)      3.0          1.810883      0.008515\n",
       "2    (1.0, 0.0, 1.0, 0.0, 1.0)      3.0          2.123591      0.009517\n",
       "3    (1.0, 0.0, 1.0, 0.0, 1.0)      3.0          3.225262      0.007536\n",
       "4    (1.0, 0.0, 1.0, 0.0, 1.0)      3.0          3.943377      0.008521\n",
       "..                         ...      ...               ...           ...\n",
       "995  (1.0, 0.0, 0.0, 0.0, 0.0)      1.0          2.269571      0.005000\n",
       "996  (1.0, 0.0, 1.0, 0.0, 1.0)      3.0          1.023561      0.005681\n",
       "997  (1.0, 0.0, 1.0, 0.0, 0.0)      2.0          2.167210      0.006510\n",
       "998  (1.0, 0.0, 1.0, 0.0, 1.0)      3.0          1.740112      0.007068\n",
       "999  (1.0, 0.0, 1.0, 0.0, 0.0)      2.0          4.612899      0.007032\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f140ecf-274f-4dcb-b26e-e76c46ca53e7",
   "metadata": {},
   "source": [
    "### Learning to Feasibility Pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddfd3db5-b61c-46dc-92ae-138ce002fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layer import netFC\n",
    "# define neural architecture for the solution mapping\n",
    "sol_func = nm.modules.blocks.MLP(insize=num_vars+1, outsize=num_vars, bias=True,\n",
    "                                 linear_map=nm.slim.maps[\"linear\"], nonlin=nn.ReLU,\n",
    "                                 hsizes=[80]*4)\n",
    "# define neural architecture for rounding\n",
    "rnd_layer = netFC(input_dim=num_vars*2+1, hidden_dims=[80]*4, output_dim=num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9397410-cf75-46de-83b9-d975605b2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get nm optimization model\n",
    "from problem.neural import probRastrigin\n",
    "def getProb(x, p, a):\n",
    "    return probRastrigin(x, p, a, num_vars=num_vars, alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2903e087-27af-4738-b1f5-3c30d717ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import feasibilityPumpModel\n",
    "# feasibility pump model\n",
    "problem_rel, problem_fp = feasibilityPumpModel([\"p\", \"a\"], getProb, sol_func, rnd_layer, int_ind=model.int_ind, num_iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57c24ef8-218a-40f0-a448-f0b38851c3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 201.03836059570312\n",
      "epoch: 1  train_loss: 200.00315856933594\n",
      "epoch: 2  train_loss: 200.04458618164062\n",
      "epoch: 3  train_loss: 199.9217987060547\n",
      "epoch: 4  train_loss: 200.03433227539062\n",
      "epoch: 5  train_loss: 199.97879028320312\n",
      "epoch: 6  train_loss: 200.00428771972656\n",
      "epoch: 7  train_loss: 200.03594970703125\n",
      "epoch: 8  train_loss: 199.9923095703125\n",
      "epoch: 9  train_loss: 200.03807067871094\n",
      "epoch: 10  train_loss: 199.88279724121094\n",
      "epoch: 11  train_loss: 200.01612854003906\n",
      "epoch: 12  train_loss: 200.03578186035156\n",
      "epoch: 13  train_loss: 199.96961975097656\n",
      "epoch: 14  train_loss: 199.97190856933594\n",
      "epoch: 15  train_loss: 200.0224609375\n",
      "epoch: 16  train_loss: 199.9395751953125\n",
      "epoch: 17  train_loss: 199.98155212402344\n",
      "epoch: 18  train_loss: 199.98475646972656\n",
      "epoch: 19  train_loss: 200.0723419189453\n",
      "epoch: 20  train_loss: 200.00851440429688\n",
      "epoch: 21  train_loss: 199.98455810546875\n",
      "epoch: 22  train_loss: 200.01275634765625\n",
      "epoch: 23  train_loss: 199.97805786132812\n",
      "epoch: 24  train_loss: 200.00315856933594\n",
      "epoch: 25  train_loss: 200.02049255371094\n",
      "epoch: 26  train_loss: 200.03358459472656\n",
      "epoch: 27  train_loss: 199.99317932128906\n",
      "epoch: 28  train_loss: 200.0459442138672\n",
      "epoch: 29  train_loss: 199.97283935546875\n",
      "epoch: 30  train_loss: 199.96368408203125\n",
      "epoch: 31  train_loss: 199.9817352294922\n",
      "epoch: 32  train_loss: 199.9905242919922\n",
      "epoch: 33  train_loss: 200.03060913085938\n",
      "epoch: 34  train_loss: 200.02310180664062\n",
      "epoch: 35  train_loss: 199.97215270996094\n",
      "epoch: 36  train_loss: 199.96534729003906\n",
      "epoch: 37  train_loss: 199.988037109375\n",
      "epoch: 38  train_loss: 199.98475646972656\n",
      "epoch: 39  train_loss: 200.0166473388672\n",
      "epoch: 40  train_loss: 199.98106384277344\n",
      "epoch: 41  train_loss: 199.95663452148438\n",
      "epoch: 42  train_loss: 200.0636444091797\n",
      "epoch: 43  train_loss: 199.95379638671875\n",
      "epoch: 44  train_loss: 200.0115966796875\n",
      "epoch: 45  train_loss: 200.03158569335938\n",
      "epoch: 46  train_loss: 200.02854919433594\n",
      "epoch: 47  train_loss: 200.0011444091797\n",
      "epoch: 48  train_loss: 199.9795684814453\n",
      "epoch: 49  train_loss: 200.008544921875\n",
      "epoch: 50  train_loss: 199.94290161132812\n",
      "epoch: 51  train_loss: 199.96336364746094\n",
      "epoch: 52  train_loss: 200.03575134277344\n",
      "epoch: 53  train_loss: 199.998046875\n",
      "epoch: 54  train_loss: 199.94749450683594\n",
      "epoch: 55  train_loss: 199.99546813964844\n",
      "epoch: 56  train_loss: 199.9852752685547\n",
      "epoch: 57  train_loss: 200.009765625\n",
      "epoch: 58  train_loss: 199.9383544921875\n",
      "epoch: 59  train_loss: 199.98809814453125\n",
      "epoch: 60  train_loss: 199.97007751464844\n",
      "epoch: 61  train_loss: 200.01922607421875\n",
      "epoch: 62  train_loss: 199.96603393554688\n",
      "epoch: 63  train_loss: 199.99879455566406\n",
      "epoch: 64  train_loss: 199.98052978515625\n",
      "epoch: 65  train_loss: 199.98097229003906\n",
      "epoch: 66  train_loss: 199.97801208496094\n",
      "epoch: 67  train_loss: 199.9718475341797\n",
      "epoch: 68  train_loss: 200.05398559570312\n",
      "epoch: 69  train_loss: 200.01124572753906\n",
      "epoch: 70  train_loss: 200.0061492919922\n",
      "epoch: 71  train_loss: 199.99594116210938\n",
      "epoch: 72  train_loss: 199.9840850830078\n",
      "epoch: 73  train_loss: 199.9438934326172\n",
      "epoch: 74  train_loss: 199.91976928710938\n",
      "epoch: 75  train_loss: 200.0050506591797\n",
      "epoch: 76  train_loss: 200.01351928710938\n",
      "epoch: 77  train_loss: 199.9857940673828\n",
      "epoch: 78  train_loss: 199.96078491210938\n",
      "epoch: 79  train_loss: 199.99122619628906\n",
      "epoch: 80  train_loss: 200.02078247070312\n",
      "epoch: 81  train_loss: 200.00428771972656\n",
      "epoch: 82  train_loss: 200.02793884277344\n",
      "epoch: 83  train_loss: 200.0331268310547\n",
      "epoch: 84  train_loss: 199.9662628173828\n",
      "epoch: 85  train_loss: 200.03016662597656\n",
      "epoch: 86  train_loss: 199.95741271972656\n",
      "epoch: 87  train_loss: 199.94874572753906\n",
      "epoch: 88  train_loss: 199.97332763671875\n",
      "epoch: 89  train_loss: 199.98580932617188\n",
      "epoch: 90  train_loss: 199.96414184570312\n",
      "epoch: 91  train_loss: 199.9540252685547\n",
      "epoch: 92  train_loss: 200.00149536132812\n",
      "epoch: 93  train_loss: 200.01217651367188\n",
      "epoch: 94  train_loss: 199.9685821533203\n",
      "epoch: 95  train_loss: 199.9377899169922\n",
      "epoch: 96  train_loss: 200.01206970214844\n",
      "epoch: 97  train_loss: 199.958251953125\n",
      "epoch: 98  train_loss: 199.9053497314453\n",
      "epoch: 99  train_loss: 199.97003173828125\n",
      "epoch: 100  train_loss: 199.98379516601562\n",
      "epoch: 101  train_loss: 199.95545959472656\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# training for mapping\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem_rel.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_rel, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917856c4-f7db-4537-a59c-1499d0d27557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 1197.4468994140625\n",
      "epoch: 1  train_loss: 1198.0772705078125\n",
      "epoch: 2  train_loss: 1200.3199462890625\n",
      "epoch: 3  train_loss: 1182.4595947265625\n",
      "epoch: 4  train_loss: 1193.3525390625\n",
      "epoch: 5  train_loss: 1188.619384765625\n",
      "epoch: 6  train_loss: 1199.23779296875\n",
      "epoch: 7  train_loss: 1195.2188720703125\n",
      "epoch: 8  train_loss: 1213.049072265625\n",
      "epoch: 9  train_loss: 1200.4154052734375\n",
      "epoch: 10  train_loss: 1204.30322265625\n",
      "epoch: 11  train_loss: 1214.9918212890625\n",
      "epoch: 12  train_loss: 1202.0118408203125\n",
      "epoch: 13  train_loss: 1195.0147705078125\n",
      "epoch: 14  train_loss: 1201.7613525390625\n",
      "epoch: 15  train_loss: 1202.967529296875\n",
      "epoch: 16  train_loss: 1193.233154296875\n",
      "epoch: 17  train_loss: 1204.9725341796875\n",
      "epoch: 18  train_loss: 1196.9180908203125\n",
      "epoch: 19  train_loss: 1197.660400390625\n",
      "epoch: 20  train_loss: 1203.8084716796875\n",
      "epoch: 21  train_loss: 1200.6768798828125\n",
      "epoch: 22  train_loss: 1199.1092529296875\n",
      "epoch: 23  train_loss: 1198.511962890625\n",
      "epoch: 24  train_loss: 1209.5\n",
      "epoch: 25  train_loss: 1206.2166748046875\n",
      "epoch: 26  train_loss: 1184.972412109375\n",
      "epoch: 27  train_loss: 1201.2127685546875\n",
      "epoch: 28  train_loss: 1209.3037109375\n",
      "epoch: 29  train_loss: 1192.7822265625\n",
      "epoch: 30  train_loss: 1185.8760986328125\n",
      "epoch: 31  train_loss: 1196.7467041015625\n",
      "epoch: 32  train_loss: 1188.526123046875\n",
      "epoch: 33  train_loss: 1203.75927734375\n",
      "epoch: 34  train_loss: 1208.2774658203125\n",
      "epoch: 35  train_loss: 1207.0103759765625\n",
      "epoch: 36  train_loss: 1207.1209716796875\n",
      "epoch: 37  train_loss: 1188.9222412109375\n",
      "epoch: 38  train_loss: 1193.588134765625\n",
      "epoch: 39  train_loss: 1200.31494140625\n",
      "epoch: 40  train_loss: 1184.4195556640625\n",
      "epoch: 41  train_loss: 1184.9599609375\n",
      "epoch: 42  train_loss: 1203.7735595703125\n",
      "epoch: 43  train_loss: 1194.924560546875\n",
      "epoch: 44  train_loss: 1187.7623291015625\n",
      "epoch: 45  train_loss: 1187.6263427734375\n",
      "epoch: 46  train_loss: 1193.032958984375\n",
      "epoch: 47  train_loss: 1197.8026123046875\n",
      "epoch: 48  train_loss: 1194.536376953125\n",
      "epoch: 49  train_loss: 1213.0355224609375\n",
      "epoch: 50  train_loss: 1188.3944091796875\n",
      "epoch: 51  train_loss: 1181.356201171875\n",
      "epoch: 52  train_loss: 1194.914794921875\n",
      "epoch: 53  train_loss: 1195.0394287109375\n",
      "epoch: 54  train_loss: 1205.493896484375\n",
      "epoch: 55  train_loss: 1211.215087890625\n",
      "epoch: 56  train_loss: 1191.28466796875\n",
      "epoch: 57  train_loss: 1201.02587890625\n",
      "epoch: 58  train_loss: 1185.9266357421875\n",
      "epoch: 59  train_loss: 1204.8182373046875\n",
      "epoch: 60  train_loss: 1198.6553955078125\n",
      "epoch: 61  train_loss: 1189.8460693359375\n",
      "epoch: 62  train_loss: 1212.7352294921875\n",
      "epoch: 63  train_loss: 1205.654541015625\n",
      "epoch: 64  train_loss: 1205.301513671875\n",
      "epoch: 65  train_loss: 1179.1280517578125\n",
      "epoch: 66  train_loss: 1201.7408447265625\n",
      "epoch: 67  train_loss: 1192.8101806640625\n",
      "epoch: 68  train_loss: 1199.013916015625\n",
      "epoch: 69  train_loss: 1204.0838623046875\n",
      "epoch: 70  train_loss: 1205.4295654296875\n",
      "epoch: 71  train_loss: 1189.10791015625\n",
      "epoch: 72  train_loss: 1188.9627685546875\n",
      "epoch: 73  train_loss: 1209.572021484375\n",
      "epoch: 74  train_loss: 1185.3050537109375\n",
      "epoch: 75  train_loss: 1221.1280517578125\n",
      "epoch: 76  train_loss: 1181.6673583984375\n",
      "epoch: 77  train_loss: 1204.7958984375\n",
      "epoch: 78  train_loss: 1189.1580810546875\n",
      "epoch: 79  train_loss: 1179.7593994140625\n",
      "epoch: 80  train_loss: 1191.497802734375\n",
      "epoch: 81  train_loss: 1205.5673828125\n",
      "epoch: 82  train_loss: 1197.09619140625\n",
      "epoch: 83  train_loss: 1203.16259765625\n",
      "epoch: 84  train_loss: 1194.705810546875\n",
      "epoch: 85  train_loss: 1201.787353515625\n",
      "epoch: 86  train_loss: 1193.5731201171875\n",
      "epoch: 87  train_loss: 1207.9403076171875\n",
      "epoch: 88  train_loss: 1198.8265380859375\n",
      "epoch: 89  train_loss: 1189.7811279296875\n",
      "epoch: 90  train_loss: 1178.7296142578125\n",
      "epoch: 91  train_loss: 1197.0029296875\n",
      "epoch: 92  train_loss: 1200.2386474609375\n",
      "epoch: 93  train_loss: 1198.900634765625\n",
      "epoch: 94  train_loss: 1205.1375732421875\n",
      "epoch: 95  train_loss: 1202.9217529296875\n",
      "epoch: 96  train_loss: 1196.2052001953125\n",
      "epoch: 97  train_loss: 1210.618408203125\n",
      "epoch: 98  train_loss: 1206.52490234375\n",
      "epoch: 99  train_loss: 1203.315185546875\n",
      "epoch: 100  train_loss: 1190.2784423828125\n",
      "epoch: 101  train_loss: 1188.5721435546875\n",
      "Early stopping!!!\n"
     ]
    }
   ],
   "source": [
    "# freeze sol mapping\n",
    "#problem_rel.freeze()\n",
    "# training for feasibility pump\n",
    "lr = 0.001    # step size for gradient descent\n",
    "epochs = 400  # number of training epochs\n",
    "warmup = 50   # number of epochs to wait before enacting early stopping policy\n",
    "patience = 50 # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "# set adamW as optimizer\n",
    "optimizer = torch.optim.AdamW(problem.parameters(), lr=lr)\n",
    "# define trainer\n",
    "trainer = nm.trainer.Trainer(problem_fp, loader_train, loader_dev, loader_test,\n",
    "                             optimizer, epochs=epochs, patience=patience, warmup=warmup)\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb8b7b8b-96db-47cc-8140-91f75aa2f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:14<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean     12.797000          2.340486      0.132399\n",
      "std       1.394179          2.058503      0.018744\n",
      "min       7.000000          0.000000      0.116246\n",
      "25%      13.000000          0.067266      0.120015\n",
      "50%      13.000000          2.407362      0.124788\n",
      "75%      14.000000          3.676876      0.138522\n",
      "max      15.000000          8.908162      0.279630\n"
     ]
    }
   ],
   "source": [
    "sols, objvals, conviols, elapseds = [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32), \"a\":torch.tensor(np.array([a]), dtype=torch.float32), \"name\": \"test\"}\n",
    "    tick = time.time()\n",
    "    output = problem_fp(datapoints)\n",
    "    tock = time.time()\n",
    "    x = output[\"test_x_rnd\"]\n",
    "    # get values\n",
    "    model.setParamValue(p, *a)\n",
    "    for ind in model.x:\n",
    "        model.x[ind].value = x[0, ind].item()\n",
    "    xval, objval = model.getVal()\n",
    "    sols.append(xval.values())\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.calViolation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1da6416-39bb-42c4-a194-79228f8f7e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sol</th>\n",
       "      <th>Obj Val</th>\n",
       "      <th>Constraints Viol</th>\n",
       "      <th>Elapsed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-2.0, 1.0, 1.0, -2.0, 2.0)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.188784</td>\n",
       "      <td>0.185267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 1.0, 1.0, -1.0, 3.0)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.378234</td>\n",
       "      <td>0.135124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-2.0, 1.0, 1.0, -2.0, 2.0)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.752818</td>\n",
       "      <td>0.150625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-1.0, 1.0, 1.0, -1.0, 3.0)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.549477</td>\n",
       "      <td>0.142117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-1.0, 1.0, 1.0, -1.0, 3.0)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(1.0, -1.0, 1.0, -1.0, 2.0)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.460858</td>\n",
       "      <td>0.126672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(1.0, -2.0, 1.0, -2.0, 2.0)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.952877</td>\n",
       "      <td>0.119656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(1.0, -2.0, 1.0, -2.0, 2.0)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.665580</td>\n",
       "      <td>0.122765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(1.0, 1.0, 1.0, -1.0, 3.0)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.519776</td>\n",
       "      <td>0.120072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(-1.0, 1.0, 1.0, -1.0, 3.0)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Sol  Obj Val  Constraints Viol  Elapsed Time\n",
       "0    (-2.0, 1.0, 1.0, -2.0, 2.0)     14.0          2.188784      0.185267\n",
       "1     (1.0, 1.0, 1.0, -1.0, 3.0)     13.0          3.378234      0.135124\n",
       "2    (-2.0, 1.0, 1.0, -2.0, 2.0)     14.0          3.752818      0.150625\n",
       "3    (-1.0, 1.0, 1.0, -1.0, 3.0)     13.0          0.549477      0.142117\n",
       "4    (-1.0, 1.0, 1.0, -1.0, 3.0)     13.0          0.000000      0.132024\n",
       "..                           ...      ...               ...           ...\n",
       "995  (1.0, -1.0, 1.0, -1.0, 2.0)      8.0          1.460858      0.126672\n",
       "996  (1.0, -2.0, 1.0, -2.0, 2.0)     14.0          5.952877      0.119656\n",
       "997  (1.0, -2.0, 1.0, -2.0, 2.0)     14.0          5.665580      0.122765\n",
       "998   (1.0, 1.0, 1.0, -1.0, 3.0)     13.0          3.519776      0.120072\n",
       "999  (-1.0, 1.0, 1.0, -1.0, 3.0)     13.0          0.000000      0.129987\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d761fd9-ab80-4f5a-80ec-cfafb9539b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
