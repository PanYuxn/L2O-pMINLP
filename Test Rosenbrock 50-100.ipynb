{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61b914-e1af-43b9-9766-5092593f92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fe4527-9dbf-48f0-bfb3-62cda59092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warning\n",
    "import logging\n",
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5560447-da9d-4cbe-aab4-538aa11c8ee8",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52363c72-0d20-4c08-bd00-0f62aa73686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50    # steepness factor\n",
    "num_blocks = 100  # number of expression blocks\n",
    "num_data = 5000   # number of data\n",
    "test_size = 1000  # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21938c00-d73f-4255-bc7c-bce6e8034cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf81ff-627d-444d-8d90-121c7e20c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec0a67-54ea-4a9d-b037-0c7c9390e3f9",
   "metadata": {},
   "source": [
    "## Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50aaabd7-90ed-4628-a1da-c98777868d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a7aa5-f73c-4a50-89f5-c9dcd19447f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▌                                                              | 20/100 [40:01<2:39:57, 119.97s/it]"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))[:100]):\n",
    "    # set params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval, objval = model.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    try:\n",
    "        xval, objval = model.solve(\"scip\")\n",
    "        # eval\n",
    "        params.append(list(p)+list(a))\n",
    "        sols.append(list(list(xval.values())[0].values()))\n",
    "        objvals.append(objval)\n",
    "        conviols.append(sum(model.cal_violation()))\n",
    "    except:\n",
    "        params.append(list(p)+list(a))\n",
    "        sols.append(None)\n",
    "        objvals.append(None)\n",
    "        conviols.append(None)\n",
    "    tock = time.time()\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "df.to_csv(\"result/rb_exact_50-100.csv\")\n",
    "df = df.iloc[:100]\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "print(\"Number of None values: \", df[\"Sol\"].isna().sum())\n",
    "df.to_csv(\"result/rb_exact_50-100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d0cd5-521e-4500-87fe-cef832015988",
   "metadata": {},
   "source": [
    "## Heuristic - Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316c0a99-63f5-4006-8a81-82212ceb7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heuristic import naive_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd361275-a1cb-4355-9695-85e5dd5447ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:01<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+02        100.000000    100.000000\n",
      "mean   1.595451e+04          0.312121      2.395702\n",
      "std    1.544777e+05          2.200007      2.172108\n",
      "min    3.598118e+02          0.000000      0.920691\n",
      "25%    4.483671e+02          0.000000      1.246543\n",
      "50%    5.084547e+02          0.000000      1.796755\n",
      "75%    5.518894e+02          0.000000      2.808077\n",
      "max    1.545284e+06         16.557013     18.618939\n",
      "Number of infeasible solution: 2\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))[:100]):\n",
    "    # set params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # relax\n",
    "    model_rel = model.relax()\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval_rel, _ = model_rel.solve(\"scip\")\n",
    "    xval, objval = naive_round(xval_rel, model)\n",
    "    tock = time.time()\n",
    "    # eval\n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_heur_rnd_50-100.csv\")\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96304fbd-08f5-4be7-a81e-83c85332029c",
   "metadata": {},
   "source": [
    "## Heuristic - N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356187af-e02d-4478-bf78-ada6a2e1b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_heur = model.first_solution_heuristic(nodes_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c7fc52-cbbc-4414-bf1d-316d65c8db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [06:46<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+03            1000.0   1000.000000\n",
      "mean   1.749761e+12               0.0      0.403884\n",
      "std    9.192329e+12               0.0      0.166594\n",
      "min    5.558174e+02               0.0      0.245428\n",
      "25%    7.700089e+02               0.0      0.310472\n",
      "50%    8.632258e+02               0.0      0.353868\n",
      "75%    9.996323e+02               0.0      0.414785\n",
      "max    4.999519e+13               0.0      1.257725\n",
      "Number of infeasible solution: 0\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # set params\n",
    "    model_heur.set_param_val({\"p\":p, \"a\":a})\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    xval, objval = model_heur.solve(\"scip\")\n",
    "    tock = time.time()\n",
    "    # eval\n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model_heur.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/rb_heur_n1_50-100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeab86ef-1d8e-45d9-acaf-8c01109a3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1.000000e+02             100.0    100.000000\n",
      "mean   1.999690e+12               0.0      0.409453\n",
      "std    9.845793e+12               0.0      0.148936\n",
      "min    5.645990e+02               0.0      0.245428\n",
      "25%    7.619726e+02               0.0      0.325797\n",
      "50%    8.919459e+02               0.0      0.358961\n",
      "75%    1.025256e+03               0.0      0.422262\n",
      "max    4.999237e+13               0.0      1.028245\n",
      "Number of infeasible solution: 0\n",
      "Number of None values:  0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/rb_heur_n1_50-100.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "print(\"Number of None values: \", df[\"Sol\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819c60c-df5f-41c6-ae83-888c75aa78d7",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160d5677-c861-486f-9533-852d43f971bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536d2d58-67ba-408a-b72a-7c5bd54a5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 80   # weight of constraint violation penealty\n",
    "hlayers_sol = 4       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 256           # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee1241e-e53a-4cbb-927a-edcdb3537303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f10263-5f69-4288-a4e8-8be83929c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 20996.05\n",
      "Epoch 1, Validation Loss: 4016.29\n",
      "Epoch 2, Validation Loss: 1759.47\n",
      "Epoch 3, Validation Loss: 1213.61\n",
      "Epoch 4, Validation Loss: 1522.16\n",
      "Epoch 5, Validation Loss: 1312.35\n",
      "Epoch 6, Validation Loss: 1165.38\n",
      "Epoch 7, Validation Loss: 1032.75\n",
      "Epoch 8, Validation Loss: 1098.03\n",
      "Epoch 9, Validation Loss: 1492.84\n",
      "Epoch 10, Validation Loss: 1189.45\n",
      "Epoch 11, Validation Loss: 831.75\n",
      "Epoch 12, Validation Loss: 845.00\n",
      "Epoch 13, Validation Loss: 885.85\n",
      "Epoch 14, Validation Loss: 662.87\n",
      "Epoch 15, Validation Loss: 820.98\n",
      "Epoch 16, Validation Loss: 756.71\n",
      "Epoch 17, Validation Loss: 650.82\n",
      "Epoch 18, Validation Loss: 665.11\n",
      "Epoch 19, Validation Loss: 884.84\n",
      "Epoch 20, Validation Loss: 730.10\n",
      "Epoch 21, Validation Loss: 614.67\n",
      "Epoch 22, Validation Loss: 644.56\n",
      "Epoch 23, Validation Loss: 720.34\n",
      "Epoch 24, Validation Loss: 749.18\n",
      "Epoch 25, Validation Loss: 666.92\n",
      "Epoch 26, Validation Loss: 606.64\n",
      "Epoch 27, Validation Loss: 566.92\n",
      "Epoch 28, Validation Loss: 766.88\n",
      "Epoch 29, Validation Loss: 723.36\n",
      "Epoch 30, Validation Loss: 664.51\n",
      "Epoch 31, Validation Loss: 715.34\n",
      "Epoch 32, Validation Loss: 656.88\n",
      "Epoch 33, Validation Loss: 648.94\n",
      "Epoch 34, Validation Loss: 617.90\n",
      "Epoch 35, Validation Loss: 598.58\n",
      "Epoch 36, Validation Loss: 601.60\n",
      "Epoch 37, Validation Loss: 912.76\n",
      "Epoch 38, Validation Loss: 682.82\n",
      "Epoch 39, Validation Loss: 795.96\n",
      "Epoch 40, Validation Loss: 665.26\n",
      "Epoch 41, Validation Loss: 721.86\n",
      "Epoch 42, Validation Loss: 694.10\n",
      "Epoch 43, Validation Loss: 633.82\n",
      "Epoch 44, Validation Loss: 729.53\n",
      "Epoch 45, Validation Loss: 898.61\n",
      "Epoch 46, Validation Loss: 1169.38\n",
      "Early stopping at epoch 46\n",
      "Best model loaded.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e835084-eb75-45d9-bcbd-5fb4c613fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    568.468975          0.005120      0.003273\n",
      "std     205.694313          0.101694      0.000969\n",
      "min     266.924016          0.000000      0.000999\n",
      "25%     366.757142          0.000000      0.002518\n",
      "50%     558.681739          0.000000      0.003003\n",
      "75%     720.295802          0.000000      0.003999\n",
      "max    1574.572316          2.409778      0.008513\n",
      "Number of infeasible solution: 3\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/rb_lr_50-100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f0badf-5831-4950-a065-b331eb77eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count   100.000000        100.000000    100.000000\n",
      "mean    548.524412          0.006933      0.003540\n",
      "std     231.017347          0.069333      0.001223\n",
      "min     276.415199          0.000000      0.001999\n",
      "25%     351.154360          0.000000      0.002767\n",
      "50%     516.172182          0.000000      0.003098\n",
      "75%     714.485029          0.000000      0.004256\n",
      "max    1419.896277          0.693326      0.008513\n",
      "Number of infeasible solution: 1\n",
      "Number of None values:  0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/rb_lr_50-100.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "print(\"Number of None values: \", df[\"Sol\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8a72-29b9-49c4-b3c1-0d68895c1c1f",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4b3d02-3cac-4bce-aaaf-43994ff200d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46b9817-87ac-4af0-b387-b10c9a4998f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 80   # weight of constraint violation penealty\n",
    "hlayers_sol = 4       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 256           # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa8b147f-39c8-4eb7-bb95-93dd8e4cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                          int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6f5bb17-8c3c-4dcd-952d-caa1d7c4c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 18587.63\n",
      "Epoch 1, Validation Loss: 3448.91\n",
      "Epoch 2, Validation Loss: 2870.52\n",
      "Epoch 3, Validation Loss: 1232.80\n",
      "Epoch 4, Validation Loss: 1303.39\n",
      "Epoch 5, Validation Loss: 1380.01\n",
      "Epoch 6, Validation Loss: 1107.19\n",
      "Epoch 7, Validation Loss: 14572.58\n",
      "Epoch 8, Validation Loss: 2064.73\n",
      "Epoch 9, Validation Loss: 24670.45\n",
      "Epoch 10, Validation Loss: 843.25\n",
      "Epoch 11, Validation Loss: 727.15\n",
      "Epoch 12, Validation Loss: 2243217268.91\n",
      "Epoch 13, Validation Loss: 794.01\n",
      "Epoch 14, Validation Loss: 827.54\n",
      "Epoch 15, Validation Loss: 809.01\n",
      "Epoch 16, Validation Loss: 1533.53\n",
      "Epoch 17, Validation Loss: 712.35\n",
      "Epoch 18, Validation Loss: 736.32\n",
      "Epoch 19, Validation Loss: 808.03\n",
      "Epoch 20, Validation Loss: 725.17\n",
      "Epoch 21, Validation Loss: 896.27\n",
      "Epoch 22, Validation Loss: 731.22\n",
      "Epoch 23, Validation Loss: 639.29\n",
      "Epoch 24, Validation Loss: 747.64\n",
      "Epoch 25, Validation Loss: 799.46\n",
      "Epoch 26, Validation Loss: 965.93\n",
      "Epoch 27, Validation Loss: 714.63\n",
      "Epoch 28, Validation Loss: 673.89\n",
      "Epoch 29, Validation Loss: 692.98\n",
      "Epoch 30, Validation Loss: 913.31\n",
      "Epoch 31, Validation Loss: 921.00\n",
      "Epoch 32, Validation Loss: 704.58\n",
      "Epoch 33, Validation Loss: 813.10\n",
      "Epoch 34, Validation Loss: 787.65\n",
      "Epoch 35, Validation Loss: 749.38\n",
      "Epoch 36, Validation Loss: 641.45\n",
      "Epoch 37, Validation Loss: 887.43\n",
      "Epoch 38, Validation Loss: 743.98\n",
      "Epoch 39, Validation Loss: 757.09\n",
      "Epoch 40, Validation Loss: 1006.59\n",
      "Epoch 41, Validation Loss: 860.04\n",
      "Epoch 42, Validation Loss: 812.01\n",
      "Early stopping at epoch 42\n",
      "Best model loaded.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6584d57e-6b4c-4262-82f5-55735ef17cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 63.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count  1000.000000       1000.000000   1000.000000\n",
      "mean    639.164363          0.011845      0.002797\n",
      "std     138.688235          0.374560      0.000703\n",
      "min     417.931821          0.000000      0.000999\n",
      "25%     545.062545          0.000000      0.002113\n",
      "50%     608.273523          0.000000      0.002994\n",
      "75%     689.761520          0.000000      0.003030\n",
      "max    1598.102928         11.844629      0.006236\n",
      "Number of infeasible solution: 1\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "df.to_csv(\"result/rb_lt_50-100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfcdddd-b77b-4e4c-8e99-f32cf2373f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count   100.000000        100.000000    100.000000\n",
      "mean    647.550143          0.118446      0.002797\n",
      "std     159.574255          1.184463      0.000684\n",
      "min     421.836907          0.000000      0.001509\n",
      "25%     559.713165          0.000000      0.002455\n",
      "50%     610.942312          0.000000      0.002830\n",
      "75%     689.762984          0.000000      0.003013\n",
      "max    1598.102928         11.844629      0.005658\n",
      "Number of infeasible solution: 1\n",
      "Number of None values:  0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result/rb_lt_50-100.csv\", index_col=0).iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))\n",
    "print(\"Number of None values: \", df[\"Sol\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b304d-5c4b-4690-b870-d2c2b9be24bb",
   "metadata": {},
   "source": [
    "## Parametric Learning Then Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84041a5d-55e1-4522-a7d1-48f0a3d5ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b302e6-357d-4704-8f75-bd48c939b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 80   # weight of constraint violation penealty\n",
    "hlayers_sol = 4       # number of hidden layers for solution mapping\n",
    "hsize = 256           # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b366eb3-92fe-42b9-8597-ef44e0325e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e071c4-b569-4e19-80ba-484d7df627c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 18669.99\n",
      "Epoch 1, Validation Loss: 1604.38\n",
      "Epoch 2, Validation Loss: 852.39\n",
      "Epoch 3, Validation Loss: 494.47\n",
      "Epoch 4, Validation Loss: 672.31\n",
      "Epoch 5, Validation Loss: 318.87\n",
      "Epoch 6, Validation Loss: 519.18\n",
      "Epoch 7, Validation Loss: 336.93\n",
      "Epoch 8, Validation Loss: 293.51\n",
      "Epoch 9, Validation Loss: 293.15\n",
      "Epoch 10, Validation Loss: 608.17\n",
      "Epoch 11, Validation Loss: 306.33\n",
      "Epoch 12, Validation Loss: 444.61\n",
      "Epoch 13, Validation Loss: 492.69\n",
      "Epoch 14, Validation Loss: 269.47\n",
      "Epoch 15, Validation Loss: 363.40\n",
      "Epoch 16, Validation Loss: 267.53\n",
      "Epoch 17, Validation Loss: 517.68\n",
      "Epoch 18, Validation Loss: 285.02\n",
      "Epoch 19, Validation Loss: 282.13\n",
      "Epoch 20, Validation Loss: 244.92\n",
      "Epoch 21, Validation Loss: 286.68\n",
      "Epoch 22, Validation Loss: 256.09\n",
      "Epoch 23, Validation Loss: 278.70\n",
      "Epoch 24, Validation Loss: 254.02\n",
      "Epoch 25, Validation Loss: 241.33\n",
      "Epoch 26, Validation Loss: 254.99\n",
      "Epoch 27, Validation Loss: 230.28\n",
      "Epoch 28, Validation Loss: 279.49\n",
      "Epoch 29, Validation Loss: 235.84\n",
      "Epoch 30, Validation Loss: 365.18\n",
      "Epoch 31, Validation Loss: 233.36\n",
      "Epoch 32, Validation Loss: 333.49\n",
      "Epoch 33, Validation Loss: 350.86\n",
      "Epoch 34, Validation Loss: 263.45\n",
      "Epoch 35, Validation Loss: 291.37\n",
      "Epoch 36, Validation Loss: 305.61\n",
      "Epoch 37, Validation Loss: 223.15\n",
      "Epoch 38, Validation Loss: 235.79\n",
      "Epoch 39, Validation Loss: 241.59\n",
      "Epoch 40, Validation Loss: 209.85\n",
      "Epoch 41, Validation Loss: 270.68\n",
      "Epoch 42, Validation Loss: 222.75\n",
      "Epoch 43, Validation Loss: 250.04\n",
      "Epoch 44, Validation Loss: 213.25\n",
      "Epoch 45, Validation Loss: 207.86\n",
      "Epoch 46, Validation Loss: 250.90\n",
      "Epoch 47, Validation Loss: 297.15\n",
      "Epoch 48, Validation Loss: 252.22\n",
      "Epoch 49, Validation Loss: 258.85\n",
      "Epoch 50, Validation Loss: 229.71\n",
      "Epoch 51, Validation Loss: 227.27\n",
      "Epoch 52, Validation Loss: 280.02\n",
      "Epoch 53, Validation Loss: 298.56\n",
      "Epoch 54, Validation Loss: 222.96\n",
      "Epoch 55, Validation Loss: 206.66\n",
      "Epoch 56, Validation Loss: 245.32\n",
      "Epoch 57, Validation Loss: 210.29\n",
      "Epoch 58, Validation Loss: 230.28\n",
      "Epoch 59, Validation Loss: 214.17\n",
      "Epoch 60, Validation Loss: 229.21\n",
      "Epoch 61, Validation Loss: 227.36\n",
      "Epoch 62, Validation Loss: 215.18\n",
      "Epoch 63, Validation Loss: 200.75\n",
      "Epoch 64, Validation Loss: 209.82\n",
      "Epoch 65, Validation Loss: 203.41\n",
      "Epoch 66, Validation Loss: 227.31\n",
      "Epoch 67, Validation Loss: 426.38\n",
      "Epoch 68, Validation Loss: 237.15\n",
      "Epoch 69, Validation Loss: 206.33\n",
      "Epoch 70, Validation Loss: 196.71\n",
      "Epoch 71, Validation Loss: 220.89\n",
      "Epoch 72, Validation Loss: 238.27\n",
      "Epoch 73, Validation Loss: 202.42\n",
      "Epoch 74, Validation Loss: 209.67\n",
      "Epoch 75, Validation Loss: 195.35\n",
      "Epoch 76, Validation Loss: 225.66\n",
      "Epoch 77, Validation Loss: 222.38\n",
      "Epoch 78, Validation Loss: 204.23\n",
      "Epoch 79, Validation Loss: 196.63\n",
      "Epoch 80, Validation Loss: 199.99\n",
      "Epoch 81, Validation Loss: 192.66\n",
      "Epoch 82, Validation Loss: 200.68\n",
      "Epoch 83, Validation Loss: 198.40\n",
      "Epoch 84, Validation Loss: 245.64\n",
      "Epoch 85, Validation Loss: 212.84\n",
      "Epoch 86, Validation Loss: 208.89\n",
      "Epoch 87, Validation Loss: 249.80\n",
      "Epoch 88, Validation Loss: 219.16\n",
      "Epoch 89, Validation Loss: 194.45\n",
      "Epoch 90, Validation Loss: 319.27\n",
      "Epoch 91, Validation Loss: 203.65\n",
      "Epoch 92, Validation Loss: 203.32\n",
      "Epoch 93, Validation Loss: 208.34\n",
      "Epoch 94, Validation Loss: 198.66\n",
      "Epoch 95, Validation Loss: 208.05\n",
      "Epoch 96, Validation Loss: 206.48\n",
      "Epoch 97, Validation Loss: 199.32\n",
      "Epoch 98, Validation Loss: 198.01\n",
      "Epoch 99, Validation Loss: 201.90\n",
      "Epoch 100, Validation Loss: 218.69\n",
      "Early stopping at epoch 100\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 53.12 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e8afab0-f608-4960-a9f7-0c4ab8ba2b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 53.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Constraints Viol  Elapsed Time\n",
      "count   100.000000        100.000000    100.000000\n",
      "mean    603.639254          0.095145      0.000709\n",
      "std     328.650344          0.951451      0.001140\n",
      "min     195.644007          0.000000      0.000000\n",
      "25%     304.208432          0.000000      0.000000\n",
      "50%     495.564522          0.000000      0.001000\n",
      "75%     842.349442          0.000000      0.001000\n",
      "max    1399.521807          9.514506      0.010791\n",
      "Number of infeasible solution: 1\n"
     ]
    }
   ],
   "source": [
    "from src.heuristic import naive_round\n",
    "params, sols, objvals, conviols, elapseds = [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))[:100]):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x\"]\n",
    "    for i in range(num_blocks*2):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval_rel, _ = model.get_val()\n",
    "    xval, objval = naive_round(xval_rel, model)\n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    conviols.append(sum(model.cal_violation()))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\":params, \"Sol\":sols, \"Obj Val\": objvals, \"Constraints Viol\": conviols, \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "df.to_csv(\"result/rb_pr_50-100.csv\")\n",
    "df = df.iloc[:100]\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Constraints Viol\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020db85e-14f8-440f-b9e3-2d2ba1cb339e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
